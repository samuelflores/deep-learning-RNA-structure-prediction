{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "import utils\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from PyPDF2 import PdfWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "clusters_dir = Path('../../../all_clusters')\n",
    "data_dir = Path('data')\n",
    "figures_dir = Path('figures')\n",
    "\n",
    "# Create figures directory if none exists\n",
    "if not figures_dir.exists():\n",
    "    figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load all data\n",
    "tloops_raw = utils.load(data_dir/'tloops_raw.pickle')\n",
    "tloops_filtered = utils.load(data_dir/'tloops_filtered.pickle')\n",
    "fragments_8_filtered = utils.load(data_dir/'fragments_8_filtered.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other functions\n",
    "\n",
    "def get_res_array(sequences:list[str], res_names:list[str]=['A','U','C','G']):\n",
    "    res_array= np.zeros(shape=(len(res_names), len(sequences[0])))\n",
    "    for seq in sequences:\n",
    "        for pos, res in enumerate(seq):\n",
    "            res_array[res_names.index(res)][pos] += 1\n",
    "    res_array = res_array/res_array.sum(axis=0, keepdims=True)\n",
    "    return res_array\n",
    "\n",
    "\n",
    "def merge_pdfs_in_dir(dir:Path, filename:str='merged_pdf'):\n",
    "    merger = PdfWriter()\n",
    "    for item in dir.iterdir():\n",
    "        merger.append(item)\n",
    "    merger.write(dir.parent/(filename + '.pdf'))\n",
    "    merger.close()\n",
    "    shutil.rmtree(dir)\n",
    "\n",
    "\n",
    "def format_filename(text:str):\n",
    "    return text.lower().replace(' ','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot functions\n",
    "\n",
    "# Plot bar graph\n",
    "def plot_bar(data:dict, title:str='', dir:Path=figures_dir) -> None:\n",
    "    \n",
    "    ax = plt.subplots(figsize=(len(data)*0.3,3))[1]\n",
    "    bar_plot = ax.bar(range(len(data)), data.values(), align='edge', width=0.5)\n",
    "    ax.bar_label(bar_plot, rotation='vertical', padding=5)\n",
    "    ax.set_xticks(range(len(data)), data.keys(), rotation='vertical', horizontalalignment='left')\n",
    "    ax.set_title(title, y=1.1)\n",
    "    \n",
    "    # Cosmetic adjustments\n",
    "    ax.margins(x=0.5/len(data), tight=True)\n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "    \n",
    "    save_pdf(dir/format_filename(title))\n",
    "\n",
    "\n",
    "# Plot stacked bar graph\n",
    "def plot_stacked_bar(x, array, labels:list[str], title:str='', dir:Path=figures_dir) -> None:\n",
    "    ax = plt.subplots(figsize=(len(x)*0.3,3))[1]\n",
    "    ax.bar(x, array[0], label=labels[0])\n",
    "    for i in range(1, len(array)):\n",
    "        ax.bar(x, array[i], bottom=np.sum(array[:i], axis=0), label=labels[i])\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.5,1.03))\n",
    "    \n",
    "    save_pdf(dir/format_filename(title))\n",
    "\n",
    "\n",
    "def save_pdf(path:Path):\n",
    "    plt.savefig(Path(path.with_suffix('.pdf')), bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragment_stats(data, label:str ='') -> None:\n",
    "\n",
    "    # Sequence histogram\n",
    "    seqs = [i.res_seq for i in data]\n",
    "    seqs_dict = OrderedDict(Counter(seqs).most_common())\n",
    "    plot_bar(seqs_dict, f'{label} sequence frequencies')\n",
    "    \n",
    "    # Sequence by cluster\n",
    "    tmp_dir = figures_dir/'tmp'#Path(f'{figures_dir}/tmp')\n",
    "    if tmp_dir.exists() and tmp_dir.is_dir():\n",
    "        shutil.rmtree(tmp_dir)\n",
    "    tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    clust_ids = set([i.clust_id for i in data])\n",
    "    for c in clust_ids:\n",
    "        clust_seqs = [t.res_seq for t in data if t.clust_id == c]\n",
    "        clust_seqs_dict = OrderedDict(Counter(clust_seqs).most_common())\n",
    "        plot_bar(clust_seqs_dict, f'{label} cluster {c} sequence frequencies', dir=tmp_dir)\n",
    "    merge_pdfs_in_dir(tmp_dir, format_filename(f'{label} cluster sequence frequencies.pdf'))\n",
    "    \n",
    "    # Cluster histogram\n",
    "    clust_ids = [t.clust_id for t in data]\n",
    "    clust_ids_dict = OrderedDict(sorted(Counter(clust_ids).items()))\n",
    "    plot_bar(clust_ids_dict, f'{label} cluster frequencies')\n",
    "    \n",
    "    # Residue position histogram\n",
    "    res_array = get_res_array(seqs)\n",
    "    plot_stacked_bar(range(len(seqs[0])), res_array, ['A','U','C','G'], f'{label} residue position frequencies')\n",
    "\n",
    "    # PDB IDs\n",
    "    pdb_ids = [i.pdb_id for i in data]\n",
    "    \n",
    "    print(\n",
    "        f'{label}:\\n'\n",
    "        f'- Amount: {len(data)}\\n'\n",
    "        f'- Unique sequences: {len(set(seqs))}\\n'\n",
    "        f'- PDB IDs: {len(set(pdb_ids))}\\n'\n",
    "        f'Figures saved to /{figures_dir}\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tetraloops\n",
    "> The final tetraloop database is composed by 21,993 RNA fragments: 17,709 from X-ray, 3057 from NMR and 1227 from cryo-EM structures. The distributions of resolutions are shown in Fig. S1. [Bottaro et al.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5529312/)\n",
    "\n",
    "According to Table SI1, there should be a total of 19383 tetraloops. I don't know where/what the remaining 2610 RNA fragments (from the total of 21993) are. The total number of \"effective\" tetraloops (members whose distance is above 0.07 eRMSD) is 16979."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw tetraloops:\n",
      "- Amount: 19383\n",
      "- Unique sequences: 292\n",
      "- PDB IDs: 864\n",
      "Figures saved to /figures\n",
      "\n",
      "Filtered tetraloops:\n",
      "- Amount: 11952\n",
      "- Unique sequences: 292\n",
      "- PDB IDs: 864\n",
      "Figures saved to /figures\n",
      "\n",
      "Generated tetraloops:\n",
      "- Amount: 151586\n",
      "- Unique sequences: 240\n",
      "- PDB IDs: 525\n",
      "Figures saved to /figures\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cluster groups, as named in Bottaro et al. Table SI1\n",
    "gnra = [1]\n",
    "gnra_like = [1, 3, 6, 9, 25, 26, 36, 40]\n",
    "uncg = [2]\n",
    "uncg_like = [2, 5, 37, 44]\n",
    "u_turn = [4]\n",
    "\n",
    "fragment_stats(tloops_raw, 'Raw tetraloops')\n",
    "fragment_stats(tloops_filtered, 'Filtered tetraloops')\n",
    "tloop_fragments = [i for i in fragments_8_filtered if i.clust_id != 0]\n",
    "fragment_stats(tloop_fragments, 'Generated tetraloops')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high number of tetraloops found the fragment dataset is probably due to chain redundancy, as all tetraloops belonging to a PDB structure were aligned to *all* chains in said PDB structure. However, 53 unique tetraloops originally found in both the raw and filtered tetraloop datasets are lost. Where the hell are they disappearing to? My guess right now is the chain annotation process somehow filters out some of the tetraloops, because they don't fulfill the conditions of a) having identical residue names and b) having identical residue numbers.\n",
    "\n",
    "UGH I TRIED EVERY FILTERING OPTION AND ITS STILL NOT WORKING WHATS HAPPENING \n",
    "\n",
    "is it because some of the pdb ids are somehow being filtered out??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique fragments\n",
    "The number of unique RNA fragments is $4^{8} = 65536$. The theoretical maximum number of fragments that can be generated from this dataset is 495279. The number of unique generated fragments is 34431, which represents approximately 53% of all possible unique fragments. \n",
    "\n",
    "Expected number of tries to obtain $x$ unique sequences:\n",
    "$$\\sum\\limits_{i=0}^x \\frac{n}{n-i}$$\n",
    "where $n$ = total number of unique sequences\n",
    "\n",
    "The expected number of tries needed to obtain *all* unique fragments is 764646. The expected number of tries needed to obtain 34431 fragments is 48839.\n",
    "\n",
    "The dataset is most likely too small to account for *all* possible residue permutations, but should be large enough to account for more than 53% of all residues. For reference, a dataset of size 451750 is expected to return 99.9% of all unique fragments.\n",
    "\n",
    "- Are certain residues/motifs overrepresented in the dataset?\n",
    "- Will increasing the dataset to include more PDB structures result in more unique fragments?\n",
    "- Is the sequence database too redundant? Should sequence similarity *between* different PDB structures also be filtered out of the reference database?\n",
    "- Are the sequences palindromic or otherwise symmetrical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible unique fragments: 65536\n",
      "Expected # tries to obtain all unique fragments: 764646\n"
     ]
    }
   ],
   "source": [
    "pos_unique_frags = 4**8\n",
    "print(f'Possible unique fragments: {pos_unique_frags}')\n",
    "\n",
    "expected_tries_all = sum([pos_unique_frags/(pos_unique_frags-i) for i in range(pos_unique_frags)])\n",
    "print(f'Expected # tries to obtain all unique fragments: {round(expected_tries_all)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
