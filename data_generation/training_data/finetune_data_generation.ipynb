{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import utils\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "fragments_dir = Path('../data/fragments/')\n",
    "\n",
    "# Load fragment data\n",
    "fragments_8 = utils.load(fragments_dir/'fragments_8_filtered.pickle')\n",
    "fragments_10 = utils.load(fragments_dir/'fragments_10_filtered.pickle')\n",
    "fragments_12 = utils.load(fragments_dir/'fragments_12_filtered.pickle')\n",
    "fragments_14 = utils.load(fragments_dir/'fragments_14_filtered.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(path, data): # Data entries should be formatted as (sequence, label) tuple\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(\"sequence,label\\n\")\n",
    "        for entry in data:\n",
    "            f.write(f\"{entry[0]},{entry[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, train_ratio = 0.8):\n",
    "    train_cutoff = int(len(data) * train_ratio)\n",
    "    dev_ratio = (1-train_ratio)/2\n",
    "    dev_cutoff = int(len(data) * (1-dev_ratio))\n",
    "    \n",
    "    train_data = data[:train_cutoff]\n",
    "    dev_data = data[train_cutoff:dev_cutoff]\n",
    "    test_data = data[dev_cutoff:]\n",
    "    return train_data, dev_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DNABERT2 finetuning CSV generation\n",
    "# for task in [\"gnra\"]:\n",
    "#     for fragment_length in [8, 10, 12, 14]:\n",
    "#         for train_ratio in [0.8]:\n",
    "#             for nucleotides in [\"T\", \"U\"]:\n",
    "#                 data_dir = Path(f\"{task}_{fragment_length}_{int(train_ratio*100)}_{nucleotides}/\")\n",
    "#                 if data_dir.exists():\n",
    "#                     shutil.rmtree(data_dir)\n",
    "#                 data_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "#                 # fragment_length\n",
    "#                 fragments = {8: fragments_8, 10: fragments_10, 12: fragments_12, 14: fragments_14}[fragment_length]\n",
    "\n",
    "#                 # task\n",
    "#                 if task == \"gnra\":\n",
    "#                     data = [i for i in fragments if i.clust_id != 0]\n",
    "#                     data = [(i.res_seq, 1) if i.clust_id == 1 else (i.res_seq, 0) for i in fragments]\n",
    "#                 elif task == \"all\":\n",
    "#                     data = [(i.res_seq, i.clust_id) for i in fragments]\n",
    "#                 random.shuffle(data)\n",
    "                \n",
    "#                 # nucleotides\n",
    "#                 if nucleotides == \"T\":\n",
    "#                     data = [(i.replace(\"U\",\"T\"), j) for i, j in data]\n",
    "                \n",
    "#                 # split_data(train_ratio)\n",
    "#                 train_data, dev_data, test_data = split_data(data, train_ratio)\n",
    "\n",
    "#                 write_csv(data_dir/\"train.csv\", train_data)\n",
    "#                 write_csv(data_dir/\"dev.csv\", dev_data)\n",
    "#                 write_csv(data_dir/\"test.csv\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/tmp.2298489/ipykernel_70980/3862090270.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.savez(f\"{dir}/{csv}_matrices.npz\", np.array(encoded_matrices))\n",
      "/local/tmp.2298489/ipykernel_70980/3862090270.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.savez(f\"{dir}/{csv}_matrices.npz\", np.array(encoded_matrices))\n",
      "/local/tmp.2298489/ipykernel_70980/3862090270.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.savez(f\"{dir}/{csv}_matrices.npz\", np.array(encoded_matrices))\n",
      "/local/tmp.2298489/ipykernel_70980/3862090270.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.savez(f\"{dir}/{csv}_matrices.npz\", np.array(encoded_matrices))\n",
      "/local/tmp.2298489/ipykernel_70980/3862090270.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.savez(f\"{dir}/{csv}_matrices.npz\", np.array(encoded_matrices))\n",
      "/local/tmp.2298489/ipykernel_70980/3862090270.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.savez(f\"{dir}/{csv}_matrices.npz\", np.array(encoded_matrices))\n",
      "/local/tmp.2298489/ipykernel_70980/3862090270.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.savez(f\"{dir}/{csv}_matrices.npz\", np.array(encoded_matrices))\n"
     ]
    }
   ],
   "source": [
    "# ANN NPZ/NPY data generation\n",
    "\n",
    "def encode_sequence(sequence, residue_map = {'A':0,'U':1,'T':1,'C':2,'G':3}): # TODO should I be included?\n",
    "    seq_array = np.array([residue_map[i] for i in sequence if i in residue_map.keys()])\n",
    "    encoded_array = np.zeros((seq_array.size, 4), dtype=int)\n",
    "    encoded_array[np.arange(seq_array.size), seq_array] = 1\n",
    "    return encoded_array\n",
    "\n",
    "def make_npzs():\n",
    "    dirs = [filename for filename in os.listdir(\"./\") if os.path.isdir(f\"./{filename}\")]\n",
    "    for dir in dirs:\n",
    "        csvs = [filename.split(\".\")[0] for filename in os.listdir(dir) if filename.endswith(\".csv\")]\n",
    "        for csv in csvs:\n",
    "            data = pd.read_csv(f\"{dir}/{csv}.csv\", sep=\",\")\n",
    "            sequences = data[\"sequence\"].tolist()\n",
    "            labels = data[\"label\"].astype(int).tolist()\n",
    "            encoded_matrices = [encode_sequence(i) for i in sequences]\n",
    "            np.savez(f\"{dir}/{csv}_matrices.npz\", np.array(encoded_matrices))\n",
    "            np.save(f\"{dir}/{csv}_labels.npy\", labels)\n",
    "\n",
    "make_npzs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 4991\tTetraloops: 4991 (100.0)\tDecoys: 0 (0.0)\n"
     ]
    }
   ],
   "source": [
    "# all = len(entries)\n",
    "# decoys = len([i for i in entries if i.clust_id == 0])\n",
    "# tloops = len([i for i in entries if i.clust_id != 0])\n",
    "# print(f\"All: {all}\\tTetraloops: {tloops} ({tloops/all*100:.4})\\tDecoys: {decoys} ({decoys/all*100:.4})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
