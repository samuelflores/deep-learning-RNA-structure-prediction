{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import utils\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "fragments_dir = Path('../data/fragments/')\n",
    "\n",
    "# Load fragment data\n",
    "fragments_8 = utils.load(fragments_dir/'fragments_8_filtered.pickle')\n",
    "fragments_10 = utils.load(fragments_dir/'fragments_10_filtered.pickle')\n",
    "fragments_12 = utils.load(fragments_dir/'fragments_12_filtered.pickle')\n",
    "fragments_14 = utils.load(fragments_dir/'fragments_14_filtered.pickle')\n",
    "fragments_16 = utils.load(fragments_dir/'fragments_16_filtered.pickle')\n",
    "fragments_18 = utils.load(fragments_dir/'fragments_18_filtered.pickle')\n",
    "fragments_20 = utils.load(fragments_dir/'fragments_20_filtered.pickle')\n",
    "fragments_22 = utils.load(fragments_dir/'fragments_22_filtered.pickle')\n",
    "fragments_24 = utils.load(fragments_dir/'fragments_24_filtered.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(path, data): # Data entries should be formatted as (sequence, label) tuple\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(\"sequence,label\\n\")\n",
    "        for entry in data:\n",
    "            f.write(f\"{entry[0]},{entry[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, train_ratio = 0.8):\n",
    "    train_cutoff = int(len(data) * train_ratio)\n",
    "    dev_ratio = (1-train_ratio)/2\n",
    "    dev_cutoff = int(len(data) * (1-dev_ratio))\n",
    "    \n",
    "    train_data = data[:train_cutoff]\n",
    "    dev_data = data[train_cutoff:dev_cutoff]\n",
    "    test_data = data[dev_cutoff:]\n",
    "    return train_data, dev_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNABERT2 finetuning CSV generation\n",
    "for task in [\"clusters\", \"tloop\"]: # \"gnravall\", \"gnra\", \"clusters\", \"tloop\"\n",
    "    for fragment_length in [16, 18, 20, 22, 24]: # 8, 10, 12, 14, 16, 18, 20, 22, 24\n",
    "        for train_ratio in [0.8]:\n",
    "            for nucleotides in [\"T\", \"U\"]: #\"T\", \"U\"\n",
    "                data_dir = Path(f\"{task}_{fragment_length}_{int(train_ratio*100)}_{nucleotides}/\")\n",
    "                if data_dir.exists():\n",
    "                    shutil.rmtree(data_dir)\n",
    "                data_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                # fragment_length\n",
    "                fragments = {\n",
    "                    8: fragments_8,\n",
    "                    10: fragments_10,\n",
    "                    12: fragments_12,\n",
    "                    14: fragments_14,\n",
    "                    16: fragments_16,\n",
    "                    18: fragments_18,\n",
    "                    20: fragments_20,\n",
    "                    22: fragments_22,\n",
    "                    24: fragments_24\n",
    "                }[fragment_length]\n",
    "                \n",
    "                # task\n",
    "                if task == \"gnravall\":\n",
    "                    data = [i for i in fragments if i.clust_id != 0]\n",
    "                    data = [(i.res_seq, 1) if i.clust_id == 1 else (i.res_seq, 0) for i in fragments] # TODO fix\n",
    "                elif task == \"gnra\":\n",
    "                    data = [i for i in fragments if i.clust_id != 0]\n",
    "                    data = [(i.res_seq, 1) if i.clust_id == 1 else (i.res_seq, 0) for i in data]\n",
    "                elif task == \"clusters\":\n",
    "                    data = [(i.res_seq, i.clust_id) for i in fragments]\n",
    "                elif task == \"tloop\":\n",
    "                    data = [(i.res_seq, 0) if i.clust_id == 0 else (i.res_seq, 1) for i in fragments]\n",
    "                random.shuffle(data)\n",
    "                \n",
    "                # nucleotides\n",
    "                if nucleotides == \"T\":\n",
    "                    data = [(i.replace(\"U\",\"T\"), j) for i, j in data]\n",
    "                \n",
    "                # split_data(train_ratio)\n",
    "                train_data, dev_data, test_data = split_data(data, train_ratio)\n",
    "\n",
    "                write_csv(data_dir/\"train.csv\", train_data)\n",
    "                write_csv(data_dir/\"dev.csv\", dev_data)\n",
    "                write_csv(data_dir/\"test.csv\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN NPZ/NPY data generation\n",
    "\n",
    "def encode_sequence(sequence, residue_map = {'A':0,'U':1,'T':1,'C':2,'G':3,'I':4}): # TODO should I be included?\n",
    "    seq_array = np.array([residue_map[i] for i in sequence if i in residue_map.keys()])\n",
    "    encoded_array = np.zeros((seq_array.size, 5), dtype=int)\n",
    "    encoded_array[np.arange(seq_array.size), seq_array] = 1\n",
    "    return encoded_array\n",
    "\n",
    "def make_npzs():\n",
    "    dirs = [filename for filename in os.listdir(\"./\") if os.path.isdir(f\"./{filename}\")]\n",
    "    for dir in dirs:\n",
    "        csvs = [filename.split(\".\")[0] for filename in os.listdir(dir) if filename.endswith(\".csv\")]\n",
    "        for csv in csvs:\n",
    "            data = pd.read_csv(f\"{dir}/{csv}.csv\", sep=\",\")\n",
    "            sequences = data[\"sequence\"].tolist()\n",
    "            labels = data[\"label\"].astype(int).tolist()\n",
    "            encoded_matrices = [encode_sequence(i) for i in sequences]\n",
    "            np.savez(f\"{dir}/{csv}_matrices.npz\", np.array(encoded_matrices))\n",
    "            np.save(f\"{dir}/{csv}_labels.npy\", labels)\n",
    "\n",
    "make_npzs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 4991\tTetraloops: 4991 (100.0)\tDecoys: 0 (0.0)\n"
     ]
    }
   ],
   "source": [
    "# all = len(entries)\n",
    "# decoys = len([i for i in entries if i.clust_id == 0])\n",
    "# tloops = len([i for i in entries if i.clust_id != 0])\n",
    "# print(f\"All: {all}\\tTetraloops: {tloops} ({tloops/all*100:.4})\\tDecoys: {decoys} ({decoys/all*100:.4})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
