{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "fragments_dir = Path('../data/fragments/')\n",
    "\n",
    "# Load fragment data\n",
    "fragments_8 = utils.load(fragments_dir/'fragments_8_filtered.pickle')\n",
    "fragments_10 = utils.load(fragments_dir/'fragments_10_filtered.pickle')\n",
    "fragments_12 = utils.load(fragments_dir/'fragments_12_filtered.pickle')\n",
    "fragments_14 = utils.load(fragments_dir/'fragments_14_filtered.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 4991\tTetraloops: 4991 (100.0)\tDecoys: 0 (0.0)\n"
     ]
    }
   ],
   "source": [
    "# all = len(entries)\n",
    "# decoys = len([i for i in entries if i.clust_id == 0])\n",
    "# tloops = len([i for i in entries if i.clust_id != 0])\n",
    "# print(f\"All: {all}\\tTetraloops: {tloops} ({tloops/all*100:.4})\\tDecoys: {decoys} ({decoys/all*100:.4})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(path, data): # Data entries should be formatted as (sequence, label) tuple\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(\"sequence,label\\n\")\n",
    "        for entry in data:\n",
    "            f.write(f\"{entry[0]},{entry[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, train_ratio = 0.8):\n",
    "    train_cutoff = int(len(data) * train_ratio)\n",
    "    dev_ratio = (1-train_ratio)/2\n",
    "    dev_cutoff = int(len(data) * (1-dev_ratio))\n",
    "    \n",
    "    train_data = data[:train_cutoff]\n",
    "    dev_data = data[train_cutoff:dev_cutoff]\n",
    "    test_data = data[dev_cutoff:]\n",
    "    return train_data, dev_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DNABERT2 finetuning CSV generation\n",
    "# for task in [\"gnra\"]:\n",
    "#     for fragment_length in [8, 10, 12, 14]:\n",
    "#         for train_ratio in [0.8]:\n",
    "#             for nucleotides in [\"T\", \"U\"]:\n",
    "#                 data_dir = Path(f\"{task}_{fragment_length}_{int(train_ratio*100)}_{nucleotides}/\")\n",
    "#                 if data_dir.exists():\n",
    "#                     shutil.rmtree(data_dir)\n",
    "#                 data_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "#                 # fragment_length\n",
    "#                 fragments = {8: fragments_8, 10: fragments_10, 12: fragments_12, 14: fragments_14}[fragment_length]\n",
    "\n",
    "#                 # task\n",
    "#                 if task == \"gnra\":\n",
    "#                     data = [i for i in fragments if i.clust_id != 0]\n",
    "#                     data = [(i.res_seq, 1) if i.clust_id == 1 else (i.res_seq, 0) for i in fragments]\n",
    "#                 elif task == \"all\":\n",
    "#                     data = [(i.res_seq, i.clust_id) for i in fragments]\n",
    "#                 random.shuffle(data)\n",
    "                \n",
    "#                 # nucleotides\n",
    "#                 if nucleotides == \"T\":\n",
    "#                     data = [(i.replace(\"U\",\"T\"), j) for i, j in data]\n",
    "                \n",
    "#                 # split_data(train_ratio)\n",
    "#                 train_data, dev_data, test_data = split_data(data, train_ratio)\n",
    "\n",
    "#                 write_csv(data_dir/\"train.csv\", train_data)\n",
    "#                 write_csv(data_dir/\"dev.csv\", dev_data)\n",
    "#                 write_csv(data_dir/\"test.csv\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN NPZ/NPY data generation\n",
    "# TODO this it the .npz data generation\n",
    "\n",
    "# Make train and test set.\n",
    "test_matrices = []; test_labels = []\n",
    "dev_matrices = []; dev_labels = []\n",
    "train_matrices = []; train_labels = []\n",
    "\n",
    "#read file\n",
    "all_loops = pd.read_csv('14_Data/14_filtered_rna_sequences_with_cluster0.csv', sep=\",\")\n",
    "\n",
    "#remove \",\" from the RNA sequence\n",
    "all_loops['RNA_Sequence'] = all_loops['RNA_Sequence'].str.replace(',', '')\n",
    "\n",
    "#remove non-alphabeticals\n",
    "#all_loops = all_loops[all_loops['values'].str.isalpha()]\n",
    "#print(all_loops.head(20))\n",
    "\n",
    "#exclude cluster 0\n",
    "all_loops = all_loops[all_loops['Cluster_ID'] != 0]\n",
    "print(all_loops.tail(20))\n",
    "#all_loops.to_csv('14_Data/14_filtered_rna_sequences_without_cluster0.csv')\n",
    "\n",
    "#label all GRNA as 1 and others as 0\n",
    "all_loops['Label'] = all_loops['Cluster_ID'].apply(lambda x: 1 if x == 1 else 0)\n",
    "print(all_loops.head(20))\n",
    "\n",
    "#convert RNA_sequence and Label to lists\n",
    "seq14_list = all_loops['RNA_Sequence'].values.tolist()\n",
    "label_list = all_loops['Label'].values.tolist()\n",
    "\n",
    "#create training and testing dataset with annotation\n",
    "def make_noAnno_seqmatrix_one_hot(seq_list, labels):\n",
    "    matrices_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for seq14, label in zip(seq_list, labels):\n",
    "        seqmatrix_one_hot = np.zeros([14, 4])\n",
    "        for i in range(14):\n",
    "            if seq14[i] == 'A':\n",
    "                seqmatrix_one_hot[i, 0] = 1\n",
    "            elif seq14[i] == 'U':\n",
    "                seqmatrix_one_hot[i, 1] = 1\n",
    "            elif seq14[i] == 'C':\n",
    "                seqmatrix_one_hot[i, 2] = 1\n",
    "            elif seq14[i] == 'G':\n",
    "                seqmatrix_one_hot[i, 3] = 1\n",
    "            else:\n",
    "                print(seq14[i])\n",
    "\n",
    "        matrices_list.append(seqmatrix_one_hot)\n",
    "        labels_list.append(label)\n",
    "\n",
    "    combined = list(zip(matrices_list, labels_list))\n",
    "    random.shuffle(combined)\n",
    "    matrices_shuffled, labels_shuffled = zip(*combined)\n",
    "\n",
    "    test_matrices = []\n",
    "    test_labels = []\n",
    "    train_matrices = []\n",
    "    train_labels = []\n",
    "\n",
    "    for i, (matrix, label) in enumerate(zip(matrices_shuffled, labels_shuffled)):\n",
    "        if i % 3 == 0:\n",
    "            test_matrices.append(matrix)\n",
    "            test_labels.append(label)\n",
    "        else:\n",
    "            train_matrices.append(matrix)\n",
    "            train_labels.append(label)\n",
    "\n",
    "    return test_matrices, test_labels, train_matrices, train_labels\n",
    "\n",
    "print(len(test_matrices), len(test_labels))\n",
    "print(len(train_matrices), len(train_labels))\n",
    "\n",
    "test_matrices, test_labels, train_matrices, train_labels = make_noAnno_seqmatrix_one_hot(seq14_list, label_list)\n",
    "\n",
    "print(len(test_matrices), len(test_labels))\n",
    "print(len(train_matrices), len(train_labels))\n",
    "\n",
    "print(test_labels)\n",
    "print(set(test_labels))\n",
    "#print(test_matrices)\n",
    "print('--------------------')\n",
    "print(set(train_labels))\n",
    "print(train_labels)\n",
    "#print(train_matrices)\n",
    "\n",
    "np.savez('14_Data/GNRA_Prediction/noAnno_test_14_nucleotide_array_without_cluster0.npz', np.array(test_matrices))\n",
    "np.savez('14_Data/GNRA_Prediction/noAnno_train_14_nucleotide_array_without_cluster0.npz', np.array(train_matrices))\n",
    "\n",
    "np.save('14_Data/GNRA_Prediction/noAnno_test_14_nucleotide_labels_without_cluster0.npy', test_labels)\n",
    "np.save('14_Data/GNRA_Prediction/noAnno_train_14_nucleotide_labels_without_cluster0.npy', train_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
