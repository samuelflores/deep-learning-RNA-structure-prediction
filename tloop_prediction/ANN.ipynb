{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aef19d0-9369-45f7-81aa-d7ca27ca925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 12:01:25.676498: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "# standard libraries\n",
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# standard scientific libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import asarray, save, load\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv1D, Conv2D, MaxPooling2D, Dropout, Flatten, Input, MaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical, set_random_seed\n",
    "\n",
    "# If using TensorFlow, this will make GPU ops as deterministic as possible, but it will affect the overall performance, so be mindful of that.\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf891565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(DATA_DIR, RESULTS_DIR, PREFIX = \"\", SUFFIX=\"\", MODEL_TYPE = \"convolutional\", NUM_CLASSES = 0, SEED=42, EPOCHS = 100, BATCH_SIZE = 16, LEARNING_RATE = 1e-3, PATIENCE = 10):\n",
    "\n",
    "    # 1. Data\n",
    "\n",
    "    # 1.1. Specify directories\n",
    "    DATA_DIR = Path(DATA_DIR)\n",
    "    SET_NAME = str(DATA_DIR).split(\"/\")[-1]\n",
    "    RESULTS_FILE = RESULTS_DIR / (PREFIX + SET_NAME + SUFFIX)\n",
    "    print(f\"\\nTraining {SET_NAME}, results will be saved into {RESULTS_FILE}\\n\")\n",
    "    \n",
    "    # 1.2. Load datasets\n",
    "    x_train_dict = np.load(DATA_DIR/\"train_matrices.npz\", allow_pickle=True)\n",
    "    y_train_arr = np.load(DATA_DIR/\"train_labels.npy\", allow_pickle=True)\n",
    "    x_dev_dict = np.load(DATA_DIR/\"dev_matrices.npz\", allow_pickle=True)\n",
    "    y_dev_arr = np.load(DATA_DIR/\"dev_labels.npy\", allow_pickle=True)\n",
    "\n",
    "    # 1.3. Define NUM_CLASSES\n",
    "    if not NUM_CLASSES: NUM_CLASSES = len(set(y_train_arr))\n",
    "    print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "    \n",
    "    # 1.4. Convert discontinuous label values to continuous values\n",
    "    # This is required for the folds datasets, which have missing numbers in the middle\n",
    "    #! Don't forget to take this into account in the results!\n",
    "    conversion_dict = dict(zip(set(y_train_arr), range(NUM_CLASSES)))\n",
    "    y_train_arr = [conversion_dict[i] for i in y_train_arr]\n",
    "    y_dev_arr = [conversion_dict[i] for i in y_dev_arr]\n",
    "    \n",
    "    # 1.5. Make X and Y TRAIN and DEV sets\n",
    "    X_TRAIN = np.stack(x_train_dict['arr_0'], axis=0)\n",
    "    X_DEV = np.stack(x_dev_dict['arr_0'], axis=0)\n",
    "    Y_TRAIN = to_categorical(y_train_arr, num_classes=NUM_CLASSES)\n",
    "    Y_DEV = to_categorical(y_dev_arr, num_classes=NUM_CLASSES)\n",
    "    print(f\"Training features shape: {X_TRAIN.shape} labels shape: {Y_TRAIN.shape}\")\n",
    "    print(f\"Validation features shape: {X_DEV.shape} labels shape: {Y_DEV.shape}\")\n",
    "\n",
    "    # 1.6. Define INPUT_SHAPE\n",
    "    INPUT_SHAPE = X_TRAIN.shape[1:]\n",
    "    INPUT_LENGTH = INPUT_SHAPE[0]\n",
    "    INPUT_SIZE = INPUT_SHAPE[0] * INPUT_SHAPE[1]\n",
    "    print(f\"Input shape: {INPUT_SHAPE}\")\n",
    "    \n",
    "    # 1.7. Calculate class weights\n",
    "    CLASS_WEIGHTS = np.round(class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_arr), y=y_train_arr), 2)\n",
    "    CLASS_WEIGHTS = dict(enumerate(CLASS_WEIGHTS))\n",
    "\n",
    "    # 2. Model\n",
    "\n",
    "    # 2.1. Define metrics\n",
    "    METRICS = [\n",
    "        keras.metrics.TruePositives(name = 'tp'),\n",
    "        keras.metrics.FalsePositives(name = 'fp'),\n",
    "        keras.metrics.TrueNegatives(name = 'tn'),\n",
    "        keras.metrics.FalseNegatives(name = 'fn'),\n",
    "        #// keras.metrics.BinaryAccuracy(name = 'accuracy'), # TODO remove this?\n",
    "        keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name = 'precision'),\n",
    "        keras.metrics.Recall(name = 'recall'),\n",
    "        keras.metrics.AUC(name = 'auc', curve='roc'),\n",
    "        keras.metrics.AUC(name = 'prc', curve = 'PR'),\n",
    "        tfa.metrics.F1Score(name = 'f1', num_classes = NUM_CLASSES),\n",
    "        tfa.metrics.MatthewsCorrelationCoefficient(name = 'mcc', num_classes = NUM_CLASSES)\n",
    "    ]\n",
    "    \n",
    "    # 2.2. Set seed\n",
    "    set_random_seed(SEED)\n",
    "    \n",
    "    # 2.3. Construct model\n",
    "    model = Sequential()\n",
    "    match MODEL_TYPE:\n",
    "        case \"benchmark\":\n",
    "            # This is just a single-layer dense network.\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(INPUT_SIZE, activation = \"relu\", kernel_initializer='he_normal'))\n",
    "            model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "        case \"convolutional\":\n",
    "            # NOTE: kernel = n*n matrix, filter = collection of (convolved) feature maps from all input channels (depth). Output size is therefore H'*w'*filters\n",
    "            # kernel_intializer: he_normal used for ReLU layers, otherwise standard (glorot_uniform)\n",
    "            # The following architecture is a pretty standard image classification architecture, with extra dropouts in the middle\n",
    "            model.add(Conv1D(\n",
    "                16, 3,\n",
    "                activation='relu',\n",
    "                padding='same',\n",
    "                input_shape = INPUT_SHAPE,\n",
    "                kernel_initializer = 'he_normal'))\n",
    "            model.add(MaxPooling1D(pool_size = 2, strides = 2))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Conv1D(\n",
    "                32, 3,\n",
    "                activation = 'relu',\n",
    "                padding = 'same',\n",
    "                kernel_initializer = 'he_normal'))\n",
    "            model.add(MaxPooling1D(pool_size = 2, strides = 2))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(\n",
    "                INPUT_LENGTH * 16,\n",
    "                activation = 'relu',\n",
    "                kernel_initializer='he_normal'))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(\n",
    "                NUM_CLASSES,\n",
    "                activation = 'softmax'))\n",
    "        case \"convolutional_simple\":\n",
    "            # NOTE: kernel = n*n matrix, filter = collection of (convolved) feature maps from all input channels (depth). Output size is therefore H'*w'*filters\n",
    "            # kernel_intializer: he_normal used for ReLU layers, otherwise standard (glorot_uniform)\n",
    "            # The following architecture is a pretty standard image classification architecture, with extra dropouts in the middle\n",
    "            model.add(Conv1D(\n",
    "                16, 3,\n",
    "                activation='relu',\n",
    "                padding='same',\n",
    "                input_shape = INPUT_SHAPE,\n",
    "                kernel_initializer = 'he_normal'))\n",
    "            model.add(MaxPooling1D(pool_size = 2, strides = 2))\n",
    "            model.add(Conv1D(\n",
    "                32, 3,\n",
    "                activation = 'relu',\n",
    "                padding = 'same',\n",
    "                kernel_initializer = 'he_normal'))\n",
    "            model.add(MaxPooling1D(pool_size = 2, strides = 2))\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(\n",
    "                32,\n",
    "                activation = 'relu',\n",
    "                kernel_initializer='he_normal'))\n",
    "            model.add(Dense(\n",
    "                NUM_CLASSES,\n",
    "                activation = 'softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    # 2.4. Compile model\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = LEARNING_RATE),  # optimizer=RMSprop(lr=0.001),\n",
    "        loss = keras.losses.CategoricalCrossentropy(),\n",
    "        metrics = METRICS)\n",
    "\n",
    "    # 2.5. Define early stopping\n",
    "    EARLY_STOPPING = keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)\n",
    "    \n",
    "    # 2.6. Train\n",
    "    history = model.fit(\n",
    "        X_TRAIN,\n",
    "        Y_TRAIN,\n",
    "        validation_data = (X_DEV, Y_DEV),\n",
    "        batch_size = BATCH_SIZE,\n",
    "        epochs = EPOCHS,\n",
    "        callbacks=[EARLY_STOPPING],\n",
    "        class_weight = CLASS_WEIGHTS\n",
    "    )\n",
    "    \n",
    "    # 2.7. Save model\n",
    "    model.save(RESULTS_FILE, overwrite=True)\n",
    "    \n",
    "    # 2.8. Save model history\n",
    "    with open(RESULTS_FILE/\"history\", \"wb\") as file:\n",
    "        pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5a9f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training uncg_18, results will be saved into results/622/uncg_18_1\n",
      "\n",
      "Number of classes: 2\n",
      "Training features shape: (334, 18, 6) labels shape: (334, 2)\n",
      "Validation features shape: (113, 18, 6) labels shape: (113, 2)\n",
      "Input shape: (18, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 12:02:18.115018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38551 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:e3:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 18, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 9, 16)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 9, 16)             0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 9, 32)             1568      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 4, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4, 32)             0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 288)               37152     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 288)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 578       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,602\n",
      "Trainable params: 39,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 12:02:21.633520: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n",
      "2024-11-22 12:02:22.501516: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 5s 49ms/step - loss: 0.7443 - tp: 178.0000 - fp: 156.0000 - tn: 178.0000 - fn: 156.0000 - accuracy: 0.5329 - precision: 0.5329 - recall: 0.5329 - auc: 0.5320 - prc: 0.5332 - f1: 0.4525 - mcc: 0.0866 - val_loss: 0.4910 - val_tp: 98.0000 - val_fp: 15.0000 - val_tn: 98.0000 - val_fn: 15.0000 - val_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673 - val_auc: 0.9341 - val_prc: 0.9322 - val_f1: 0.7464 - val_mcc: 0.5109\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.5215 - tp: 276.0000 - fp: 58.0000 - tn: 276.0000 - fn: 58.0000 - accuracy: 0.8263 - precision: 0.8263 - recall: 0.8263 - auc: 0.9042 - prc: 0.8980 - f1: 0.6889 - mcc: 0.4078 - val_loss: 0.5237 - val_tp: 88.0000 - val_fp: 25.0000 - val_tn: 88.0000 - val_fn: 25.0000 - val_accuracy: 0.7788 - val_precision: 0.7788 - val_recall: 0.7788 - val_auc: 0.8430 - val_prc: 0.8156 - val_f1: 0.6835 - val_mcc: 0.4817\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3884 - tp: 290.0000 - fp: 44.0000 - tn: 290.0000 - fn: 44.0000 - accuracy: 0.8683 - precision: 0.8683 - recall: 0.8683 - auc: 0.9278 - prc: 0.9245 - f1: 0.7673 - mcc: 0.5749 - val_loss: 0.3640 - val_tp: 96.0000 - val_fp: 17.0000 - val_tn: 96.0000 - val_fn: 17.0000 - val_accuracy: 0.8496 - val_precision: 0.8496 - val_recall: 0.8496 - val_auc: 0.9265 - val_prc: 0.9105 - val_f1: 0.7559 - val_mcc: 0.5785\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3343 - tp: 282.0000 - fp: 52.0000 - tn: 282.0000 - fn: 52.0000 - accuracy: 0.8443 - precision: 0.8443 - recall: 0.8443 - auc: 0.9321 - prc: 0.9289 - f1: 0.7393 - mcc: 0.5334 - val_loss: 0.4282 - val_tp: 91.0000 - val_fp: 22.0000 - val_tn: 91.0000 - val_fn: 22.0000 - val_accuracy: 0.8053 - val_precision: 0.8053 - val_recall: 0.8053 - val_auc: 0.8897 - val_prc: 0.8703 - val_f1: 0.7090 - val_mcc: 0.5147\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3293 - tp: 288.0000 - fp: 46.0000 - tn: 288.0000 - fn: 46.0000 - accuracy: 0.8623 - precision: 0.8623 - recall: 0.8623 - auc: 0.9347 - prc: 0.9327 - f1: 0.7601 - mcc: 0.5640 - val_loss: 0.2430 - val_tp: 100.0000 - val_fp: 13.0000 - val_tn: 100.0000 - val_fn: 13.0000 - val_accuracy: 0.8850 - val_precision: 0.8850 - val_recall: 0.8850 - val_auc: 0.9659 - val_prc: 0.9670 - val_f1: 0.7803 - val_mcc: 0.5799\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2997 - tp: 295.0000 - fp: 39.0000 - tn: 295.0000 - fn: 39.0000 - accuracy: 0.8832 - precision: 0.8832 - recall: 0.8832 - auc: 0.9584 - prc: 0.9592 - f1: 0.7830 - mcc: 0.5934 - val_loss: 0.4543 - val_tp: 91.0000 - val_fp: 22.0000 - val_tn: 91.0000 - val_fn: 22.0000 - val_accuracy: 0.8053 - val_precision: 0.8053 - val_recall: 0.8053 - val_auc: 0.8825 - val_prc: 0.8616 - val_f1: 0.7090 - val_mcc: 0.5147\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2802 - tp: 290.0000 - fp: 44.0000 - tn: 290.0000 - fn: 44.0000 - accuracy: 0.8683 - precision: 0.8683 - recall: 0.8683 - auc: 0.9265 - prc: 0.9203 - f1: 0.7765 - mcc: 0.6077 - val_loss: 0.2961 - val_tp: 97.0000 - val_fp: 16.0000 - val_tn: 97.0000 - val_fn: 16.0000 - val_accuracy: 0.8584 - val_precision: 0.8584 - val_recall: 0.8584 - val_auc: 0.9464 - val_prc: 0.9469 - val_f1: 0.7660 - val_mcc: 0.5930\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3405 - tp: 302.0000 - fp: 32.0000 - tn: 302.0000 - fn: 32.0000 - accuracy: 0.9042 - precision: 0.9042 - recall: 0.9042 - auc: 0.9344 - prc: 0.9208 - f1: 0.8233 - mcc: 0.6784 - val_loss: 0.3124 - val_tp: 96.0000 - val_fp: 17.0000 - val_tn: 96.0000 - val_fn: 17.0000 - val_accuracy: 0.8496 - val_precision: 0.8496 - val_recall: 0.8496 - val_auc: 0.9421 - val_prc: 0.9431 - val_f1: 0.7559 - val_mcc: 0.5785\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2265 - tp: 304.0000 - fp: 30.0000 - tn: 304.0000 - fn: 30.0000 - accuracy: 0.9102 - precision: 0.9102 - recall: 0.9102 - auc: 0.9618 - prc: 0.9603 - f1: 0.8318 - mcc: 0.6919 - val_loss: 0.2422 - val_tp: 102.0000 - val_fp: 11.0000 - val_tn: 102.0000 - val_fn: 11.0000 - val_accuracy: 0.9027 - val_precision: 0.9027 - val_recall: 0.9027 - val_auc: 0.9647 - val_prc: 0.9662 - val_f1: 0.8223 - val_mcc: 0.6772\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2510 - tp: 302.0000 - fp: 32.0000 - tn: 302.0000 - fn: 32.0000 - accuracy: 0.9042 - precision: 0.9042 - recall: 0.9042 - auc: 0.9670 - prc: 0.9636 - f1: 0.8149 - mcc: 0.6497 - val_loss: 0.3590 - val_tp: 93.0000 - val_fp: 20.0000 - val_tn: 93.0000 - val_fn: 20.0000 - val_accuracy: 0.8230 - val_precision: 0.8230 - val_recall: 0.8230 - val_auc: 0.9258 - val_prc: 0.9290 - val_f1: 0.7271 - val_mcc: 0.5387\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2309 - tp: 294.0000 - fp: 40.0000 - tn: 294.0000 - fn: 40.0000 - accuracy: 0.8802 - precision: 0.8802 - recall: 0.8802 - auc: 0.9491 - prc: 0.9469 - f1: 0.7941 - mcc: 0.6401 - val_loss: 0.1948 - val_tp: 104.0000 - val_fp: 9.0000 - val_tn: 104.0000 - val_fn: 9.0000 - val_accuracy: 0.9204 - val_precision: 0.9204 - val_recall: 0.9204 - val_auc: 0.9775 - val_prc: 0.9785 - val_f1: 0.8479 - val_mcc: 0.7180\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2365 - tp: 305.0000 - fp: 29.0000 - tn: 305.0000 - fn: 29.0000 - accuracy: 0.9132 - precision: 0.9132 - recall: 0.9132 - auc: 0.9721 - prc: 0.9727 - f1: 0.8309 - mcc: 0.6806 - val_loss: 0.4229 - val_tp: 89.0000 - val_fp: 24.0000 - val_tn: 89.0000 - val_fn: 24.0000 - val_accuracy: 0.7876 - val_precision: 0.7876 - val_recall: 0.7876 - val_auc: 0.9041 - val_prc: 0.9070 - val_f1: 0.6918 - val_mcc: 0.4923\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2385 - tp: 301.0000 - fp: 33.0000 - tn: 301.0000 - fn: 33.0000 - accuracy: 0.9012 - precision: 0.9012 - recall: 0.9012 - auc: 0.9631 - prc: 0.9637 - f1: 0.8164 - mcc: 0.6621 - val_loss: 0.2401 - val_tp: 102.0000 - val_fp: 11.0000 - val_tn: 102.0000 - val_fn: 11.0000 - val_accuracy: 0.9027 - val_precision: 0.9027 - val_recall: 0.9027 - val_auc: 0.9673 - val_prc: 0.9689 - val_f1: 0.8223 - val_mcc: 0.6772\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1897 - tp: 307.0000 - fp: 27.0000 - tn: 307.0000 - fn: 27.0000 - accuracy: 0.9192 - precision: 0.9192 - recall: 0.9192 - auc: 0.9616 - prc: 0.9563 - f1: 0.8474 - mcc: 0.7220 - val_loss: 0.2317 - val_tp: 102.0000 - val_fp: 11.0000 - val_tn: 102.0000 - val_fn: 11.0000 - val_accuracy: 0.9027 - val_precision: 0.9027 - val_recall: 0.9027 - val_auc: 0.9689 - val_prc: 0.9705 - val_f1: 0.8223 - val_mcc: 0.6772\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1694 - tp: 312.0000 - fp: 22.0000 - tn: 312.0000 - fn: 22.0000 - accuracy: 0.9341 - precision: 0.9341 - recall: 0.9341 - auc: 0.9759 - prc: 0.9728 - f1: 0.8685 - mcc: 0.7519 - val_loss: 0.2911 - val_tp: 99.0000 - val_fp: 14.0000 - val_tn: 99.0000 - val_fn: 14.0000 - val_accuracy: 0.8761 - val_precision: 0.8761 - val_recall: 0.8761 - val_auc: 0.9509 - val_prc: 0.9535 - val_f1: 0.7874 - val_mcc: 0.6241\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1502 - tp: 307.0000 - fp: 27.0000 - tn: 307.0000 - fn: 27.0000 - accuracy: 0.9192 - precision: 0.9192 - recall: 0.9192 - auc: 0.9843 - prc: 0.9850 - f1: 0.8498 - mcc: 0.7309 - val_loss: 0.1847 - val_tp: 104.0000 - val_fp: 9.0000 - val_tn: 104.0000 - val_fn: 9.0000 - val_accuracy: 0.9204 - val_precision: 0.9204 - val_recall: 0.9204 - val_auc: 0.9807 - val_prc: 0.9814 - val_f1: 0.8403 - val_mcc: 0.6928\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1698 - tp: 312.0000 - fp: 22.0000 - tn: 312.0000 - fn: 22.0000 - accuracy: 0.9341 - precision: 0.9341 - recall: 0.9341 - auc: 0.9757 - prc: 0.9759 - f1: 0.8706 - mcc: 0.7598 - val_loss: 0.2693 - val_tp: 100.0000 - val_fp: 13.0000 - val_tn: 100.0000 - val_fn: 13.0000 - val_accuracy: 0.8850 - val_precision: 0.8850 - val_recall: 0.8850 - val_auc: 0.9605 - val_prc: 0.9625 - val_f1: 0.7986 - val_mcc: 0.6408\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1496 - tp: 314.0000 - fp: 20.0000 - tn: 314.0000 - fn: 20.0000 - accuracy: 0.9401 - precision: 0.9401 - recall: 0.9401 - auc: 0.9833 - prc: 0.9839 - f1: 0.8784 - mcc: 0.7687 - val_loss: 0.2578 - val_tp: 100.0000 - val_fp: 13.0000 - val_tn: 100.0000 - val_fn: 13.0000 - val_accuracy: 0.8850 - val_precision: 0.8850 - val_recall: 0.8850 - val_auc: 0.9619 - val_prc: 0.9640 - val_f1: 0.7986 - val_mcc: 0.6408\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1590 - tp: 318.0000 - fp: 16.0000 - tn: 318.0000 - fn: 16.0000 - accuracy: 0.9521 - precision: 0.9521 - recall: 0.9521 - auc: 0.9818 - prc: 0.9801 - f1: 0.9010 - mcc: 0.8114 - val_loss: 0.2988 - val_tp: 98.0000 - val_fp: 15.0000 - val_tn: 98.0000 - val_fn: 15.0000 - val_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673 - val_auc: 0.9508 - val_prc: 0.9536 - val_f1: 0.7765 - val_mcc: 0.6082\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1253 - tp: 309.0000 - fp: 25.0000 - tn: 309.0000 - fn: 25.0000 - accuracy: 0.9251 - precision: 0.9251 - recall: 0.9251 - auc: 0.9848 - prc: 0.9833 - f1: 0.8587 - mcc: 0.7452 - val_loss: 0.2247 - val_tp: 101.0000 - val_fp: 12.0000 - val_tn: 101.0000 - val_fn: 12.0000 - val_accuracy: 0.8938 - val_precision: 0.8938 - val_recall: 0.8938 - val_auc: 0.9708 - val_prc: 0.9724 - val_f1: 0.8102 - val_mcc: 0.6585\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1709 - tp: 312.0000 - fp: 22.0000 - tn: 312.0000 - fn: 22.0000 - accuracy: 0.9341 - precision: 0.9341 - recall: 0.9341 - auc: 0.9827 - prc: 0.9811 - f1: 0.8706 - mcc: 0.7598 - val_loss: 0.3184 - val_tp: 96.0000 - val_fp: 17.0000 - val_tn: 96.0000 - val_fn: 17.0000 - val_accuracy: 0.8496 - val_precision: 0.8496 - val_recall: 0.8496 - val_auc: 0.9463 - val_prc: 0.9492 - val_f1: 0.7559 - val_mcc: 0.5785\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1605 - tp: 314.0000 - fp: 20.0000 - tn: 314.0000 - fn: 20.0000 - accuracy: 0.9401 - precision: 0.9401 - recall: 0.9401 - auc: 0.9845 - prc: 0.9850 - f1: 0.8784 - mcc: 0.7687 - val_loss: 0.2591 - val_tp: 101.0000 - val_fp: 12.0000 - val_tn: 101.0000 - val_fn: 12.0000 - val_accuracy: 0.8938 - val_precision: 0.8938 - val_recall: 0.8938 - val_auc: 0.9624 - val_prc: 0.9646 - val_f1: 0.8102 - val_mcc: 0.6585\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1345 - tp: 312.0000 - fp: 22.0000 - tn: 312.0000 - fn: 22.0000 - accuracy: 0.9341 - precision: 0.9341 - recall: 0.9341 - auc: 0.9813 - prc: 0.9818 - f1: 0.8706 - mcc: 0.7598 - val_loss: 0.2333 - val_tp: 103.0000 - val_fp: 10.0000 - val_tn: 103.0000 - val_fn: 10.0000 - val_accuracy: 0.9115 - val_precision: 0.9115 - val_recall: 0.9115 - val_auc: 0.9685 - val_prc: 0.9702 - val_f1: 0.8348 - val_mcc: 0.6970\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1035 - tp: 325.0000 - fp: 9.0000 - tn: 325.0000 - fn: 9.0000 - accuracy: 0.9731 - precision: 0.9731 - recall: 0.9731 - auc: 0.9909 - prc: 0.9893 - f1: 0.9428 - mcc: 0.8915 - val_loss: 0.2488 - val_tp: 102.0000 - val_fp: 11.0000 - val_tn: 102.0000 - val_fn: 11.0000 - val_accuracy: 0.9027 - val_precision: 0.9027 - val_recall: 0.9027 - val_auc: 0.9675 - val_prc: 0.9692 - val_f1: 0.8223 - val_mcc: 0.6772\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1146 - tp: 315.0000 - fp: 19.0000 - tn: 315.0000 - fn: 19.0000 - accuracy: 0.9431 - precision: 0.9431 - recall: 0.9431 - auc: 0.9924 - prc: 0.9927 - f1: 0.8834 - mcc: 0.7775 - val_loss: 0.2526 - val_tp: 103.0000 - val_fp: 10.0000 - val_tn: 103.0000 - val_fn: 10.0000 - val_accuracy: 0.9115 - val_precision: 0.9115 - val_recall: 0.9115 - val_auc: 0.9662 - val_prc: 0.9680 - val_f1: 0.8348 - val_mcc: 0.6970\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0758 - tp: 323.0000 - fp: 11.0000 - tn: 323.0000 - fn: 11.0000 - accuracy: 0.9671 - precision: 0.9671 - recall: 0.9671 - auc: 0.9932 - prc: 0.9934 - f1: 0.9313 - mcc: 0.8711 - val_loss: 0.2239 - val_tp: 103.0000 - val_fp: 10.0000 - val_tn: 103.0000 - val_fn: 10.0000 - val_accuracy: 0.9115 - val_precision: 0.9115 - val_recall: 0.9115 - val_auc: 0.9740 - val_prc: 0.9752 - val_f1: 0.8348 - val_mcc: 0.6970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: results/622/uncg_18_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training uncg_18, results will be saved into results/622/uncg_18_2\n",
      "\n",
      "Number of classes: 2\n",
      "Training features shape: (334, 18, 6) labels shape: (334, 2)\n",
      "Validation features shape: (113, 18, 6) labels shape: (113, 2)\n",
      "Input shape: (18, 6)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 18, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 9, 16)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 9, 16)             0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 9, 32)             1568      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 4, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4, 32)             0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 288)               37152     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 288)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 578       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,602\n",
      "Trainable params: 39,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - 3s 46ms/step - loss: 0.9102 - tp: 197.0000 - fp: 137.0000 - tn: 197.0000 - fn: 137.0000 - accuracy: 0.5898 - precision: 0.5898 - recall: 0.5898 - auc: 0.6894 - prc: 0.6850 - f1: 0.4809 - mcc: 0.0890 - val_loss: 0.8923 - val_tp: 40.0000 - val_fp: 73.0000 - val_tn: 40.0000 - val_fn: 73.0000 - val_accuracy: 0.3540 - val_precision: 0.3540 - val_recall: 0.3540 - val_auc: 0.3387 - val_prc: 0.4542 - val_f1: 0.3466 - val_mcc: 0.2056\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.4991 - tp: 255.0000 - fp: 79.0000 - tn: 255.0000 - fn: 79.0000 - accuracy: 0.7635 - precision: 0.7635 - recall: 0.7635 - auc: 0.8688 - prc: 0.8679 - f1: 0.6292 - mcc: 0.3208 - val_loss: 0.5136 - val_tp: 83.0000 - val_fp: 30.0000 - val_tn: 83.0000 - val_fn: 30.0000 - val_accuracy: 0.7345 - val_precision: 0.7345 - val_recall: 0.7345 - val_auc: 0.8338 - val_prc: 0.8341 - val_f1: 0.6439 - val_mcc: 0.4334\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.4596 - tp: 245.0000 - fp: 89.0000 - tn: 245.0000 - fn: 89.0000 - accuracy: 0.7335 - precision: 0.7335 - recall: 0.7335 - auc: 0.8071 - prc: 0.8027 - f1: 0.6295 - mcc: 0.3787 - val_loss: 0.3038 - val_tp: 102.0000 - val_fp: 11.0000 - val_tn: 102.0000 - val_fn: 11.0000 - val_accuracy: 0.9027 - val_precision: 0.9027 - val_recall: 0.9027 - val_auc: 0.9646 - val_prc: 0.9658 - val_f1: 0.8223 - val_mcc: 0.6772\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3856 - tp: 294.0000 - fp: 40.0000 - tn: 294.0000 - fn: 40.0000 - accuracy: 0.8802 - precision: 0.8802 - recall: 0.8802 - auc: 0.9305 - prc: 0.9311 - f1: 0.7791 - mcc: 0.5873 - val_loss: 0.4259 - val_tp: 91.0000 - val_fp: 22.0000 - val_tn: 91.0000 - val_fn: 22.0000 - val_accuracy: 0.8053 - val_precision: 0.8053 - val_recall: 0.8053 - val_auc: 0.8828 - val_prc: 0.8835 - val_f1: 0.7175 - val_mcc: 0.5500\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3377 - tp: 298.0000 - fp: 36.0000 - tn: 298.0000 - fn: 36.0000 - accuracy: 0.8922 - precision: 0.8922 - recall: 0.8922 - auc: 0.9396 - prc: 0.9347 - f1: 0.7982 - mcc: 0.6227 - val_loss: 0.3311 - val_tp: 97.0000 - val_fp: 16.0000 - val_tn: 97.0000 - val_fn: 16.0000 - val_accuracy: 0.8584 - val_precision: 0.8584 - val_recall: 0.8584 - val_auc: 0.9385 - val_prc: 0.9395 - val_f1: 0.7742 - val_mcc: 0.6255\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3293 - tp: 276.0000 - fp: 58.0000 - tn: 276.0000 - fn: 58.0000 - accuracy: 0.8263 - precision: 0.8263 - recall: 0.8263 - auc: 0.9192 - prc: 0.9111 - f1: 0.7163 - mcc: 0.4936 - val_loss: 0.2468 - val_tp: 104.0000 - val_fp: 9.0000 - val_tn: 104.0000 - val_fn: 9.0000 - val_accuracy: 0.9204 - val_precision: 0.9204 - val_recall: 0.9204 - val_auc: 0.9668 - val_prc: 0.9672 - val_f1: 0.8479 - val_mcc: 0.7180\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2489 - tp: 311.0000 - fp: 23.0000 - tn: 311.0000 - fn: 23.0000 - accuracy: 0.9311 - precision: 0.9311 - recall: 0.9311 - auc: 0.9698 - prc: 0.9693 - f1: 0.8636 - mcc: 0.7438 - val_loss: 0.3494 - val_tp: 98.0000 - val_fp: 15.0000 - val_tn: 98.0000 - val_fn: 15.0000 - val_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673 - val_auc: 0.9271 - val_prc: 0.9277 - val_f1: 0.7846 - val_mcc: 0.6400\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3107 - tp: 290.0000 - fp: 44.0000 - tn: 290.0000 - fn: 44.0000 - accuracy: 0.8683 - precision: 0.8683 - recall: 0.8683 - auc: 0.9391 - prc: 0.9390 - f1: 0.7673 - mcc: 0.5749 - val_loss: 0.2949 - val_tp: 100.0000 - val_fp: 13.0000 - val_tn: 100.0000 - val_fn: 13.0000 - val_accuracy: 0.8850 - val_precision: 0.8850 - val_recall: 0.8850 - val_auc: 0.9483 - val_prc: 0.9486 - val_f1: 0.8063 - val_mcc: 0.6711\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2012 - tp: 300.0000 - fp: 34.0000 - tn: 300.0000 - fn: 34.0000 - accuracy: 0.8982 - precision: 0.8982 - recall: 0.8982 - auc: 0.9666 - prc: 0.9642 - f1: 0.8150 - mcc: 0.6655 - val_loss: 0.1533 - val_tp: 107.0000 - val_fp: 6.0000 - val_tn: 107.0000 - val_fn: 6.0000 - val_accuracy: 0.9469 - val_precision: 0.9469 - val_recall: 0.9469 - val_auc: 0.9861 - val_prc: 0.9866 - val_f1: 0.8908 - val_mcc: 0.7905\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2604 - tp: 301.0000 - fp: 33.0000 - tn: 301.0000 - fn: 33.0000 - accuracy: 0.9012 - precision: 0.9012 - recall: 0.9012 - auc: 0.9593 - prc: 0.9561 - f1: 0.8164 - mcc: 0.6621 - val_loss: 0.2458 - val_tp: 104.0000 - val_fp: 9.0000 - val_tn: 104.0000 - val_fn: 9.0000 - val_accuracy: 0.9204 - val_precision: 0.9204 - val_recall: 0.9204 - val_auc: 0.9632 - val_prc: 0.9636 - val_f1: 0.8546 - val_mcc: 0.7439\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1980 - tp: 300.0000 - fp: 34.0000 - tn: 300.0000 - fn: 34.0000 - accuracy: 0.8982 - precision: 0.8982 - recall: 0.8982 - auc: 0.9742 - prc: 0.9753 - f1: 0.8150 - mcc: 0.6655 - val_loss: 0.2035 - val_tp: 104.0000 - val_fp: 9.0000 - val_tn: 104.0000 - val_fn: 9.0000 - val_accuracy: 0.9204 - val_precision: 0.9204 - val_recall: 0.9204 - val_auc: 0.9739 - val_prc: 0.9745 - val_f1: 0.8479 - val_mcc: 0.7180\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2068 - tp: 308.0000 - fp: 26.0000 - tn: 308.0000 - fn: 26.0000 - accuracy: 0.9222 - precision: 0.9222 - recall: 0.9222 - auc: 0.9696 - prc: 0.9702 - f1: 0.8542 - mcc: 0.7379 - val_loss: 0.2274 - val_tp: 105.0000 - val_fp: 8.0000 - val_tn: 105.0000 - val_fn: 8.0000 - val_accuracy: 0.9292 - val_precision: 0.9292 - val_recall: 0.9292 - val_auc: 0.9688 - val_prc: 0.9693 - val_f1: 0.8678 - val_mcc: 0.7648\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2331 - tp: 306.0000 - fp: 28.0000 - tn: 306.0000 - fn: 28.0000 - accuracy: 0.9162 - precision: 0.9162 - recall: 0.9162 - auc: 0.9660 - prc: 0.9643 - f1: 0.8380 - mcc: 0.6969 - val_loss: 0.2769 - val_tp: 102.0000 - val_fp: 11.0000 - val_tn: 102.0000 - val_fn: 11.0000 - val_accuracy: 0.9027 - val_precision: 0.9027 - val_recall: 0.9027 - val_auc: 0.9559 - val_prc: 0.9567 - val_f1: 0.8296 - val_mcc: 0.7055\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2368 - tp: 305.0000 - fp: 29.0000 - tn: 305.0000 - fn: 29.0000 - accuracy: 0.9132 - precision: 0.9132 - recall: 0.9132 - auc: 0.9668 - prc: 0.9675 - f1: 0.8336 - mcc: 0.6896 - val_loss: 0.2339 - val_tp: 104.0000 - val_fp: 9.0000 - val_tn: 104.0000 - val_fn: 9.0000 - val_accuracy: 0.9204 - val_precision: 0.9204 - val_recall: 0.9204 - val_auc: 0.9665 - val_prc: 0.9675 - val_f1: 0.8546 - val_mcc: 0.7439\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2592 - tp: 297.0000 - fp: 37.0000 - tn: 297.0000 - fn: 37.0000 - accuracy: 0.8892 - precision: 0.8892 - recall: 0.8892 - auc: 0.9527 - prc: 0.9514 - f1: 0.8029 - mcc: 0.6470 - val_loss: 0.2009 - val_tp: 106.0000 - val_fp: 7.0000 - val_tn: 106.0000 - val_fn: 7.0000 - val_accuracy: 0.9381 - val_precision: 0.9381 - val_recall: 0.9381 - val_auc: 0.9746 - val_prc: 0.9754 - val_f1: 0.8817 - val_mcc: 0.7871\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2175 - tp: 313.0000 - fp: 21.0000 - tn: 313.0000 - fn: 21.0000 - accuracy: 0.9371 - precision: 0.9371 - recall: 0.9371 - auc: 0.9791 - prc: 0.9800 - f1: 0.8734 - mcc: 0.7602 - val_loss: 0.3272 - val_tp: 99.0000 - val_fp: 14.0000 - val_tn: 99.0000 - val_fn: 14.0000 - val_accuracy: 0.8761 - val_precision: 0.8761 - val_recall: 0.8761 - val_auc: 0.9391 - val_prc: 0.9394 - val_f1: 0.7953 - val_mcc: 0.6552\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1619 - tp: 308.0000 - fp: 26.0000 - tn: 308.0000 - fn: 26.0000 - accuracy: 0.9222 - precision: 0.9222 - recall: 0.9222 - auc: 0.9712 - prc: 0.9719 - f1: 0.8564 - mcc: 0.7468 - val_loss: 0.1593 - val_tp: 105.0000 - val_fp: 8.0000 - val_tn: 105.0000 - val_fn: 8.0000 - val_accuracy: 0.9292 - val_precision: 0.9292 - val_recall: 0.9292 - val_auc: 0.9859 - val_prc: 0.9864 - val_f1: 0.8615 - val_mcc: 0.7405\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1673 - tp: 310.0000 - fp: 24.0000 - tn: 310.0000 - fn: 24.0000 - accuracy: 0.9281 - precision: 0.9281 - recall: 0.9281 - auc: 0.9804 - prc: 0.9809 - f1: 0.8589 - mcc: 0.7358 - val_loss: 0.2282 - val_tp: 103.0000 - val_fp: 10.0000 - val_tn: 103.0000 - val_fn: 10.0000 - val_accuracy: 0.9115 - val_precision: 0.9115 - val_recall: 0.9115 - val_auc: 0.9694 - val_prc: 0.9706 - val_f1: 0.8348 - val_mcc: 0.6970\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1398 - tp: 314.0000 - fp: 20.0000 - tn: 314.0000 - fn: 20.0000 - accuracy: 0.9401 - precision: 0.9401 - recall: 0.9401 - auc: 0.9841 - prc: 0.9846 - f1: 0.8824 - mcc: 0.7837 - val_loss: 0.1719 - val_tp: 104.0000 - val_fp: 9.0000 - val_tn: 104.0000 - val_fn: 9.0000 - val_accuracy: 0.9204 - val_precision: 0.9204 - val_recall: 0.9204 - val_auc: 0.9843 - val_prc: 0.9850 - val_f1: 0.8479 - val_mcc: 0.7180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: results/622/uncg_18_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training uncg_18, results will be saved into results/622/uncg_18_3\n",
      "\n",
      "Number of classes: 2\n",
      "Training features shape: (334, 18, 6) labels shape: (334, 2)\n",
      "Validation features shape: (113, 18, 6) labels shape: (113, 2)\n",
      "Input shape: (18, 6)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 18, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 9, 16)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 9, 16)             0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 9, 32)             1568      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 4, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 4, 32)             0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 288)               37152     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 288)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 578       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,602\n",
      "Trainable params: 39,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - 3s 68ms/step - loss: 0.7517 - tp: 216.0000 - fp: 118.0000 - tn: 216.0000 - fn: 118.0000 - accuracy: 0.6467 - precision: 0.6467 - recall: 0.6467 - auc: 0.6917 - prc: 0.6772 - f1: 0.5270 - mcc: 0.1632 - val_loss: 0.4093 - val_tp: 99.0000 - val_fp: 14.0000 - val_tn: 99.0000 - val_fn: 14.0000 - val_accuracy: 0.8761 - val_precision: 0.8761 - val_recall: 0.8761 - val_auc: 0.9632 - val_prc: 0.9651 - val_f1: 0.7310 - val_mcc: 0.4636\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.6184 - tp: 218.0000 - fp: 116.0000 - tn: 218.0000 - fn: 116.0000 - accuracy: 0.6527 - precision: 0.6527 - recall: 0.6527 - auc: 0.7248 - prc: 0.7239 - f1: 0.5424 - mcc: 0.2092 - val_loss: 0.3291 - val_tp: 101.0000 - val_fp: 12.0000 - val_tn: 101.0000 - val_fn: 12.0000 - val_accuracy: 0.8938 - val_precision: 0.8938 - val_recall: 0.8938 - val_auc: 0.9675 - val_prc: 0.9691 - val_f1: 0.8102 - val_mcc: 0.6585\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.4564 - tp: 269.0000 - fp: 65.0000 - tn: 269.0000 - fn: 65.0000 - accuracy: 0.8054 - precision: 0.8054 - recall: 0.8054 - auc: 0.8883 - prc: 0.8872 - f1: 0.6840 - mcc: 0.4266 - val_loss: 0.7673 - val_tp: 67.0000 - val_fp: 46.0000 - val_tn: 67.0000 - val_fn: 46.0000 - val_accuracy: 0.5929 - val_precision: 0.5929 - val_recall: 0.5929 - val_auc: 0.6368 - val_prc: 0.6193 - val_f1: 0.5379 - val_mcc: 0.3534\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.4539 - tp: 252.0000 - fp: 82.0000 - tn: 252.0000 - fn: 82.0000 - accuracy: 0.7545 - precision: 0.7545 - recall: 0.7545 - auc: 0.8463 - prc: 0.8484 - f1: 0.6406 - mcc: 0.3756 - val_loss: 0.3338 - val_tp: 98.0000 - val_fp: 15.0000 - val_tn: 98.0000 - val_fn: 15.0000 - val_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673 - val_auc: 0.9342 - val_prc: 0.9337 - val_f1: 0.7846 - val_mcc: 0.6400\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3813 - tp: 278.0000 - fp: 56.0000 - tn: 278.0000 - fn: 56.0000 - accuracy: 0.8323 - precision: 0.8323 - recall: 0.8323 - auc: 0.9155 - prc: 0.9176 - f1: 0.7156 - mcc: 0.4788 - val_loss: 0.5045 - val_tp: 87.0000 - val_fp: 26.0000 - val_tn: 87.0000 - val_fn: 26.0000 - val_accuracy: 0.7699 - val_precision: 0.7699 - val_recall: 0.7699 - val_auc: 0.8489 - val_prc: 0.8363 - val_f1: 0.6837 - val_mcc: 0.5080\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3828 - tp: 280.0000 - fp: 54.0000 - tn: 280.0000 - fn: 54.0000 - accuracy: 0.8383 - precision: 0.8383 - recall: 0.8383 - auc: 0.9096 - prc: 0.9095 - f1: 0.7257 - mcc: 0.5003 - val_loss: 0.4793 - val_tp: 91.0000 - val_fp: 22.0000 - val_tn: 91.0000 - val_fn: 22.0000 - val_accuracy: 0.8053 - val_precision: 0.8053 - val_recall: 0.8053 - val_auc: 0.8657 - val_prc: 0.8404 - val_f1: 0.7175 - val_mcc: 0.5500\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3879 - tp: 270.0000 - fp: 64.0000 - tn: 270.0000 - fn: 64.0000 - accuracy: 0.8084 - precision: 0.8084 - recall: 0.8084 - auc: 0.8964 - prc: 0.8931 - f1: 0.7046 - mcc: 0.4922 - val_loss: 0.3184 - val_tp: 98.0000 - val_fp: 15.0000 - val_tn: 98.0000 - val_fn: 15.0000 - val_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673 - val_auc: 0.9362 - val_prc: 0.9323 - val_f1: 0.7765 - val_mcc: 0.6082\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2877 - tp: 289.0000 - fp: 45.0000 - tn: 289.0000 - fn: 45.0000 - accuracy: 0.8653 - precision: 0.8653 - recall: 0.8653 - auc: 0.9489 - prc: 0.9504 - f1: 0.7669 - mcc: 0.5804 - val_loss: 0.3358 - val_tp: 97.0000 - val_fp: 16.0000 - val_tn: 97.0000 - val_fn: 16.0000 - val_accuracy: 0.8584 - val_precision: 0.8584 - val_recall: 0.8584 - val_auc: 0.9323 - val_prc: 0.9293 - val_f1: 0.7660 - val_mcc: 0.5930\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2902 - tp: 294.0000 - fp: 40.0000 - tn: 294.0000 - fn: 40.0000 - accuracy: 0.8802 - precision: 0.8802 - recall: 0.8802 - auc: 0.9545 - prc: 0.9556 - f1: 0.7823 - mcc: 0.5979 - val_loss: 0.4951 - val_tp: 93.0000 - val_fp: 20.0000 - val_tn: 93.0000 - val_fn: 20.0000 - val_accuracy: 0.8230 - val_precision: 0.8230 - val_recall: 0.8230 - val_auc: 0.8669 - val_prc: 0.8521 - val_f1: 0.7355 - val_mcc: 0.5732\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2911 - tp: 284.0000 - fp: 50.0000 - tn: 284.0000 - fn: 50.0000 - accuracy: 0.8503 - precision: 0.8503 - recall: 0.8503 - auc: 0.9308 - prc: 0.9304 - f1: 0.7524 - mcc: 0.5661 - val_loss: 0.3270 - val_tp: 99.0000 - val_fp: 14.0000 - val_tn: 99.0000 - val_fn: 14.0000 - val_accuracy: 0.8761 - val_precision: 0.8761 - val_recall: 0.8761 - val_auc: 0.9379 - val_prc: 0.9357 - val_f1: 0.7953 - val_mcc: 0.6552\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2158 - tp: 296.0000 - fp: 38.0000 - tn: 296.0000 - fn: 38.0000 - accuracy: 0.8862 - precision: 0.8862 - recall: 0.8862 - auc: 0.9600 - prc: 0.9618 - f1: 0.8070 - mcc: 0.6721 - val_loss: 0.2065 - val_tp: 102.0000 - val_fp: 11.0000 - val_tn: 102.0000 - val_fn: 11.0000 - val_accuracy: 0.9027 - val_precision: 0.9027 - val_recall: 0.9027 - val_auc: 0.9748 - val_prc: 0.9756 - val_f1: 0.8223 - val_mcc: 0.6772\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2178 - tp: 304.0000 - fp: 30.0000 - tn: 304.0000 - fn: 30.0000 - accuracy: 0.9102 - precision: 0.9102 - recall: 0.9102 - auc: 0.9713 - prc: 0.9724 - f1: 0.8264 - mcc: 0.6733 - val_loss: 0.2679 - val_tp: 99.0000 - val_fp: 14.0000 - val_tn: 99.0000 - val_fn: 14.0000 - val_accuracy: 0.8761 - val_precision: 0.8761 - val_recall: 0.8761 - val_auc: 0.9579 - val_prc: 0.9578 - val_f1: 0.7874 - val_mcc: 0.6241\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2638 - tp: 299.0000 - fp: 35.0000 - tn: 299.0000 - fn: 35.0000 - accuracy: 0.8952 - precision: 0.8952 - recall: 0.8952 - auc: 0.9625 - prc: 0.9639 - f1: 0.8109 - mcc: 0.6592 - val_loss: 0.3667 - val_tp: 98.0000 - val_fp: 15.0000 - val_tn: 98.0000 - val_fn: 15.0000 - val_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673 - val_auc: 0.9301 - val_prc: 0.9304 - val_f1: 0.7846 - val_mcc: 0.6400\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1848 - tp: 303.0000 - fp: 31.0000 - tn: 303.0000 - fn: 31.0000 - accuracy: 0.9072 - precision: 0.9072 - recall: 0.9072 - auc: 0.9704 - prc: 0.9714 - f1: 0.8301 - mcc: 0.6945 - val_loss: 0.1656 - val_tp: 106.0000 - val_fp: 7.0000 - val_tn: 106.0000 - val_fn: 7.0000 - val_accuracy: 0.9381 - val_precision: 0.9381 - val_recall: 0.9381 - val_auc: 0.9836 - val_prc: 0.9842 - val_f1: 0.8691 - val_mcc: 0.7434\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2354 - tp: 303.0000 - fp: 31.0000 - tn: 303.0000 - fn: 31.0000 - accuracy: 0.9072 - precision: 0.9072 - recall: 0.9072 - auc: 0.9726 - prc: 0.9736 - f1: 0.8248 - mcc: 0.6756 - val_loss: 0.4204 - val_tp: 95.0000 - val_fp: 18.0000 - val_tn: 95.0000 - val_fn: 18.0000 - val_accuracy: 0.8407 - val_precision: 0.8407 - val_recall: 0.8407 - val_auc: 0.9117 - val_prc: 0.9035 - val_f1: 0.7543 - val_mcc: 0.5983\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2338 - tp: 302.0000 - fp: 32.0000 - tn: 302.0000 - fn: 32.0000 - accuracy: 0.9042 - precision: 0.9042 - recall: 0.9042 - auc: 0.9616 - prc: 0.9599 - f1: 0.8233 - mcc: 0.6784 - val_loss: 0.2629 - val_tp: 101.0000 - val_fp: 12.0000 - val_tn: 101.0000 - val_fn: 12.0000 - val_accuracy: 0.8938 - val_precision: 0.8938 - val_recall: 0.8938 - val_auc: 0.9619 - val_prc: 0.9625 - val_f1: 0.8177 - val_mcc: 0.6879\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1867 - tp: 306.0000 - fp: 28.0000 - tn: 306.0000 - fn: 28.0000 - accuracy: 0.9162 - precision: 0.9162 - recall: 0.9162 - auc: 0.9683 - prc: 0.9692 - f1: 0.8430 - mcc: 0.7149 - val_loss: 0.1942 - val_tp: 101.0000 - val_fp: 12.0000 - val_tn: 101.0000 - val_fn: 12.0000 - val_accuracy: 0.8938 - val_precision: 0.8938 - val_recall: 0.8938 - val_auc: 0.9772 - val_prc: 0.9781 - val_f1: 0.8018 - val_mcc: 0.6291\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2466 - tp: 306.0000 - fp: 28.0000 - tn: 306.0000 - fn: 28.0000 - accuracy: 0.9162 - precision: 0.9162 - recall: 0.9162 - auc: 0.9731 - prc: 0.9743 - f1: 0.8406 - mcc: 0.7059 - val_loss: 0.3560 - val_tp: 98.0000 - val_fp: 15.0000 - val_tn: 98.0000 - val_fn: 15.0000 - val_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673 - val_auc: 0.9349 - val_prc: 0.9360 - val_f1: 0.7846 - val_mcc: 0.6400\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2721 - tp: 295.0000 - fp: 39.0000 - tn: 295.0000 - fn: 39.0000 - accuracy: 0.8832 - precision: 0.8832 - recall: 0.8832 - auc: 0.9571 - prc: 0.9585 - f1: 0.7862 - mcc: 0.6039 - val_loss: 0.3423 - val_tp: 98.0000 - val_fp: 15.0000 - val_tn: 98.0000 - val_fn: 15.0000 - val_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673 - val_auc: 0.9378 - val_prc: 0.9385 - val_f1: 0.7846 - val_mcc: 0.6400\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2275 - tp: 291.0000 - fp: 43.0000 - tn: 291.0000 - fn: 43.0000 - accuracy: 0.8713 - precision: 0.8713 - recall: 0.8713 - auc: 0.9531 - prc: 0.9552 - f1: 0.7830 - mcc: 0.6238 - val_loss: 0.2118 - val_tp: 102.0000 - val_fp: 11.0000 - val_tn: 102.0000 - val_fn: 11.0000 - val_accuracy: 0.9027 - val_precision: 0.9027 - val_recall: 0.9027 - val_auc: 0.9738 - val_prc: 0.9744 - val_f1: 0.8223 - val_mcc: 0.6772\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1931 - tp: 311.0000 - fp: 23.0000 - tn: 311.0000 - fn: 23.0000 - accuracy: 0.9311 - precision: 0.9311 - recall: 0.9311 - auc: 0.9755 - prc: 0.9760 - f1: 0.8636 - mcc: 0.7438 - val_loss: 0.2544 - val_tp: 102.0000 - val_fp: 11.0000 - val_tn: 102.0000 - val_fn: 11.0000 - val_accuracy: 0.9027 - val_precision: 0.9027 - val_recall: 0.9027 - val_auc: 0.9640 - val_prc: 0.9644 - val_f1: 0.8296 - val_mcc: 0.7055\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1807 - tp: 308.0000 - fp: 26.0000 - tn: 308.0000 - fn: 26.0000 - accuracy: 0.9222 - precision: 0.9222 - recall: 0.9222 - auc: 0.9769 - prc: 0.9778 - f1: 0.8520 - mcc: 0.7292 - val_loss: 0.2364 - val_tp: 101.0000 - val_fp: 12.0000 - val_tn: 101.0000 - val_fn: 12.0000 - val_accuracy: 0.8938 - val_precision: 0.8938 - val_recall: 0.8938 - val_auc: 0.9683 - val_prc: 0.9688 - val_f1: 0.8102 - val_mcc: 0.6585\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1799 - tp: 306.0000 - fp: 28.0000 - tn: 306.0000 - fn: 28.0000 - accuracy: 0.9162 - precision: 0.9162 - recall: 0.9162 - auc: 0.9808 - prc: 0.9814 - f1: 0.8380 - mcc: 0.6969 - val_loss: 0.2494 - val_tp: 102.0000 - val_fp: 11.0000 - val_tn: 102.0000 - val_fn: 11.0000 - val_accuracy: 0.9027 - val_precision: 0.9027 - val_recall: 0.9027 - val_auc: 0.9662 - val_prc: 0.9667 - val_f1: 0.8296 - val_mcc: 0.7055\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2041 - tp: 300.0000 - fp: 34.0000 - tn: 300.0000 - fn: 34.0000 - accuracy: 0.8982 - precision: 0.8982 - recall: 0.8982 - auc: 0.9618 - prc: 0.9629 - f1: 0.8150 - mcc: 0.6655 - val_loss: 0.2395 - val_tp: 102.0000 - val_fp: 11.0000 - val_tn: 102.0000 - val_fn: 11.0000 - val_accuracy: 0.9027 - val_precision: 0.9027 - val_recall: 0.9027 - val_auc: 0.9684 - val_prc: 0.9690 - val_f1: 0.8223 - val_mcc: 0.6772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: results/622/uncg_18_3/assets\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"../data_generation/training_data/622/\")\n",
    "RESULTS_DIR = Path(\"results/622/\")\n",
    "for DATA_DIR in os.listdir(DATA_PATH):\n",
    "    for seed in [1, 2, 3]:\n",
    "        train(DATA_PATH/DATA_DIR, RESULTS_DIR, SUFFIX=f\"_{seed}\", SEED=seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnabert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
