{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aef19d0-9369-45f7-81aa-d7ca27ca925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 13:53:03.864524: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# standard libraries\n",
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "# standard scientific libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import asarray, save, load\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv1D, Conv2D, MaxPooling2D, Dropout, Flatten, Input, MaxPooling1D\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc75139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# fragment length (8- 14)\n",
    "# classifier vs. single-sequence (GNRA)\n",
    "# with/without decoys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3f533a-9c9c-46ff-bff6-70da4c18f363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 13:53:09.600682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13762 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:30:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Config (hyperparameters, figsize, metrics, etc.)\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "mpl.rcParams['figure.figsize'] = (15, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'),\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "      # TODO add F1, MCC\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddcbf01c-6048-449f-96f5-007e0b64f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions\n",
    "\n",
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale on y-axis to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color=colors[n], label='Train ' + label)\n",
    "  # plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "  #              color=colors[n], label='Val ' + label,\n",
    "  #              linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix')\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Non-GNRA Detected (True Negatives): ', cm[0][0])\n",
    "  print('Non-GNRA Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('GNRA Missed (False Negatives): ', cm[1][0])\n",
    "  print('GNRA Detected (True Positives): ', cm[1][1])\n",
    "  print('Total GNRA: ', np.sum(cm[1]))\n",
    "\n",
    "def plot_metrics(history1, history2):\n",
    "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history1.epoch, history1.history[metric], color=colors[0], label='Conf1_Train')\n",
    "    plt.plot(history1.epoch, history1.history['val_' + metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Conf1_Test')\n",
    "    plt.plot(history2.epoch, history2.history[metric], color=colors[1], label='Conf2_Train')\n",
    "    plt.plot(history2.epoch, history2.history['val_' + metric],\n",
    "             color=colors[1], linestyle=\"--\", label='Conf2_Test')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "  fpr, tpr, _ = sklearn.metrics.roc_curve(labels, predictions)  # fpr=false positive rate = fp/(fp+tn), tpr=true positive rate = tp/(tp+fn)\n",
    "\n",
    "  plt.rcParams['font.size'] = '16'\n",
    "  plt.plot(100*fpr, 100*tpr, label=name, linewidth=2, **kwargs)\n",
    "  plt.xlabel('False positives rate = fp/(fp+tn)')\n",
    "  plt.ylabel('True positives rate = tp/(tp+fn)')\n",
    "  plt.xlim([-0.5,20])\n",
    "  plt.ylim([80,100.5])\n",
    "  plt.grid(True)\n",
    "  ax = plt.gca()\n",
    "  ax.set_aspect('equal')\n",
    "\n",
    "def plot_prc(name, labels, predictions, **kwargs):  #precision = tp / (tp + fp), recall = tp / (tp + fn)\n",
    "    precision, recall, _ = sklearn.metrics.precision_recall_curve(labels, predictions)\n",
    "\n",
    "    plt.rcParams['font.size'] = '9'\n",
    "    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Recall = TP / (TP + FP)')\n",
    "    plt.ylabel('Precision = TP / (TP + FN)')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2613041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[1 0 0 ... 1 0 0]\n",
      "Training features shape: (52739, 14, 4)\n",
      "Test features shape: (26370, 14, 4)\n",
      "Training labels shape: (52739,)\n",
      "Test labels shape: (26370,)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dict_train = np.load('noAnno_train_14_nucleotide_array_with_cluster0.npz')\n",
    "x_train = np.stack(dict_train['arr_0'], axis=0)\n",
    "y_flt_train = np.load('noAnno_train_14_nucleotide_labels_with_cluster0.npy')\n",
    "y_train = y_flt_train.astype(int)\n",
    "print(y_train)\n",
    "\n",
    "dict_test = np.load('noAnno_test_14_nucleotide_array_with_cluster0.npz')\n",
    "x_test = np.stack(dict_test['arr_0'], axis=0)\n",
    "y_flt_test = np.load('noAnno_test_14_nucleotide_labels_with_cluster0.npy')\n",
    "y_test = y_flt_test.astype(int)\n",
    "print(y_test)\n",
    "\n",
    "print('Training features shape:', x_train.shape)\n",
    "print('Test features shape:', x_test.shape)\n",
    "print('Training labels shape:', y_train.shape)\n",
    "print('Test labels shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37a12f60-67a2-461f-82db-7b574391affd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 79109\n",
      "    Positive: 5578 (7.05% of total)\n",
      "\n",
      "Training labels shape: (52739,)\n",
      "Test labels shape: (26370,)\n",
      "Training features shape: (52739, 14, 4)\n",
      "Test features shape: (26370, 14, 4)\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(y_train)+np.bincount(y_test)\n",
    "total = neg + pos\n",
    "\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))\n",
    "\n",
    "print('Training labels shape:', y_train.shape)\n",
    "print('Test labels shape:', y_test.shape)\n",
    "\n",
    "print('Training features shape:', x_train.shape)\n",
    "print('Test features shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bafc96ad-62ad-47da-834b-df3dc94e2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model1(metrics=METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "    model = Sequential([\n",
    "        # The input shape is 14x4\n",
    "        # This is the first convolution\n",
    "        Conv1D(16, 3, strides=1, activation='relu', padding='same',\n",
    "               input_shape=(14, 4),\n",
    "               kernel_initializer='he_normal',\n",
    "               bias_initializer='zeros'),\n",
    "        MaxPooling1D(pool_size=2, strides=2),\n",
    "        Dropout(0.2),\n",
    "        Conv1D(32, 3, strides=1, activation='relu', padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               bias_initializer='zeros'),\n",
    "        MaxPooling1D(pool_size=2, strides=2),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        #  neuron hidden layer\n",
    "        Dense(224, activation='relu', bias_initializer=output_bias),  # 14/2(maxpooling)=7, 32*7 = 224\n",
    "        Dropout(0.2),\n",
    "        # Only 1 output neuron. It will contain a value from 0-1 where 0 for class ('not GNRA') and 1 for the other ('GNRA')\n",
    "        Dense(1, activation='sigmoid')  # Sigmoid for binary question.\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),  # optimizer=RMSprop(lr=0.001),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f6950d-c0e4-4313-8774-e6a7144dfa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model2(metrics=METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "    model = Sequential([\n",
    "        # The input shape is 14x4\n",
    "        # This is the first convolution\n",
    "        Conv1D(64, 3, strides=1, activation='relu', padding='same',\n",
    "               input_shape=(14, 4),\n",
    "               kernel_initializer='he_normal',\n",
    "               bias_initializer='zeros'),\n",
    "        MaxPooling1D(pool_size=2, strides=2),\n",
    "        Dropout(0.2),\n",
    "        Conv1D(32, 3, strides=1, activation='relu', padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               bias_initializer='zeros'),\n",
    "        MaxPooling1D(pool_size=2, strides=2),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        #  neuron hidden layer\n",
    "        Dense(224, activation='relu', bias_initializer=output_bias),  # 14/2(maxpooling)=7, 32*7 = 224\n",
    "        Dropout(0.2),\n",
    "        # Only 1 output neuron. It will contain a value from 0-1 where 0 for class ('not GNRA') and 1 for the other ('GNRA')\n",
    "        Dense(1, activation='sigmoid')  # Sigmoid for binary question.\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),  # optimizer=RMSprop(lr=0.001),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0212af-03ea-4253-b725-d11b35d7ed07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.54\n",
      "Weight for class 1: 7.09\n"
     ]
    }
   ],
   "source": [
    "# retrain with class weights\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66f3b235-e4e4-47ba-b861-e8f97efd7741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 13:53:30.729601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3297/3297 [==============================] - 17s 4ms/step - loss: 0.2645 - tp: 3350.0000 - fp: 5803.0000 - tn: 43214.0000 - fn: 372.0000 - accuracy: 0.8829 - precision: 0.3660 - recall: 0.9001 - auc: 0.9575 - prc: 0.7135 - val_loss: 0.1168 - val_tp: 1807.0000 - val_fp: 1074.0000 - val_tn: 23440.0000 - val_fn: 49.0000 - val_accuracy: 0.9574 - val_precision: 0.6272 - val_recall: 0.9736 - val_auc: 0.9929 - val_prc: 0.9438\n",
      "Epoch 2/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.1618 - tp: 3505.0000 - fp: 3011.0000 - tn: 46006.0000 - fn: 217.0000 - accuracy: 0.9388 - precision: 0.5379 - recall: 0.9417 - auc: 0.9831 - prc: 0.8566 - val_loss: 0.1015 - val_tp: 1820.0000 - val_fp: 914.0000 - val_tn: 23600.0000 - val_fn: 36.0000 - val_accuracy: 0.9640 - val_precision: 0.6657 - val_recall: 0.9806 - val_auc: 0.9951 - val_prc: 0.9577\n",
      "Epoch 3/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.1313 - tp: 3558.0000 - fp: 2335.0000 - tn: 46682.0000 - fn: 164.0000 - accuracy: 0.9526 - precision: 0.6038 - recall: 0.9559 - auc: 0.9885 - prc: 0.8912 - val_loss: 0.1270 - val_tp: 1833.0000 - val_fp: 1050.0000 - val_tn: 23464.0000 - val_fn: 23.0000 - val_accuracy: 0.9593 - val_precision: 0.6358 - val_recall: 0.9876 - val_auc: 0.9969 - val_prc: 0.9707\n",
      "Epoch 4/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.1134 - tp: 3585.0000 - fp: 1924.0000 - tn: 47093.0000 - fn: 137.0000 - accuracy: 0.9609 - precision: 0.6508 - recall: 0.9632 - auc: 0.9911 - prc: 0.9114 - val_loss: 0.0877 - val_tp: 1835.0000 - val_fp: 754.0000 - val_tn: 23760.0000 - val_fn: 21.0000 - val_accuracy: 0.9706 - val_precision: 0.7088 - val_recall: 0.9887 - val_auc: 0.9964 - val_prc: 0.9728\n",
      "Epoch 5/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.1050 - tp: 3591.0000 - fp: 1748.0000 - tn: 47269.0000 - fn: 131.0000 - accuracy: 0.9644 - precision: 0.6726 - recall: 0.9648 - auc: 0.9920 - prc: 0.9237 - val_loss: 0.0962 - val_tp: 1841.0000 - val_fp: 775.0000 - val_tn: 23739.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.7037 - val_recall: 0.9919 - val_auc: 0.9978 - val_prc: 0.9727\n",
      "Epoch 6/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0954 - tp: 3606.0000 - fp: 1531.0000 - tn: 47486.0000 - fn: 116.0000 - accuracy: 0.9688 - precision: 0.7020 - recall: 0.9688 - auc: 0.9934 - prc: 0.9231 - val_loss: 0.0800 - val_tp: 1835.0000 - val_fp: 692.0000 - val_tn: 23822.0000 - val_fn: 21.0000 - val_accuracy: 0.9730 - val_precision: 0.7262 - val_recall: 0.9887 - val_auc: 0.9974 - val_prc: 0.9734\n",
      "Epoch 7/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0906 - tp: 3604.0000 - fp: 1430.0000 - tn: 47587.0000 - fn: 118.0000 - accuracy: 0.9706 - precision: 0.7159 - recall: 0.9683 - auc: 0.9938 - prc: 0.9343 - val_loss: 0.0701 - val_tp: 1836.0000 - val_fp: 566.0000 - val_tn: 23948.0000 - val_fn: 20.0000 - val_accuracy: 0.9778 - val_precision: 0.7644 - val_recall: 0.9892 - val_auc: 0.9977 - val_prc: 0.9665\n",
      "Epoch 8/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0873 - tp: 3612.0000 - fp: 1365.0000 - tn: 47652.0000 - fn: 110.0000 - accuracy: 0.9720 - precision: 0.7257 - recall: 0.9704 - auc: 0.9939 - prc: 0.9361 - val_loss: 0.0753 - val_tp: 1840.0000 - val_fp: 565.0000 - val_tn: 23949.0000 - val_fn: 16.0000 - val_accuracy: 0.9780 - val_precision: 0.7651 - val_recall: 0.9914 - val_auc: 0.9981 - val_prc: 0.9787\n",
      "Epoch 9/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0833 - tp: 3613.0000 - fp: 1299.0000 - tn: 47718.0000 - fn: 109.0000 - accuracy: 0.9733 - precision: 0.7355 - recall: 0.9707 - auc: 0.9946 - prc: 0.9426 - val_loss: 0.0835 - val_tp: 1846.0000 - val_fp: 688.0000 - val_tn: 23826.0000 - val_fn: 10.0000 - val_accuracy: 0.9735 - val_precision: 0.7285 - val_recall: 0.9946 - val_auc: 0.9975 - val_prc: 0.9649\n",
      "Epoch 10/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0827 - tp: 3615.0000 - fp: 1370.0000 - tn: 47647.0000 - fn: 107.0000 - accuracy: 0.9720 - precision: 0.7252 - recall: 0.9713 - auc: 0.9950 - prc: 0.9396 - val_loss: 0.0885 - val_tp: 1843.0000 - val_fp: 740.0000 - val_tn: 23774.0000 - val_fn: 13.0000 - val_accuracy: 0.9714 - val_precision: 0.7135 - val_recall: 0.9930 - val_auc: 0.9981 - val_prc: 0.9719\n",
      "Epoch 11/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0783 - tp: 3627.0000 - fp: 1257.0000 - tn: 47760.0000 - fn: 95.0000 - accuracy: 0.9744 - precision: 0.7426 - recall: 0.9745 - auc: 0.9951 - prc: 0.9441 - val_loss: 0.0586 - val_tp: 1839.0000 - val_fp: 491.0000 - val_tn: 24023.0000 - val_fn: 17.0000 - val_accuracy: 0.9807 - val_precision: 0.7893 - val_recall: 0.9908 - val_auc: 0.9973 - val_prc: 0.9738\n",
      "Epoch 12/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0835 - tp: 3620.0000 - fp: 1321.0000 - tn: 47696.0000 - fn: 102.0000 - accuracy: 0.9730 - precision: 0.7326 - recall: 0.9726 - auc: 0.9944 - prc: 0.9419 - val_loss: 0.0740 - val_tp: 1844.0000 - val_fp: 588.0000 - val_tn: 23926.0000 - val_fn: 12.0000 - val_accuracy: 0.9772 - val_precision: 0.7582 - val_recall: 0.9935 - val_auc: 0.9979 - val_prc: 0.9735\n",
      "Epoch 13/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0788 - tp: 3626.0000 - fp: 1246.0000 - tn: 47771.0000 - fn: 96.0000 - accuracy: 0.9746 - precision: 0.7443 - recall: 0.9742 - auc: 0.9953 - prc: 0.9464 - val_loss: 0.0646 - val_tp: 1840.0000 - val_fp: 513.0000 - val_tn: 24001.0000 - val_fn: 16.0000 - val_accuracy: 0.9799 - val_precision: 0.7820 - val_recall: 0.9914 - val_auc: 0.9984 - val_prc: 0.9785\n",
      "Epoch 14/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0739 - tp: 3631.0000 - fp: 1147.0000 - tn: 47870.0000 - fn: 91.0000 - accuracy: 0.9765 - precision: 0.7599 - recall: 0.9756 - auc: 0.9956 - prc: 0.9466 - val_loss: 0.0773 - val_tp: 1845.0000 - val_fp: 658.0000 - val_tn: 23856.0000 - val_fn: 11.0000 - val_accuracy: 0.9746 - val_precision: 0.7371 - val_recall: 0.9941 - val_auc: 0.9980 - val_prc: 0.9732\n",
      "Epoch 15/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0771 - tp: 3632.0000 - fp: 1167.0000 - tn: 47850.0000 - fn: 90.0000 - accuracy: 0.9762 - precision: 0.7568 - recall: 0.9758 - auc: 0.9951 - prc: 0.9528 - val_loss: 0.0754 - val_tp: 1840.0000 - val_fp: 580.0000 - val_tn: 23934.0000 - val_fn: 16.0000 - val_accuracy: 0.9774 - val_precision: 0.7603 - val_recall: 0.9914 - val_auc: 0.9981 - val_prc: 0.9739\n",
      "Epoch 16/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0704 - tp: 3633.0000 - fp: 1092.0000 - tn: 47925.0000 - fn: 89.0000 - accuracy: 0.9776 - precision: 0.7689 - recall: 0.9761 - auc: 0.9960 - prc: 0.9541 - val_loss: 0.0775 - val_tp: 1844.0000 - val_fp: 626.0000 - val_tn: 23888.0000 - val_fn: 12.0000 - val_accuracy: 0.9758 - val_precision: 0.7466 - val_recall: 0.9935 - val_auc: 0.9981 - val_prc: 0.9678\n",
      "Epoch 17/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0721 - tp: 3637.0000 - fp: 1116.0000 - tn: 47901.0000 - fn: 85.0000 - accuracy: 0.9772 - precision: 0.7652 - recall: 0.9772 - auc: 0.9956 - prc: 0.9488 - val_loss: 0.0578 - val_tp: 1838.0000 - val_fp: 447.0000 - val_tn: 24067.0000 - val_fn: 18.0000 - val_accuracy: 0.9824 - val_precision: 0.8044 - val_recall: 0.9903 - val_auc: 0.9982 - val_prc: 0.9724\n",
      "Epoch 18/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0711 - tp: 3635.0000 - fp: 1097.0000 - tn: 47920.0000 - fn: 87.0000 - accuracy: 0.9775 - precision: 0.7682 - recall: 0.9766 - auc: 0.9959 - prc: 0.9535 - val_loss: 0.0985 - val_tp: 1844.0000 - val_fp: 776.0000 - val_tn: 23738.0000 - val_fn: 12.0000 - val_accuracy: 0.9701 - val_precision: 0.7038 - val_recall: 0.9935 - val_auc: 0.9977 - val_prc: 0.9668\n",
      "Epoch 19/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0749 - tp: 3629.0000 - fp: 1109.0000 - tn: 47908.0000 - fn: 93.0000 - accuracy: 0.9772 - precision: 0.7659 - recall: 0.9750 - auc: 0.9954 - prc: 0.9519 - val_loss: 0.0562 - val_tp: 1838.0000 - val_fp: 423.0000 - val_tn: 24091.0000 - val_fn: 18.0000 - val_accuracy: 0.9833 - val_precision: 0.8129 - val_recall: 0.9903 - val_auc: 0.9980 - val_prc: 0.9760\n",
      "Epoch 20/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0705 - tp: 3638.0000 - fp: 1136.0000 - tn: 47881.0000 - fn: 84.0000 - accuracy: 0.9769 - precision: 0.7620 - recall: 0.9774 - auc: 0.9961 - prc: 0.9514 - val_loss: 0.0639 - val_tp: 1841.0000 - val_fp: 461.0000 - val_tn: 24053.0000 - val_fn: 15.0000 - val_accuracy: 0.9819 - val_precision: 0.7997 - val_recall: 0.9919 - val_auc: 0.9980 - val_prc: 0.9693\n"
     ]
    }
   ],
   "source": [
    "weighted_model1 = make_model1()\n",
    "#weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history1 = weighted_model1.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data = (x_test, y_test),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "\n",
    "    # The class weights go here\n",
    "    class_weight={0: 0.54, 1: 7.09})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46a015d5-dafe-43e9-8fdc-f2a520438dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3297/3297 [==============================] - 15s 4ms/step - loss: 0.1995 - tp: 5303.0000 - fp: 4468.0000 - tn: 69063.0000 - fn: 275.0000 - accuracy: 0.9400 - precision: 0.5427 - recall: 0.9507 - auc: 0.9859 - prc: 0.8824 - val_loss: 0.1710 - val_tp: 1839.0000 - val_fp: 1524.0000 - val_tn: 22990.0000 - val_fn: 17.0000 - val_accuracy: 0.9416 - val_precision: 0.5468 - val_recall: 0.9908 - val_auc: 0.9951 - val_prc: 0.9335\n",
      "Epoch 2/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.1144 - tp: 3582.0000 - fp: 2056.0000 - tn: 46961.0000 - fn: 140.0000 - accuracy: 0.9584 - precision: 0.6353 - recall: 0.9624 - auc: 0.9906 - prc: 0.9035 - val_loss: 0.0735 - val_tp: 1827.0000 - val_fp: 609.0000 - val_tn: 23905.0000 - val_fn: 29.0000 - val_accuracy: 0.9758 - val_precision: 0.7500 - val_recall: 0.9844 - val_auc: 0.9976 - val_prc: 0.9740\n",
      "Epoch 3/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0934 - tp: 3616.0000 - fp: 1523.0000 - tn: 47494.0000 - fn: 106.0000 - accuracy: 0.9691 - precision: 0.7036 - recall: 0.9715 - auc: 0.9929 - prc: 0.9229 - val_loss: 0.0667 - val_tp: 1834.0000 - val_fp: 558.0000 - val_tn: 23956.0000 - val_fn: 22.0000 - val_accuracy: 0.9780 - val_precision: 0.7667 - val_recall: 0.9881 - val_auc: 0.9978 - val_prc: 0.9707\n",
      "Epoch 4/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0821 - tp: 3630.0000 - fp: 1350.0000 - tn: 47667.0000 - fn: 92.0000 - accuracy: 0.9727 - precision: 0.7289 - recall: 0.9753 - auc: 0.9947 - prc: 0.9400 - val_loss: 0.1069 - val_tp: 1844.0000 - val_fp: 859.0000 - val_tn: 23655.0000 - val_fn: 12.0000 - val_accuracy: 0.9670 - val_precision: 0.6822 - val_recall: 0.9935 - val_auc: 0.9981 - val_prc: 0.9698\n",
      "Epoch 5/20\n",
      "3297/3297 [==============================] - 12s 4ms/step - loss: 0.0719 - tp: 3643.0000 - fp: 1187.0000 - tn: 47830.0000 - fn: 79.0000 - accuracy: 0.9760 - precision: 0.7542 - recall: 0.9788 - auc: 0.9954 - prc: 0.9446 - val_loss: 0.0745 - val_tp: 1844.0000 - val_fp: 620.0000 - val_tn: 23894.0000 - val_fn: 12.0000 - val_accuracy: 0.9760 - val_precision: 0.7484 - val_recall: 0.9935 - val_auc: 0.9982 - val_prc: 0.9755\n",
      "Epoch 6/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0632 - tp: 3656.0000 - fp: 1060.0000 - tn: 47957.0000 - fn: 66.0000 - accuracy: 0.9786 - precision: 0.7752 - recall: 0.9823 - auc: 0.9962 - prc: 0.9503 - val_loss: 0.0771 - val_tp: 1840.0000 - val_fp: 624.0000 - val_tn: 23890.0000 - val_fn: 16.0000 - val_accuracy: 0.9757 - val_precision: 0.7468 - val_recall: 0.9914 - val_auc: 0.9980 - val_prc: 0.9663\n",
      "Epoch 7/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0649 - tp: 3643.0000 - fp: 1029.0000 - tn: 47988.0000 - fn: 79.0000 - accuracy: 0.9790 - precision: 0.7798 - recall: 0.9788 - auc: 0.9963 - prc: 0.9542 - val_loss: 0.0690 - val_tp: 1842.0000 - val_fp: 542.0000 - val_tn: 23972.0000 - val_fn: 14.0000 - val_accuracy: 0.9789 - val_precision: 0.7727 - val_recall: 0.9925 - val_auc: 0.9982 - val_prc: 0.9753\n",
      "Epoch 8/20\n",
      "3297/3297 [==============================] - 12s 4ms/step - loss: 0.0559 - tp: 3663.0000 - fp: 866.0000 - tn: 48151.0000 - fn: 59.0000 - accuracy: 0.9825 - precision: 0.8088 - recall: 0.9841 - auc: 0.9971 - prc: 0.9601 - val_loss: 0.0681 - val_tp: 1845.0000 - val_fp: 538.0000 - val_tn: 23976.0000 - val_fn: 11.0000 - val_accuracy: 0.9792 - val_precision: 0.7742 - val_recall: 0.9941 - val_auc: 0.9981 - val_prc: 0.9698\n",
      "Epoch 9/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0567 - tp: 3657.0000 - fp: 892.0000 - tn: 48125.0000 - fn: 65.0000 - accuracy: 0.9819 - precision: 0.8039 - recall: 0.9825 - auc: 0.9968 - prc: 0.9593 - val_loss: 0.0333 - val_tp: 1833.0000 - val_fp: 248.0000 - val_tn: 24266.0000 - val_fn: 23.0000 - val_accuracy: 0.9897 - val_precision: 0.8808 - val_recall: 0.9876 - val_auc: 0.9987 - val_prc: 0.9815\n",
      "Epoch 10/20\n",
      "3297/3297 [==============================] - 12s 4ms/step - loss: 0.0540 - tp: 3657.0000 - fp: 850.0000 - tn: 48167.0000 - fn: 65.0000 - accuracy: 0.9827 - precision: 0.8114 - recall: 0.9825 - auc: 0.9972 - prc: 0.9612 - val_loss: 0.0400 - val_tp: 1837.0000 - val_fp: 280.0000 - val_tn: 24234.0000 - val_fn: 19.0000 - val_accuracy: 0.9887 - val_precision: 0.8677 - val_recall: 0.9898 - val_auc: 0.9982 - val_prc: 0.9768\n",
      "Epoch 11/20\n",
      "3297/3297 [==============================] - 12s 4ms/step - loss: 0.0539 - tp: 3653.0000 - fp: 814.0000 - tn: 48203.0000 - fn: 69.0000 - accuracy: 0.9833 - precision: 0.8178 - recall: 0.9815 - auc: 0.9972 - prc: 0.9603 - val_loss: 0.0411 - val_tp: 1838.0000 - val_fp: 303.0000 - val_tn: 24211.0000 - val_fn: 18.0000 - val_accuracy: 0.9878 - val_precision: 0.8585 - val_recall: 0.9903 - val_auc: 0.9986 - val_prc: 0.9778\n",
      "Epoch 12/20\n",
      "3297/3297 [==============================] - 12s 4ms/step - loss: 0.0510 - tp: 3661.0000 - fp: 819.0000 - tn: 48198.0000 - fn: 61.0000 - accuracy: 0.9833 - precision: 0.8172 - recall: 0.9836 - auc: 0.9973 - prc: 0.9623 - val_loss: 0.0526 - val_tp: 1844.0000 - val_fp: 447.0000 - val_tn: 24067.0000 - val_fn: 12.0000 - val_accuracy: 0.9826 - val_precision: 0.8049 - val_recall: 0.9935 - val_auc: 0.9986 - val_prc: 0.9778\n",
      "Epoch 13/20\n",
      "3297/3297 [==============================] - 12s 4ms/step - loss: 0.0472 - tp: 3676.0000 - fp: 723.0000 - tn: 48294.0000 - fn: 46.0000 - accuracy: 0.9854 - precision: 0.8356 - recall: 0.9876 - auc: 0.9975 - prc: 0.9654 - val_loss: 0.0367 - val_tp: 1840.0000 - val_fp: 258.0000 - val_tn: 24256.0000 - val_fn: 16.0000 - val_accuracy: 0.9896 - val_precision: 0.8770 - val_recall: 0.9914 - val_auc: 0.9985 - val_prc: 0.9744\n",
      "Epoch 14/20\n",
      "3297/3297 [==============================] - 12s 4ms/step - loss: 0.0461 - tp: 3667.0000 - fp: 729.0000 - tn: 48288.0000 - fn: 55.0000 - accuracy: 0.9851 - precision: 0.8342 - recall: 0.9852 - auc: 0.9978 - prc: 0.9640 - val_loss: 0.0373 - val_tp: 1836.0000 - val_fp: 282.0000 - val_tn: 24232.0000 - val_fn: 20.0000 - val_accuracy: 0.9885 - val_precision: 0.8669 - val_recall: 0.9892 - val_auc: 0.9986 - val_prc: 0.9785\n",
      "Epoch 15/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0488 - tp: 3666.0000 - fp: 733.0000 - tn: 48284.0000 - fn: 56.0000 - accuracy: 0.9850 - precision: 0.8334 - recall: 0.9850 - auc: 0.9973 - prc: 0.9635 - val_loss: 0.0484 - val_tp: 1845.0000 - val_fp: 401.0000 - val_tn: 24113.0000 - val_fn: 11.0000 - val_accuracy: 0.9844 - val_precision: 0.8215 - val_recall: 0.9941 - val_auc: 0.9985 - val_prc: 0.9765\n",
      "Epoch 16/20\n",
      "3297/3297 [==============================] - 13s 4ms/step - loss: 0.0493 - tp: 3665.0000 - fp: 783.0000 - tn: 48234.0000 - fn: 57.0000 - accuracy: 0.9841 - precision: 0.8240 - recall: 0.9847 - auc: 0.9975 - prc: 0.9691 - val_loss: 0.0412 - val_tp: 1839.0000 - val_fp: 339.0000 - val_tn: 24175.0000 - val_fn: 17.0000 - val_accuracy: 0.9865 - val_precision: 0.8444 - val_recall: 0.9908 - val_auc: 0.9987 - val_prc: 0.9808\n",
      "Epoch 17/20\n",
      "3297/3297 [==============================] - 12s 4ms/step - loss: 0.0466 - tp: 3673.0000 - fp: 765.0000 - tn: 48252.0000 - fn: 49.0000 - accuracy: 0.9846 - precision: 0.8276 - recall: 0.9868 - auc: 0.9978 - prc: 0.9689 - val_loss: 0.0379 - val_tp: 1842.0000 - val_fp: 329.0000 - val_tn: 24185.0000 - val_fn: 14.0000 - val_accuracy: 0.9870 - val_precision: 0.8485 - val_recall: 0.9925 - val_auc: 0.9985 - val_prc: 0.9790\n",
      "Epoch 18/20\n",
      "3297/3297 [==============================] - 12s 4ms/step - loss: 0.0491 - tp: 3670.0000 - fp: 794.0000 - tn: 48223.0000 - fn: 52.0000 - accuracy: 0.9840 - precision: 0.8221 - recall: 0.9860 - auc: 0.9973 - prc: 0.9642 - val_loss: 0.0838 - val_tp: 1851.0000 - val_fp: 774.0000 - val_tn: 23740.0000 - val_fn: 5.0000 - val_accuracy: 0.9705 - val_precision: 0.7051 - val_recall: 0.9973 - val_auc: 0.9984 - val_prc: 0.9742\n",
      "Epoch 19/20\n",
      "3297/3297 [==============================] - 12s 4ms/step - loss: 0.0449 - tp: 3675.0000 - fp: 734.0000 - tn: 48283.0000 - fn: 47.0000 - accuracy: 0.9852 - precision: 0.8335 - recall: 0.9874 - auc: 0.9977 - prc: 0.9670 - val_loss: 0.0523 - val_tp: 1844.0000 - val_fp: 393.0000 - val_tn: 24121.0000 - val_fn: 12.0000 - val_accuracy: 0.9846 - val_precision: 0.8243 - val_recall: 0.9935 - val_auc: 0.9983 - val_prc: 0.9701\n",
      "Epoch 20/20\n",
      "3297/3297 [==============================] - 12s 4ms/step - loss: 0.0488 - tp: 3670.0000 - fp: 783.0000 - tn: 48234.0000 - fn: 52.0000 - accuracy: 0.9842 - precision: 0.8242 - recall: 0.9860 - auc: 0.9974 - prc: 0.9676 - val_loss: 0.0385 - val_tp: 1838.0000 - val_fp: 278.0000 - val_tn: 24236.0000 - val_fn: 18.0000 - val_accuracy: 0.9888 - val_precision: 0.8686 - val_recall: 0.9903 - val_auc: 0.9986 - val_prc: 0.9772\n"
     ]
    }
   ],
   "source": [
    "weighted_model2 = make_model2()\n",
    "#weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history2 = weighted_model2.fit(\n",
    "    x_train,\n",
    "    y_train, \n",
    "    validation_data = (x_test, y_test),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "\n",
    "    # The class weights go here\n",
    "    class_weight={0: 0.54, 1: 7.09})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b07ebed-978c-440d-8666-5ddec80e28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(weighted_history1, weighted_history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee309736-c3a9-454b-b4ea-773e8c0c06e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3297/3297 [==============================] - 3s 954us/step\n",
      "1649/1649 [==============================] - 2s 955us/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_weighted1 = weighted_model1.predict(x_train, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted1 = weighted_model1.predict(x_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "757aed4a-e8cb-434b-aae5-61c85e01f94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3297/3297 [==============================] - 3s 941us/step\n",
      "1649/1649 [==============================] - 2s 939us/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_weighted2 = weighted_model2.predict(x_train, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted2 = weighted_model2.predict(x_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b76a7dc-6b99-48b5-ac03-5b50982fac12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.06392601132392883\n",
      "tp :  1841.0\n",
      "fp :  461.0\n",
      "tn :  24053.0\n",
      "fn :  15.0\n",
      "accuracy :  0.9819492101669312\n",
      "precision :  0.7997393608093262\n",
      "recall :  0.9919180870056152\n",
      "auc :  0.9980196952819824\n",
      "prc :  0.969272792339325\n",
      "\n",
      "Non-GNRA Detected (True Negatives):  24053\n",
      "Non-GNRA Incorrectly Detected (False Positives):  461\n",
      "GNRA Missed (False Negatives):  15\n",
      "GNRA Detected (True Positives):  1841\n",
      "Total GNRA:  1856\n"
     ]
    }
   ],
   "source": [
    "# Results of test data set. \n",
    "weighted_results1 = weighted_model1.evaluate(x_test, y_test,\n",
    "                                           batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(weighted_model1.metrics_names, weighted_results1):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(y_test, test_predictions_weighted1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74877d7b-5c8f-46dc-adfa-53eb0ba2cb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.06392601132392883\n",
      "tp :  1841.0\n",
      "fp :  461.0\n",
      "tn :  24053.0\n",
      "fn :  15.0\n",
      "accuracy :  0.9819492101669312\n",
      "precision :  0.7997393608093262\n",
      "recall :  0.9919180870056152\n",
      "auc :  0.9980196952819824\n",
      "prc :  0.969272792339325\n",
      "\n",
      "Non-GNRA Detected (True Negatives):  24236\n",
      "Non-GNRA Incorrectly Detected (False Positives):  278\n",
      "GNRA Missed (False Negatives):  18\n",
      "GNRA Detected (True Positives):  1838\n",
      "Total GNRA:  1856\n"
     ]
    }
   ],
   "source": [
    "# Results of test data set. \n",
    "weighted_results2 = weighted_model2.evaluate(x_test, y_test,\n",
    "                                           batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(weighted_model2.metrics_names, weighted_results1):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(y_test, test_predictions_weighted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e8f9b88-2e83-4c9e-9b11-a54579e966ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(\"Conf1_Train Weighted\", y_train, train_predictions_weighted1, color=colors[0])\n",
    "plot_roc(\"Conf1_Test Weighted\", y_test, test_predictions_weighted1, color=colors[0], linestyle='--')\n",
    "plot_roc(\"Conf2_Train Weighted\", y_train, train_predictions_weighted2, color=colors[1])\n",
    "plot_roc(\"Conf2_Test Weighted\", y_test, test_predictions_weighted2, color=colors[1], linestyle='--')\n",
    "\n",
    "\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cbbe4be-be63-417b-9af0-a1e5af47443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prc(\"Conf1_Train Weighted\", y_train, train_predictions_weighted1, color=colors[0])\n",
    "plot_prc(\"Conf1_Test Weighted\", y_test, test_predictions_weighted1, color=colors[0], linestyle='--')\n",
    "plot_prc(\"Conf2_Train Weighted\", y_train, train_predictions_weighted2, color=colors[1])\n",
    "plot_prc(\"Conf2_Test Weighted\", y_test, test_predictions_weighted2, color=colors[1], linestyle='--')\n",
    "# plt.xlim([0, 1.2])\n",
    "plt.ylim([0, 1.2])\n",
    "\n",
    "plt.legend(loc='upper right');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnabert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
