{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aef19d0-9369-45f7-81aa-d7ca27ca925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 12:30:03.285226: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/mimer/NOBACKUP/groups/naiss2024-5-16/tloop/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/mimer/NOBACKUP/groups/naiss2024-5-16/tloop/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# standard libraries\n",
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# standard scientific libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import asarray, save, load\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv1D, Conv2D, MaxPooling2D, Dropout, Flatten, Input, MaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2bc2c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bafc96ad-62ad-47da-834b-df3dc94e2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(metrics, num_classes, input_shape, output_bias=None, pool_size = 2):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    \n",
    "    model = Sequential([        \n",
    "        # First convolution\n",
    "        Conv1D(16, 3, strides=1, activation='relu', padding='same', # TODO set as 64?\n",
    "               input_shape = input_shape,\n",
    "               kernel_initializer = 'he_normal',\n",
    "               bias_initializer = 'zeros'),\n",
    "        MaxPooling1D(pool_size = pool_size, strides = 2), # TODO set strides?\n",
    "        Dropout(0.2),\n",
    "        Conv1D(32, 3, strides = 1, activation = 'relu', padding = 'same',\n",
    "               kernel_initializer = 'he_normal',\n",
    "               bias_initializer = 'zeros'),\n",
    "        MaxPooling1D(pool_size = pool_size, strides = 2),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        \n",
    "        # Neuron hidden layer\n",
    "        Dense(int(input_shape[0]/pool_size) * 32, activation = 'relu', kernel_initializer='he_normal', bias_initializer = output_bias),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Output neuron\n",
    "        # Dense(1, activation='sigmoid')  # Sigmoid for binary question. It will contain a value from 0-1 where 0 for class ('not GNRA') and 1 for the other ('GNRA')\n",
    "        Dense(num_classes, activation='softmax', bias_initializer=output_bias, kernel_initializer='glorot_uniform') # TODO categorical: Softmax for multiclass classification\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate = 1e-3),  # optimizer=RMSprop(lr=0.001),\n",
    "        loss=keras.losses.CategoricalCrossentropy(), \n",
    "        # loss=keras.losses.BinaryCrossentropy(), # TODO remove?\n",
    "        metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf891565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(DATA_DIR, NUM_CLASSES, EPOCHS = 20, BATCH_SIZE = 16):\n",
    "    DATA_DIR = Path(DATA_DIR)\n",
    "    SET_NAME = str(DATA_DIR).split(\"/\")[-1]\n",
    "    RESULTS_FILE = Path(f\"results/ANN/{SET_NAME}\")\n",
    "    METRICS = [ \n",
    "        keras.metrics.TruePositives(name = 'tp'), # TODO is this correct? something is wrong\n",
    "        keras.metrics.FalsePositives(name = 'fp'),\n",
    "        keras.metrics.TrueNegatives(name = 'tn'),\n",
    "        keras.metrics.FalseNegatives(name = 'fn'),\n",
    "        # keras.metrics.BinaryAccuracy(name = 'accuracy'), # TODO remove this?\n",
    "        keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name = 'precision'),\n",
    "        keras.metrics.Recall(name = 'recall'),\n",
    "        keras.metrics.AUC(name = 'auc', curve='roc'),\n",
    "        keras.metrics.AUC(name = 'prc', curve = 'PR'), # precision-recall curve\n",
    "        tfa.metrics.F1Score(name = 'f1', num_classes = NUM_CLASSES),\n",
    "        tfa.metrics.MatthewsCorrelationCoefficient(name = 'mcc', num_classes = NUM_CLASSES)\n",
    "    ]\n",
    "\n",
    "    # Load dataset\n",
    "    \n",
    "    train_dict = np.load(DATA_DIR/\"train_matrices.npz\", allow_pickle=True)\n",
    "    x_train = np.stack(train_dict['arr_0'], axis=0)\n",
    "    y_train = np.load(DATA_DIR/\"train_labels.npy\", allow_pickle=True)\n",
    "    y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "\n",
    "    dev_dict = np.load(DATA_DIR/\"dev_matrices.npz\", allow_pickle=True)\n",
    "    x_dev = np.stack(dev_dict['arr_0'], axis=0)\n",
    "    y_dev = np.load(DATA_DIR/\"dev_labels.npy\", allow_pickle=True)\n",
    "    y_dev = to_categorical(y_dev, num_classes=NUM_CLASSES)\n",
    "\n",
    "    print(\"Training features shape:\", x_train.shape)\n",
    "    print(\"Training labels shape:\", y_train.shape)\n",
    "\n",
    "    print(\"\\nDev (validation) features shape:\", x_dev.shape)\n",
    "    print(\"Dev (validation) labels shape:\", y_dev.shape)\n",
    "\n",
    "    print(\"\\nInput shape:\", x_train.shape[1:])\n",
    "    print()\n",
    "\n",
    "    INPUT_SHAPE = x_train.shape[1:]\n",
    "\n",
    "    # Calculate class weight\n",
    "\n",
    "    # Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "    # The sum of the weights of all examples stays the same.\n",
    "    y_integers = np.argmax(y_train, axis=1)\n",
    "    class_weights = np.round(class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_integers), y=y_integers), 2)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    # Train with class weights\n",
    "\n",
    "    model = make_model(METRICS, NUM_CLASSES, INPUT_SHAPE)\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_data = (x_dev, y_dev),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        \n",
    "        # The class weights go here\n",
    "        class_weight=d_class_weights)\n",
    "    \n",
    "    # Save model\n",
    "    model.save(RESULTS_FILE, overwrite=True)\n",
    "\n",
    "    # Save history\n",
    "    with open(RESULTS_FILE/\"history\", 'wb') as file:\n",
    "        pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce5a9f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_18_80_T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 12:30:11.823978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38551 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:4b:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (58392, 18, 5)\n",
      "Training labels shape: (58392, 24)\n",
      "\n",
      "Dev (validation) features shape: (7299, 18, 5)\n",
      "Dev (validation) labels shape: (7299, 24)\n",
      "\n",
      "Input shape: (18, 5)\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /apps/Arch/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 12:30:15.414994: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n",
      "2024-05-05 12:30:16.323735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3650/3650 [==============================] - 18s 4ms/step - loss: 1.4041 - tp: 4747.0000 - fp: 10279.0000 - tn: 1332737.0000 - fn: 53645.0000 - accuracy: 0.2333 - precision: 0.3159 - recall: 0.0813 - auc: 0.8715 - prc: 0.2119 - f1: 0.0757 - mcc: 0.1007 - val_loss: 2.9657 - val_tp: 249.0000 - val_fp: 1965.0000 - val_tn: 165912.0000 - val_fn: 7050.0000 - val_accuracy: 0.0854 - val_precision: 0.1125 - val_recall: 0.0341 - val_auc: 0.8007 - val_prc: 0.1183 - val_f1: 0.1300 - val_mcc: 0.1392\n",
      "Epoch 2/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.6470 - tp: 11914.0000 - fp: 17765.0000 - tn: 1325251.0000 - fn: 46478.0000 - accuracy: 0.3394 - precision: 0.4014 - recall: 0.2040 - auc: 0.9116 - prc: 0.3134 - f1: 0.1376 - mcc: 0.1683 - val_loss: 2.0871 - val_tp: 497.0000 - val_fp: 1847.0000 - val_tn: 166030.0000 - val_fn: 6802.0000 - val_accuracy: 0.1930 - val_precision: 0.2120 - val_recall: 0.0681 - val_auc: 0.9058 - val_prc: 0.2263 - val_f1: 0.1870 - val_mcc: 0.1646\n",
      "Epoch 3/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.5098 - tp: 16985.0000 - fp: 17800.0000 - tn: 1325216.0000 - fn: 41407.0000 - accuracy: 0.4269 - precision: 0.4883 - recall: 0.2909 - auc: 0.9439 - prc: 0.4179 - f1: 0.1716 - mcc: 0.2069 - val_loss: 1.5083 - val_tp: 1502.0000 - val_fp: 1829.0000 - val_tn: 166048.0000 - val_fn: 5797.0000 - val_accuracy: 0.4054 - val_precision: 0.4509 - val_recall: 0.2058 - val_auc: 0.9514 - val_prc: 0.4005 - val_f1: 0.2543 - val_mcc: 0.2391\n",
      "Epoch 4/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.5026 - tp: 19612.0000 - fp: 16929.0000 - tn: 1326087.0000 - fn: 38780.0000 - accuracy: 0.4777 - precision: 0.5367 - recall: 0.3359 - auc: 0.9542 - prc: 0.4713 - f1: 0.1906 - mcc: 0.2269 - val_loss: 1.4538 - val_tp: 1511.0000 - val_fp: 1280.0000 - val_tn: 166597.0000 - val_fn: 5788.0000 - val_accuracy: 0.4494 - val_precision: 0.5414 - val_recall: 0.2070 - val_auc: 0.9552 - val_prc: 0.4431 - val_f1: 0.2425 - val_mcc: 0.2467\n",
      "Epoch 5/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.4383 - tp: 19665.0000 - fp: 17120.0000 - tn: 1325896.0000 - fn: 38727.0000 - accuracy: 0.4751 - precision: 0.5346 - recall: 0.3368 - auc: 0.9547 - prc: 0.4714 - f1: 0.2041 - mcc: 0.2334 - val_loss: 1.2370 - val_tp: 2589.0000 - val_fp: 1420.0000 - val_tn: 166457.0000 - val_fn: 4710.0000 - val_accuracy: 0.5549 - val_precision: 0.6458 - val_recall: 0.3547 - val_auc: 0.9662 - val_prc: 0.5555 - val_f1: 0.2541 - val_mcc: 0.2900\n",
      "Epoch 6/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.4062 - tp: 25705.0000 - fp: 15100.0000 - tn: 1327916.0000 - fn: 32687.0000 - accuracy: 0.5616 - precision: 0.6299 - recall: 0.4402 - auc: 0.9680 - prc: 0.5877 - f1: 0.2265 - mcc: 0.2666 - val_loss: 1.2456 - val_tp: 2564.0000 - val_fp: 1391.0000 - val_tn: 166486.0000 - val_fn: 4735.0000 - val_accuracy: 0.5406 - val_precision: 0.6483 - val_recall: 0.3513 - val_auc: 0.9664 - val_prc: 0.5667 - val_f1: 0.2571 - val_mcc: 0.2890\n",
      "Epoch 7/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3589 - tp: 25357.0000 - fp: 15894.0000 - tn: 1327122.0000 - fn: 33035.0000 - accuracy: 0.5550 - precision: 0.6147 - recall: 0.4343 - auc: 0.9678 - prc: 0.5778 - f1: 0.2374 - mcc: 0.2701 - val_loss: 1.1738 - val_tp: 2798.0000 - val_fp: 1580.0000 - val_tn: 166297.0000 - val_fn: 4501.0000 - val_accuracy: 0.5621 - val_precision: 0.6391 - val_recall: 0.3833 - val_auc: 0.9696 - val_prc: 0.5763 - val_f1: 0.2591 - val_mcc: 0.2972\n",
      "Epoch 8/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3433 - tp: 28404.0000 - fp: 15187.0000 - tn: 1327829.0000 - fn: 29988.0000 - accuracy: 0.5926 - precision: 0.6516 - recall: 0.4864 - auc: 0.9724 - prc: 0.6282 - f1: 0.2659 - mcc: 0.2831 - val_loss: 1.3055 - val_tp: 2110.0000 - val_fp: 1631.0000 - val_tn: 166246.0000 - val_fn: 5189.0000 - val_accuracy: 0.4816 - val_precision: 0.5640 - val_recall: 0.2891 - val_auc: 0.9635 - val_prc: 0.5013 - val_f1: 0.2534 - val_mcc: 0.2651\n",
      "Epoch 9/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3233 - tp: 29300.0000 - fp: 15651.0000 - tn: 1327365.0000 - fn: 29092.0000 - accuracy: 0.5997 - precision: 0.6518 - recall: 0.5018 - auc: 0.9716 - prc: 0.6329 - f1: 0.2592 - mcc: 0.2900 - val_loss: 1.1538 - val_tp: 2755.0000 - val_fp: 1526.0000 - val_tn: 166351.0000 - val_fn: 4544.0000 - val_accuracy: 0.5764 - val_precision: 0.6435 - val_recall: 0.3774 - val_auc: 0.9706 - val_prc: 0.5830 - val_f1: 0.2609 - val_mcc: 0.3017\n",
      "Epoch 10/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3457 - tp: 29247.0000 - fp: 14895.0000 - tn: 1328121.0000 - fn: 29145.0000 - accuracy: 0.6030 - precision: 0.6626 - recall: 0.5009 - auc: 0.9728 - prc: 0.6417 - f1: 0.2808 - mcc: 0.2897 - val_loss: 1.1712 - val_tp: 2796.0000 - val_fp: 1517.0000 - val_tn: 166360.0000 - val_fn: 4503.0000 - val_accuracy: 0.5595 - val_precision: 0.6483 - val_recall: 0.3831 - val_auc: 0.9693 - val_prc: 0.5829 - val_f1: 0.2638 - val_mcc: 0.3002\n",
      "Epoch 11/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3235 - tp: 29123.0000 - fp: 14977.0000 - tn: 1328039.0000 - fn: 29269.0000 - accuracy: 0.6010 - precision: 0.6604 - recall: 0.4987 - auc: 0.9713 - prc: 0.6308 - f1: 0.2655 - mcc: 0.2919 - val_loss: 1.0657 - val_tp: 3273.0000 - val_fp: 1580.0000 - val_tn: 166297.0000 - val_fn: 4026.0000 - val_accuracy: 0.6082 - val_precision: 0.6744 - val_recall: 0.4484 - val_auc: 0.9738 - val_prc: 0.6288 - val_f1: 0.3186 - val_mcc: 0.3214\n",
      "Epoch 12/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3114 - tp: 31339.0000 - fp: 14921.0000 - tn: 1328095.0000 - fn: 27053.0000 - accuracy: 0.6257 - precision: 0.6775 - recall: 0.5367 - auc: 0.9747 - prc: 0.6669 - f1: 0.2994 - mcc: 0.3065 - val_loss: 1.4673 - val_tp: 2153.0000 - val_fp: 2202.0000 - val_tn: 165675.0000 - val_fn: 5146.0000 - val_accuracy: 0.4376 - val_precision: 0.4944 - val_recall: 0.2950 - val_auc: 0.9520 - val_prc: 0.4422 - val_f1: 0.2772 - val_mcc: 0.2422\n",
      "Epoch 13/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3007 - tp: 31918.0000 - fp: 14987.0000 - tn: 1328029.0000 - fn: 26474.0000 - accuracy: 0.6294 - precision: 0.6805 - recall: 0.5466 - auc: 0.9726 - prc: 0.6670 - f1: 0.2870 - mcc: 0.3042 - val_loss: 0.8216 - val_tp: 4570.0000 - val_fp: 1307.0000 - val_tn: 166570.0000 - val_fn: 2729.0000 - val_accuracy: 0.7202 - val_precision: 0.7776 - val_recall: 0.6261 - val_auc: 0.9821 - val_prc: 0.7699 - val_f1: 0.3061 - val_mcc: 0.3892\n",
      "Epoch 14/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3335 - tp: 32504.0000 - fp: 14571.0000 - tn: 1328445.0000 - fn: 25888.0000 - accuracy: 0.6371 - precision: 0.6905 - recall: 0.5567 - auc: 0.9736 - prc: 0.6847 - f1: 0.2822 - mcc: 0.3109 - val_loss: 1.5168 - val_tp: 2040.0000 - val_fp: 2068.0000 - val_tn: 165809.0000 - val_fn: 5259.0000 - val_accuracy: 0.4317 - val_precision: 0.4966 - val_recall: 0.2795 - val_auc: 0.9483 - val_prc: 0.4265 - val_f1: 0.2445 - val_mcc: 0.2495\n",
      "Epoch 15/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3079 - tp: 33142.0000 - fp: 14704.0000 - tn: 1328312.0000 - fn: 25250.0000 - accuracy: 0.6427 - precision: 0.6927 - recall: 0.5676 - auc: 0.9740 - prc: 0.6894 - f1: 0.2769 - mcc: 0.3155 - val_loss: 0.9660 - val_tp: 3852.0000 - val_fp: 1448.0000 - val_tn: 166429.0000 - val_fn: 3447.0000 - val_accuracy: 0.6621 - val_precision: 0.7268 - val_recall: 0.5277 - val_auc: 0.9763 - val_prc: 0.6905 - val_f1: 0.2819 - val_mcc: 0.3484\n",
      "Epoch 16/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3411 - tp: 29268.0000 - fp: 15978.0000 - tn: 1327038.0000 - fn: 29124.0000 - accuracy: 0.5886 - precision: 0.6469 - recall: 0.5012 - auc: 0.9687 - prc: 0.6264 - f1: 0.2601 - mcc: 0.2883 - val_loss: 1.2312 - val_tp: 2836.0000 - val_fp: 1949.0000 - val_tn: 165928.0000 - val_fn: 4463.0000 - val_accuracy: 0.5483 - val_precision: 0.5927 - val_recall: 0.3885 - val_auc: 0.9642 - val_prc: 0.5313 - val_f1: 0.2555 - val_mcc: 0.2972\n",
      "Epoch 17/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.2972 - tp: 31777.0000 - fp: 14774.0000 - tn: 1328242.0000 - fn: 26615.0000 - accuracy: 0.6366 - precision: 0.6826 - recall: 0.5442 - auc: 0.9753 - prc: 0.6675 - f1: 0.3028 - mcc: 0.3131 - val_loss: 1.0413 - val_tp: 3472.0000 - val_fp: 1736.0000 - val_tn: 166141.0000 - val_fn: 3827.0000 - val_accuracy: 0.6117 - val_precision: 0.6667 - val_recall: 0.4757 - val_auc: 0.9732 - val_prc: 0.6144 - val_f1: 0.2977 - val_mcc: 0.3238\n",
      "Epoch 18/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3256 - tp: 31777.0000 - fp: 14231.0000 - tn: 1328785.0000 - fn: 26615.0000 - accuracy: 0.6374 - precision: 0.6907 - recall: 0.5442 - auc: 0.9748 - prc: 0.6731 - f1: 0.2788 - mcc: 0.3088 - val_loss: 1.6013 - val_tp: 1319.0000 - val_fp: 2437.0000 - val_tn: 165440.0000 - val_fn: 5980.0000 - val_accuracy: 0.3291 - val_precision: 0.3512 - val_recall: 0.1807 - val_auc: 0.9450 - val_prc: 0.3514 - val_f1: 0.2151 - val_mcc: 0.2297\n",
      "Epoch 19/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3173 - tp: 32166.0000 - fp: 14178.0000 - tn: 1328838.0000 - fn: 26226.0000 - accuracy: 0.6411 - precision: 0.6941 - recall: 0.5509 - auc: 0.9749 - prc: 0.6803 - f1: 0.2878 - mcc: 0.3132 - val_loss: 1.1851 - val_tp: 2844.0000 - val_fp: 1609.0000 - val_tn: 166268.0000 - val_fn: 4455.0000 - val_accuracy: 0.5617 - val_precision: 0.6387 - val_recall: 0.3896 - val_auc: 0.9683 - val_prc: 0.5672 - val_f1: 0.2407 - val_mcc: 0.3034\n",
      "Epoch 20/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3103 - tp: 32750.0000 - fp: 14392.0000 - tn: 1328624.0000 - fn: 25642.0000 - accuracy: 0.6415 - precision: 0.6947 - recall: 0.5609 - auc: 0.9747 - prc: 0.6876 - f1: 0.2823 - mcc: 0.3108 - val_loss: 1.3650 - val_tp: 2714.0000 - val_fp: 1880.0000 - val_tn: 165997.0000 - val_fn: 4585.0000 - val_accuracy: 0.5168 - val_precision: 0.5908 - val_recall: 0.3718 - val_auc: 0.9559 - val_prc: 0.5065 - val_f1: 0.2155 - val_mcc: 0.2769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_18_80_T/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_18_80_T/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_22_80_T\n",
      "Training features shape: (59692, 22, 5)\n",
      "Training labels shape: (59692, 24)\n",
      "\n",
      "Dev (validation) features shape: (7461, 22, 5)\n",
      "Dev (validation) labels shape: (7461, 24)\n",
      "\n",
      "Input shape: (22, 5)\n",
      "\n",
      "Epoch 1/20\n",
      "3731/3731 [==============================] - 16s 4ms/step - loss: 1.1961 - tp: 5783.0000 - fp: 10683.0000 - tn: 1362233.0000 - fn: 53909.0000 - accuracy: 0.2378 - precision: 0.3512 - recall: 0.0969 - auc: 0.8623 - prc: 0.2166 - f1: 0.0895 - mcc: 0.1190 - val_loss: 2.0898 - val_tp: 285.0000 - val_fp: 495.0000 - val_tn: 171108.0000 - val_fn: 7176.0000 - val_accuracy: 0.2254 - val_precision: 0.3654 - val_recall: 0.0382 - val_auc: 0.9051 - val_prc: 0.2342 - val_f1: 0.1806 - val_mcc: 0.1583\n",
      "Epoch 2/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.5741 - tp: 13243.0000 - fp: 15165.0000 - tn: 1357751.0000 - fn: 46449.0000 - accuracy: 0.4036 - precision: 0.4662 - recall: 0.2219 - auc: 0.9425 - prc: 0.3867 - f1: 0.1637 - mcc: 0.1953 - val_loss: 2.0012 - val_tp: 494.0000 - val_fp: 1446.0000 - val_tn: 170157.0000 - val_fn: 6967.0000 - val_accuracy: 0.2305 - val_precision: 0.2546 - val_recall: 0.0662 - val_auc: 0.9148 - val_prc: 0.2480 - val_f1: 0.1846 - val_mcc: 0.1816\n",
      "Epoch 3/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.4597 - tp: 19114.0000 - fp: 16040.0000 - tn: 1356876.0000 - fn: 40578.0000 - accuracy: 0.4780 - precision: 0.5437 - recall: 0.3202 - auc: 0.9565 - prc: 0.4746 - f1: 0.2065 - mcc: 0.2335 - val_loss: 1.5934 - val_tp: 1052.0000 - val_fp: 1909.0000 - val_tn: 169694.0000 - val_fn: 6409.0000 - val_accuracy: 0.3339 - val_precision: 0.3553 - val_recall: 0.1410 - val_auc: 0.9480 - val_prc: 0.3480 - val_f1: 0.2581 - val_mcc: 0.2194\n",
      "Epoch 4/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.4086 - tp: 20918.0000 - fp: 16117.0000 - tn: 1356799.0000 - fn: 38774.0000 - accuracy: 0.5124 - precision: 0.5648 - recall: 0.3504 - auc: 0.9639 - prc: 0.5089 - f1: 0.2319 - mcc: 0.2518 - val_loss: 1.4072 - val_tp: 1403.0000 - val_fp: 1384.0000 - val_tn: 170219.0000 - val_fn: 6058.0000 - val_accuracy: 0.4499 - val_precision: 0.5034 - val_recall: 0.1880 - val_auc: 0.9608 - val_prc: 0.4477 - val_f1: 0.2487 - val_mcc: 0.2495\n",
      "Epoch 5/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3889 - tp: 25072.0000 - fp: 16326.0000 - tn: 1356590.0000 - fn: 34620.0000 - accuracy: 0.5444 - precision: 0.6056 - recall: 0.4200 - auc: 0.9652 - prc: 0.5627 - f1: 0.2492 - mcc: 0.2680 - val_loss: 1.1739 - val_tp: 2367.0000 - val_fp: 1262.0000 - val_tn: 170341.0000 - val_fn: 5094.0000 - val_accuracy: 0.5667 - val_precision: 0.6522 - val_recall: 0.3172 - val_auc: 0.9721 - val_prc: 0.5748 - val_f1: 0.2706 - val_mcc: 0.2895\n",
      "Epoch 6/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3547 - tp: 26633.0000 - fp: 15496.0000 - tn: 1357420.0000 - fn: 33059.0000 - accuracy: 0.5707 - precision: 0.6322 - recall: 0.4462 - auc: 0.9688 - prc: 0.5857 - f1: 0.2621 - mcc: 0.2788 - val_loss: 1.3648 - val_tp: 2100.0000 - val_fp: 1816.0000 - val_tn: 169787.0000 - val_fn: 5361.0000 - val_accuracy: 0.4833 - val_precision: 0.5363 - val_recall: 0.2815 - val_auc: 0.9608 - val_prc: 0.4763 - val_f1: 0.2625 - val_mcc: 0.2560\n",
      "Epoch 7/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3536 - tp: 28981.0000 - fp: 14950.0000 - tn: 1357966.0000 - fn: 30711.0000 - accuracy: 0.6029 - precision: 0.6597 - recall: 0.4855 - auc: 0.9725 - prc: 0.6262 - f1: 0.2815 - mcc: 0.2918 - val_loss: 1.7750 - val_tp: 902.0000 - val_fp: 1814.0000 - val_tn: 169789.0000 - val_fn: 6559.0000 - val_accuracy: 0.2978 - val_precision: 0.3321 - val_recall: 0.1209 - val_auc: 0.9338 - val_prc: 0.3081 - val_f1: 0.2214 - val_mcc: 0.2102\n",
      "Epoch 8/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3055 - tp: 32000.0000 - fp: 13936.0000 - tn: 1358980.0000 - fn: 27692.0000 - accuracy: 0.6393 - precision: 0.6966 - recall: 0.5361 - auc: 0.9779 - prc: 0.6783 - f1: 0.3190 - mcc: 0.3132 - val_loss: 1.1128 - val_tp: 2960.0000 - val_fp: 1308.0000 - val_tn: 170295.0000 - val_fn: 4501.0000 - val_accuracy: 0.5908 - val_precision: 0.6935 - val_recall: 0.3967 - val_auc: 0.9738 - val_prc: 0.6234 - val_f1: 0.2932 - val_mcc: 0.2894\n",
      "Epoch 9/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3044 - tp: 33179.0000 - fp: 14867.0000 - tn: 1358049.0000 - fn: 26513.0000 - accuracy: 0.6420 - precision: 0.6906 - recall: 0.5558 - auc: 0.9751 - prc: 0.6745 - f1: 0.3125 - mcc: 0.3145 - val_loss: 1.2278 - val_tp: 2414.0000 - val_fp: 1533.0000 - val_tn: 170070.0000 - val_fn: 5047.0000 - val_accuracy: 0.5529 - val_precision: 0.6116 - val_recall: 0.3235 - val_auc: 0.9675 - val_prc: 0.5372 - val_f1: 0.2737 - val_mcc: 0.2841\n",
      "Epoch 10/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3045 - tp: 34493.0000 - fp: 13768.0000 - tn: 1359148.0000 - fn: 25199.0000 - accuracy: 0.6636 - precision: 0.7147 - recall: 0.5778 - auc: 0.9790 - prc: 0.7067 - f1: 0.3106 - mcc: 0.3269 - val_loss: 1.5856 - val_tp: 1453.0000 - val_fp: 1665.0000 - val_tn: 169938.0000 - val_fn: 6008.0000 - val_accuracy: 0.3915 - val_precision: 0.4660 - val_recall: 0.1947 - val_auc: 0.9464 - val_prc: 0.3874 - val_f1: 0.2339 - val_mcc: 0.2178\n",
      "Epoch 11/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.2974 - tp: 32824.0000 - fp: 13987.0000 - tn: 1358929.0000 - fn: 26868.0000 - accuracy: 0.6432 - precision: 0.7012 - recall: 0.5499 - auc: 0.9781 - prc: 0.6913 - f1: 0.3157 - mcc: 0.3192 - val_loss: 1.0146 - val_tp: 3534.0000 - val_fp: 1631.0000 - val_tn: 169972.0000 - val_fn: 3927.0000 - val_accuracy: 0.6240 - val_precision: 0.6842 - val_recall: 0.4737 - val_auc: 0.9766 - val_prc: 0.6439 - val_f1: 0.3312 - val_mcc: 0.3140\n",
      "Epoch 12/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.2969 - tp: 33344.0000 - fp: 14593.0000 - tn: 1358323.0000 - fn: 26348.0000 - accuracy: 0.6462 - precision: 0.6956 - recall: 0.5586 - auc: 0.9775 - prc: 0.6905 - f1: 0.3077 - mcc: 0.3185 - val_loss: 1.0174 - val_tp: 3271.0000 - val_fp: 1392.0000 - val_tn: 170211.0000 - val_fn: 4190.0000 - val_accuracy: 0.6169 - val_precision: 0.7015 - val_recall: 0.4384 - val_auc: 0.9775 - val_prc: 0.6538 - val_f1: 0.2732 - val_mcc: 0.3104\n",
      "Epoch 13/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.2724 - tp: 34672.0000 - fp: 14210.0000 - tn: 1358706.0000 - fn: 25020.0000 - accuracy: 0.6619 - precision: 0.7093 - recall: 0.5808 - auc: 0.9778 - prc: 0.7080 - f1: 0.3308 - mcc: 0.3325 - val_loss: 1.0860 - val_tp: 3496.0000 - val_fp: 1558.0000 - val_tn: 170045.0000 - val_fn: 3965.0000 - val_accuracy: 0.6151 - val_precision: 0.6917 - val_recall: 0.4686 - val_auc: 0.9714 - val_prc: 0.6340 - val_f1: 0.3133 - val_mcc: 0.3094\n",
      "Epoch 14/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3100 - tp: 30881.0000 - fp: 15983.0000 - tn: 1356933.0000 - fn: 28811.0000 - accuracy: 0.6052 - precision: 0.6589 - recall: 0.5173 - auc: 0.9714 - prc: 0.6383 - f1: 0.2775 - mcc: 0.2985 - val_loss: 1.3047 - val_tp: 2419.0000 - val_fp: 1707.0000 - val_tn: 169896.0000 - val_fn: 5042.0000 - val_accuracy: 0.5175 - val_precision: 0.5863 - val_recall: 0.3242 - val_auc: 0.9621 - val_prc: 0.5146 - val_f1: 0.2275 - val_mcc: 0.2687\n",
      "Epoch 15/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3136 - tp: 32690.0000 - fp: 14658.0000 - tn: 1358258.0000 - fn: 27002.0000 - accuracy: 0.6358 - precision: 0.6904 - recall: 0.5476 - auc: 0.9749 - prc: 0.6750 - f1: 0.2983 - mcc: 0.3125 - val_loss: 1.3253 - val_tp: 2177.0000 - val_fp: 1364.0000 - val_tn: 170239.0000 - val_fn: 5284.0000 - val_accuracy: 0.5300 - val_precision: 0.6148 - val_recall: 0.2918 - val_auc: 0.9635 - val_prc: 0.5227 - val_f1: 0.2687 - val_mcc: 0.2723\n",
      "Epoch 16/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3112 - tp: 31689.0000 - fp: 14284.0000 - tn: 1358632.0000 - fn: 28003.0000 - accuracy: 0.6270 - precision: 0.6893 - recall: 0.5309 - auc: 0.9745 - prc: 0.6717 - f1: 0.2793 - mcc: 0.3094 - val_loss: 1.0613 - val_tp: 3129.0000 - val_fp: 1477.0000 - val_tn: 170126.0000 - val_fn: 4332.0000 - val_accuracy: 0.6167 - val_precision: 0.6793 - val_recall: 0.4194 - val_auc: 0.9755 - val_prc: 0.6308 - val_f1: 0.2962 - val_mcc: 0.3136\n",
      "Epoch 17/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.2768 - tp: 33634.0000 - fp: 15070.0000 - tn: 1357846.0000 - fn: 26058.0000 - accuracy: 0.6442 - precision: 0.6906 - recall: 0.5635 - auc: 0.9753 - prc: 0.6814 - f1: 0.3117 - mcc: 0.3201 - val_loss: 0.9729 - val_tp: 4135.0000 - val_fp: 1739.0000 - val_tn: 169864.0000 - val_fn: 3326.0000 - val_accuracy: 0.6592 - val_precision: 0.7039 - val_recall: 0.5542 - val_auc: 0.9751 - val_prc: 0.6608 - val_f1: 0.3064 - val_mcc: 0.3321\n",
      "Epoch 18/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.2842 - tp: 34574.0000 - fp: 14594.0000 - tn: 1358322.0000 - fn: 25118.0000 - accuracy: 0.6557 - precision: 0.7032 - recall: 0.5792 - auc: 0.9761 - prc: 0.6954 - f1: 0.3230 - mcc: 0.3233 - val_loss: 1.0274 - val_tp: 3755.0000 - val_fp: 1640.0000 - val_tn: 169963.0000 - val_fn: 3706.0000 - val_accuracy: 0.6358 - val_precision: 0.6960 - val_recall: 0.5033 - val_auc: 0.9744 - val_prc: 0.6638 - val_f1: 0.3081 - val_mcc: 0.3212\n",
      "Epoch 19/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.2976 - tp: 32449.0000 - fp: 16014.0000 - tn: 1356902.0000 - fn: 27243.0000 - accuracy: 0.6212 - precision: 0.6696 - recall: 0.5436 - auc: 0.9709 - prc: 0.6541 - f1: 0.2901 - mcc: 0.3056 - val_loss: 1.3827 - val_tp: 2248.0000 - val_fp: 1934.0000 - val_tn: 169669.0000 - val_fn: 5213.0000 - val_accuracy: 0.4762 - val_precision: 0.5375 - val_recall: 0.3013 - val_auc: 0.9577 - val_prc: 0.4720 - val_f1: 0.2400 - val_mcc: 0.2581\n",
      "Epoch 20/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3057 - tp: 32366.0000 - fp: 15062.0000 - tn: 1357854.0000 - fn: 27326.0000 - accuracy: 0.6316 - precision: 0.6824 - recall: 0.5422 - auc: 0.9722 - prc: 0.6620 - f1: 0.2804 - mcc: 0.3116 - val_loss: 1.1834 - val_tp: 3317.0000 - val_fp: 1961.0000 - val_tn: 169642.0000 - val_fn: 4144.0000 - val_accuracy: 0.5812 - val_precision: 0.6285 - val_recall: 0.4446 - val_auc: 0.9661 - val_prc: 0.5662 - val_f1: 0.2712 - val_mcc: 0.2953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_22_80_T/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_22_80_T/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_8_80_T\n",
      "Training features shape: (33084, 8, 5)\n",
      "Training labels shape: (33084, 24)\n",
      "\n",
      "Dev (validation) features shape: (4135, 8, 5)\n",
      "Dev (validation) labels shape: (4135, 24)\n",
      "\n",
      "Input shape: (8, 5)\n",
      "\n",
      "Epoch 1/20\n",
      "2068/2068 [==============================] - 10s 4ms/step - loss: 1.9700 - tp: 960.0000 - fp: 2667.0000 - tn: 758265.0000 - fn: 32124.0000 - accuracy: 0.1845 - precision: 0.2647 - recall: 0.0290 - auc: 0.8127 - prc: 0.1514 - f1: 0.0773 - mcc: 0.1006 - val_loss: 1.9204 - val_tp: 284.0000 - val_fp: 384.0000 - val_tn: 94721.0000 - val_fn: 3851.0000 - val_accuracy: 0.3833 - val_precision: 0.4251 - val_recall: 0.0687 - val_auc: 0.9194 - val_prc: 0.3239 - val_f1: 0.1701 - val_mcc: 0.2248\n",
      "Epoch 2/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 1.0719 - tp: 3523.0000 - fp: 6846.0000 - tn: 754086.0000 - fn: 29561.0000 - accuracy: 0.2886 - precision: 0.3398 - recall: 0.1065 - auc: 0.8909 - prc: 0.2452 - f1: 0.1408 - mcc: 0.1757 - val_loss: 1.6914 - val_tp: 551.0000 - val_fp: 466.0000 - val_tn: 94639.0000 - val_fn: 3584.0000 - val_accuracy: 0.4464 - val_precision: 0.5418 - val_recall: 0.1333 - val_auc: 0.9396 - val_prc: 0.4000 - val_f1: 0.1857 - val_mcc: 0.2575\n",
      "Epoch 3/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.8711 - tp: 5445.0000 - fp: 7410.0000 - tn: 753522.0000 - fn: 27639.0000 - accuracy: 0.3635 - precision: 0.4236 - recall: 0.1646 - auc: 0.9169 - prc: 0.3155 - f1: 0.1652 - mcc: 0.2108 - val_loss: 1.8695 - val_tp: 651.0000 - val_fp: 852.0000 - val_tn: 94253.0000 - val_fn: 3484.0000 - val_accuracy: 0.3807 - val_precision: 0.4331 - val_recall: 0.1574 - val_auc: 0.9188 - val_prc: 0.3239 - val_f1: 0.2218 - val_mcc: 0.2484\n",
      "Epoch 4/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.7472 - tp: 7693.0000 - fp: 8455.0000 - tn: 752477.0000 - fn: 25391.0000 - accuracy: 0.4034 - precision: 0.4764 - recall: 0.2325 - auc: 0.9289 - prc: 0.3650 - f1: 0.1900 - mcc: 0.2338 - val_loss: 1.6212 - val_tp: 886.0000 - val_fp: 762.0000 - val_tn: 94343.0000 - val_fn: 3249.0000 - val_accuracy: 0.4455 - val_precision: 0.5376 - val_recall: 0.2143 - val_auc: 0.9408 - val_prc: 0.4113 - val_f1: 0.2241 - val_mcc: 0.2883\n",
      "Epoch 5/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.6840 - tp: 8563.0000 - fp: 8334.0000 - tn: 752598.0000 - fn: 24521.0000 - accuracy: 0.4335 - precision: 0.5068 - recall: 0.2588 - auc: 0.9370 - prc: 0.3977 - f1: 0.2011 - mcc: 0.2492 - val_loss: 1.3547 - val_tp: 1288.0000 - val_fp: 638.0000 - val_tn: 94467.0000 - val_fn: 2847.0000 - val_accuracy: 0.5461 - val_precision: 0.6687 - val_recall: 0.3115 - val_auc: 0.9591 - val_prc: 0.5290 - val_f1: 0.2769 - val_mcc: 0.3407\n",
      "Epoch 6/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.6403 - tp: 8466.0000 - fp: 8492.0000 - tn: 752440.0000 - fn: 24618.0000 - accuracy: 0.4313 - precision: 0.4992 - recall: 0.2559 - auc: 0.9383 - prc: 0.3940 - f1: 0.2072 - mcc: 0.2513 - val_loss: 1.4837 - val_tp: 964.0000 - val_fp: 734.0000 - val_tn: 94371.0000 - val_fn: 3171.0000 - val_accuracy: 0.4996 - val_precision: 0.5677 - val_recall: 0.2331 - val_auc: 0.9506 - val_prc: 0.4509 - val_f1: 0.2647 - val_mcc: 0.3156\n",
      "Epoch 7/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.6056 - tp: 10063.0000 - fp: 8124.0000 - tn: 752808.0000 - fn: 23021.0000 - accuracy: 0.4822 - precision: 0.5533 - recall: 0.3042 - auc: 0.9477 - prc: 0.4473 - f1: 0.2281 - mcc: 0.2750 - val_loss: 1.6365 - val_tp: 785.0000 - val_fp: 772.0000 - val_tn: 94333.0000 - val_fn: 3350.0000 - val_accuracy: 0.4300 - val_precision: 0.5042 - val_recall: 0.1898 - val_auc: 0.9389 - val_prc: 0.3883 - val_f1: 0.2452 - val_mcc: 0.2860\n",
      "Epoch 8/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.5628 - tp: 10505.0000 - fp: 8511.0000 - tn: 752421.0000 - fn: 22579.0000 - accuracy: 0.4886 - precision: 0.5524 - recall: 0.3175 - auc: 0.9488 - prc: 0.4525 - f1: 0.2304 - mcc: 0.2847 - val_loss: 1.2062 - val_tp: 1685.0000 - val_fp: 775.0000 - val_tn: 94330.0000 - val_fn: 2450.0000 - val_accuracy: 0.6002 - val_precision: 0.6850 - val_recall: 0.4075 - val_auc: 0.9661 - val_prc: 0.5728 - val_f1: 0.3316 - val_mcc: 0.3789\n",
      "Epoch 9/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.5156 - tp: 11854.0000 - fp: 8994.0000 - tn: 751938.0000 - fn: 21230.0000 - accuracy: 0.5072 - precision: 0.5686 - recall: 0.3583 - auc: 0.9505 - prc: 0.4727 - f1: 0.2439 - mcc: 0.2970 - val_loss: 1.3112 - val_tp: 1563.0000 - val_fp: 833.0000 - val_tn: 94272.0000 - val_fn: 2572.0000 - val_accuracy: 0.5768 - val_precision: 0.6523 - val_recall: 0.3780 - val_auc: 0.9583 - val_prc: 0.5314 - val_f1: 0.2839 - val_mcc: 0.3584\n",
      "Epoch 10/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.5186 - tp: 11845.0000 - fp: 8579.0000 - tn: 752353.0000 - fn: 21239.0000 - accuracy: 0.5132 - precision: 0.5800 - recall: 0.3580 - auc: 0.9532 - prc: 0.4836 - f1: 0.2453 - mcc: 0.2988 - val_loss: 1.4175 - val_tp: 1451.0000 - val_fp: 980.0000 - val_tn: 94125.0000 - val_fn: 2684.0000 - val_accuracy: 0.5306 - val_precision: 0.5969 - val_recall: 0.3509 - val_auc: 0.9522 - val_prc: 0.4865 - val_f1: 0.2658 - val_mcc: 0.3265\n",
      "Epoch 11/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.5104 - tp: 12427.0000 - fp: 8692.0000 - tn: 752240.0000 - fn: 20657.0000 - accuracy: 0.5266 - precision: 0.5884 - recall: 0.3756 - auc: 0.9545 - prc: 0.4960 - f1: 0.2489 - mcc: 0.3055 - val_loss: 1.2873 - val_tp: 1411.0000 - val_fp: 782.0000 - val_tn: 94323.0000 - val_fn: 2724.0000 - val_accuracy: 0.5712 - val_precision: 0.6434 - val_recall: 0.3412 - val_auc: 0.9623 - val_prc: 0.5244 - val_f1: 0.2902 - val_mcc: 0.3637\n",
      "Epoch 12/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.4817 - tp: 12674.0000 - fp: 9172.0000 - tn: 751760.0000 - fn: 20410.0000 - accuracy: 0.5250 - precision: 0.5802 - recall: 0.3831 - auc: 0.9536 - prc: 0.4884 - f1: 0.2526 - mcc: 0.3096 - val_loss: 1.3224 - val_tp: 1615.0000 - val_fp: 1038.0000 - val_tn: 94067.0000 - val_fn: 2520.0000 - val_accuracy: 0.5557 - val_precision: 0.6087 - val_recall: 0.3906 - val_auc: 0.9577 - val_prc: 0.5125 - val_f1: 0.3195 - val_mcc: 0.3643\n",
      "Epoch 13/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.4770 - tp: 14507.0000 - fp: 8883.0000 - tn: 752049.0000 - fn: 18577.0000 - accuracy: 0.5627 - precision: 0.6202 - recall: 0.4385 - auc: 0.9579 - prc: 0.5336 - f1: 0.2628 - mcc: 0.3246 - val_loss: 1.1611 - val_tp: 1867.0000 - val_fp: 848.0000 - val_tn: 94257.0000 - val_fn: 2268.0000 - val_accuracy: 0.6210 - val_precision: 0.6877 - val_recall: 0.4515 - val_auc: 0.9673 - val_prc: 0.5798 - val_f1: 0.3279 - val_mcc: 0.3947\n",
      "Epoch 14/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.4919 - tp: 14352.0000 - fp: 8695.0000 - tn: 752237.0000 - fn: 18732.0000 - accuracy: 0.5637 - precision: 0.6227 - recall: 0.4338 - auc: 0.9600 - prc: 0.5416 - f1: 0.2749 - mcc: 0.3305 - val_loss: 1.1478 - val_tp: 2008.0000 - val_fp: 921.0000 - val_tn: 94184.0000 - val_fn: 2127.0000 - val_accuracy: 0.6191 - val_precision: 0.6856 - val_recall: 0.4856 - val_auc: 0.9679 - val_prc: 0.5919 - val_f1: 0.3181 - val_mcc: 0.3836\n",
      "Epoch 15/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.4760 - tp: 15410.0000 - fp: 8656.0000 - tn: 752276.0000 - fn: 17674.0000 - accuracy: 0.5723 - precision: 0.6403 - recall: 0.4658 - auc: 0.9590 - prc: 0.5652 - f1: 0.2758 - mcc: 0.3315 - val_loss: 1.4780 - val_tp: 1441.0000 - val_fp: 1082.0000 - val_tn: 94023.0000 - val_fn: 2694.0000 - val_accuracy: 0.5071 - val_precision: 0.5711 - val_recall: 0.3485 - val_auc: 0.9488 - val_prc: 0.4661 - val_f1: 0.2759 - val_mcc: 0.3281\n",
      "Epoch 16/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.4541 - tp: 14910.0000 - fp: 8609.0000 - tn: 752323.0000 - fn: 18174.0000 - accuracy: 0.5689 - precision: 0.6340 - recall: 0.4507 - auc: 0.9613 - prc: 0.5643 - f1: 0.2779 - mcc: 0.3334 - val_loss: 1.2783 - val_tp: 1683.0000 - val_fp: 939.0000 - val_tn: 94166.0000 - val_fn: 2452.0000 - val_accuracy: 0.5676 - val_precision: 0.6419 - val_recall: 0.4070 - val_auc: 0.9604 - val_prc: 0.5380 - val_f1: 0.3140 - val_mcc: 0.3722\n",
      "Epoch 17/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.4476 - tp: 14306.0000 - fp: 9565.0000 - tn: 751367.0000 - fn: 18778.0000 - accuracy: 0.5431 - precision: 0.5993 - recall: 0.4324 - auc: 0.9569 - prc: 0.5291 - f1: 0.2689 - mcc: 0.3237 - val_loss: 1.2503 - val_tp: 1742.0000 - val_fp: 932.0000 - val_tn: 94173.0000 - val_fn: 2393.0000 - val_accuracy: 0.5778 - val_precision: 0.6515 - val_recall: 0.4213 - val_auc: 0.9624 - val_prc: 0.5494 - val_f1: 0.2907 - val_mcc: 0.3711\n",
      "Epoch 18/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.4387 - tp: 15554.0000 - fp: 8791.0000 - tn: 752141.0000 - fn: 17530.0000 - accuracy: 0.5745 - precision: 0.6389 - recall: 0.4701 - auc: 0.9627 - prc: 0.5779 - f1: 0.2791 - mcc: 0.3358 - val_loss: 0.9745 - val_tp: 2307.0000 - val_fp: 771.0000 - val_tn: 94334.0000 - val_fn: 1828.0000 - val_accuracy: 0.6733 - val_precision: 0.7495 - val_recall: 0.5579 - val_auc: 0.9751 - val_prc: 0.6821 - val_f1: 0.3551 - val_mcc: 0.4270\n",
      "Epoch 19/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.4372 - tp: 15502.0000 - fp: 8788.0000 - tn: 752144.0000 - fn: 17582.0000 - accuracy: 0.5748 - precision: 0.6382 - recall: 0.4686 - auc: 0.9628 - prc: 0.5779 - f1: 0.2831 - mcc: 0.3368 - val_loss: 1.2544 - val_tp: 1764.0000 - val_fp: 1024.0000 - val_tn: 94081.0000 - val_fn: 2371.0000 - val_accuracy: 0.5652 - val_precision: 0.6327 - val_recall: 0.4266 - val_auc: 0.9624 - val_prc: 0.5494 - val_f1: 0.2798 - val_mcc: 0.3690\n",
      "Epoch 20/20\n",
      "2068/2068 [==============================] - 7s 4ms/step - loss: 0.4372 - tp: 15287.0000 - fp: 9021.0000 - tn: 751911.0000 - fn: 17797.0000 - accuracy: 0.5696 - precision: 0.6289 - recall: 0.4621 - auc: 0.9605 - prc: 0.5641 - f1: 0.2841 - mcc: 0.3360 - val_loss: 1.3203 - val_tp: 1702.0000 - val_fp: 1025.0000 - val_tn: 94080.0000 - val_fn: 2433.0000 - val_accuracy: 0.5620 - val_precision: 0.6241 - val_recall: 0.4116 - val_auc: 0.9569 - val_prc: 0.5200 - val_f1: 0.3099 - val_mcc: 0.3708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_8_80_T/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_8_80_T/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_10_80_T\n",
      "Training features shape: (51122, 10, 5)\n",
      "Training labels shape: (51122, 24)\n",
      "\n",
      "Dev (validation) features shape: (6390, 10, 5)\n",
      "Dev (validation) labels shape: (6390, 24)\n",
      "\n",
      "Input shape: (10, 5)\n",
      "\n",
      "Epoch 1/20\n",
      "3196/3196 [==============================] - 14s 4ms/step - loss: 1.7454 - tp: 1714.0000 - fp: 5839.0000 - tn: 1169967.0000 - fn: 49408.0000 - accuracy: 0.1898 - precision: 0.2269 - recall: 0.0335 - auc: 0.8359 - prc: 0.1593 - f1: 0.0641 - mcc: 0.0915 - val_loss: 2.2942 - val_tp: 192.0000 - val_fp: 1092.0000 - val_tn: 145878.0000 - val_fn: 6198.0000 - val_accuracy: 0.2235 - val_precision: 0.1495 - val_recall: 0.0300 - val_auc: 0.8799 - val_prc: 0.1892 - val_f1: 0.1178 - val_mcc: 0.1635\n",
      "Epoch 2/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.8403 - tp: 6980.0000 - fp: 12881.0000 - tn: 1162925.0000 - fn: 44142.0000 - accuracy: 0.3172 - precision: 0.3514 - recall: 0.1365 - auc: 0.9082 - prc: 0.2743 - f1: 0.1154 - mcc: 0.1640 - val_loss: 1.9922 - val_tp: 509.0000 - val_fp: 1258.0000 - val_tn: 145712.0000 - val_fn: 5881.0000 - val_accuracy: 0.2833 - val_precision: 0.2881 - val_recall: 0.0797 - val_auc: 0.9129 - val_prc: 0.2548 - val_f1: 0.1578 - val_mcc: 0.1920\n",
      "Epoch 3/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.6899 - tp: 10866.0000 - fp: 13667.0000 - tn: 1162139.0000 - fn: 40256.0000 - accuracy: 0.3890 - precision: 0.4429 - recall: 0.2126 - auc: 0.9330 - prc: 0.3521 - f1: 0.1414 - mcc: 0.1942 - val_loss: 1.3845 - val_tp: 1774.0000 - val_fp: 1090.0000 - val_tn: 145880.0000 - val_fn: 4616.0000 - val_accuracy: 0.4969 - val_precision: 0.6194 - val_recall: 0.2776 - val_auc: 0.9598 - val_prc: 0.4943 - val_f1: 0.2021 - val_mcc: 0.2517\n",
      "Epoch 4/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.5842 - tp: 14594.0000 - fp: 14214.0000 - tn: 1161592.0000 - fn: 36528.0000 - accuracy: 0.4406 - precision: 0.5066 - recall: 0.2855 - auc: 0.9436 - prc: 0.4118 - f1: 0.1614 - mcc: 0.2148 - val_loss: 1.4562 - val_tp: 1833.0000 - val_fp: 1256.0000 - val_tn: 145714.0000 - val_fn: 4557.0000 - val_accuracy: 0.4898 - val_precision: 0.5934 - val_recall: 0.2869 - val_auc: 0.9529 - val_prc: 0.4700 - val_f1: 0.1734 - val_mcc: 0.2583\n",
      "Epoch 5/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.5378 - tp: 15217.0000 - fp: 15165.0000 - tn: 1160641.0000 - fn: 35905.0000 - accuracy: 0.4439 - precision: 0.5009 - recall: 0.2977 - auc: 0.9442 - prc: 0.4143 - f1: 0.1603 - mcc: 0.2252 - val_loss: 1.5528 - val_tp: 1463.0000 - val_fp: 1685.0000 - val_tn: 145285.0000 - val_fn: 4927.0000 - val_accuracy: 0.4218 - val_precision: 0.4647 - val_recall: 0.2290 - val_auc: 0.9468 - val_prc: 0.3793 - val_f1: 0.2272 - val_mcc: 0.2313\n",
      "Epoch 6/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.4908 - tp: 16907.0000 - fp: 15159.0000 - tn: 1160647.0000 - fn: 34215.0000 - accuracy: 0.4718 - precision: 0.5273 - recall: 0.3307 - auc: 0.9515 - prc: 0.4482 - f1: 0.1802 - mcc: 0.2368 - val_loss: 1.1680 - val_tp: 2621.0000 - val_fp: 1405.0000 - val_tn: 145565.0000 - val_fn: 3769.0000 - val_accuracy: 0.5648 - val_precision: 0.6510 - val_recall: 0.4102 - val_auc: 0.9698 - val_prc: 0.5764 - val_f1: 0.2290 - val_mcc: 0.3048\n",
      "Epoch 7/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.4899 - tp: 17972.0000 - fp: 15805.0000 - tn: 1160001.0000 - fn: 33150.0000 - accuracy: 0.4814 - precision: 0.5321 - recall: 0.3516 - auc: 0.9527 - prc: 0.4587 - f1: 0.1814 - mcc: 0.2413 - val_loss: 1.2730 - val_tp: 2177.0000 - val_fp: 1468.0000 - val_tn: 145502.0000 - val_fn: 4213.0000 - val_accuracy: 0.5321 - val_precision: 0.5973 - val_recall: 0.3407 - val_auc: 0.9640 - val_prc: 0.5137 - val_f1: 0.1968 - val_mcc: 0.2877\n",
      "Epoch 8/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.4576 - tp: 19230.0000 - fp: 15366.0000 - tn: 1160440.0000 - fn: 31892.0000 - accuracy: 0.5042 - precision: 0.5558 - recall: 0.3762 - auc: 0.9554 - prc: 0.4854 - f1: 0.1924 - mcc: 0.2535 - val_loss: 1.2383 - val_tp: 2640.0000 - val_fp: 1477.0000 - val_tn: 145493.0000 - val_fn: 3750.0000 - val_accuracy: 0.5689 - val_precision: 0.6412 - val_recall: 0.4131 - val_auc: 0.9630 - val_prc: 0.5487 - val_f1: 0.2096 - val_mcc: 0.3086\n",
      "Epoch 9/20\n",
      "3196/3196 [==============================] - 12s 4ms/step - loss: 0.4518 - tp: 20467.0000 - fp: 14615.0000 - tn: 1161191.0000 - fn: 30655.0000 - accuracy: 0.5247 - precision: 0.5834 - recall: 0.4004 - auc: 0.9590 - prc: 0.5133 - f1: 0.2087 - mcc: 0.2652 - val_loss: 1.0956 - val_tp: 2996.0000 - val_fp: 1445.0000 - val_tn: 145525.0000 - val_fn: 3394.0000 - val_accuracy: 0.6164 - val_precision: 0.6746 - val_recall: 0.4689 - val_auc: 0.9713 - val_prc: 0.6114 - val_f1: 0.2245 - val_mcc: 0.3283\n",
      "Epoch 10/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.4324 - tp: 21774.0000 - fp: 15300.0000 - tn: 1160506.0000 - fn: 29348.0000 - accuracy: 0.5322 - precision: 0.5873 - recall: 0.4259 - auc: 0.9592 - prc: 0.5281 - f1: 0.2150 - mcc: 0.2666 - val_loss: 1.5288 - val_tp: 1936.0000 - val_fp: 1960.0000 - val_tn: 145010.0000 - val_fn: 4454.0000 - val_accuracy: 0.4495 - val_precision: 0.4969 - val_recall: 0.3030 - val_auc: 0.9463 - val_prc: 0.4108 - val_f1: 0.2050 - val_mcc: 0.2600\n",
      "Epoch 11/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.4319 - tp: 22103.0000 - fp: 15244.0000 - tn: 1160562.0000 - fn: 29019.0000 - accuracy: 0.5344 - precision: 0.5918 - recall: 0.4324 - auc: 0.9594 - prc: 0.5324 - f1: 0.2180 - mcc: 0.2667 - val_loss: 1.4083 - val_tp: 1870.0000 - val_fp: 1818.0000 - val_tn: 145152.0000 - val_fn: 4520.0000 - val_accuracy: 0.4502 - val_precision: 0.5070 - val_recall: 0.2926 - val_auc: 0.9561 - val_prc: 0.4374 - val_f1: 0.2350 - val_mcc: 0.2575\n",
      "Epoch 12/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.4181 - tp: 22468.0000 - fp: 14955.0000 - tn: 1160851.0000 - fn: 28654.0000 - accuracy: 0.5444 - precision: 0.6004 - recall: 0.4395 - auc: 0.9625 - prc: 0.5493 - f1: 0.2247 - mcc: 0.2763 - val_loss: 1.4264 - val_tp: 1965.0000 - val_fp: 1609.0000 - val_tn: 145361.0000 - val_fn: 4425.0000 - val_accuracy: 0.4707 - val_precision: 0.5498 - val_recall: 0.3075 - val_auc: 0.9546 - val_prc: 0.4479 - val_f1: 0.2364 - val_mcc: 0.2709\n",
      "Epoch 13/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.4137 - tp: 21824.0000 - fp: 15337.0000 - tn: 1160469.0000 - fn: 29298.0000 - accuracy: 0.5302 - precision: 0.5873 - recall: 0.4269 - auc: 0.9602 - prc: 0.5286 - f1: 0.2164 - mcc: 0.2687 - val_loss: 1.4952 - val_tp: 1978.0000 - val_fp: 1832.0000 - val_tn: 145138.0000 - val_fn: 4412.0000 - val_accuracy: 0.4562 - val_precision: 0.5192 - val_recall: 0.3095 - val_auc: 0.9486 - val_prc: 0.4262 - val_f1: 0.2150 - val_mcc: 0.2584\n",
      "Epoch 14/20\n",
      "3196/3196 [==============================] - 12s 4ms/step - loss: 0.3979 - tp: 23175.0000 - fp: 15144.0000 - tn: 1160662.0000 - fn: 27947.0000 - accuracy: 0.5498 - precision: 0.6048 - recall: 0.4533 - auc: 0.9626 - prc: 0.5539 - f1: 0.2250 - mcc: 0.2809 - val_loss: 1.3923 - val_tp: 2240.0000 - val_fp: 1882.0000 - val_tn: 145088.0000 - val_fn: 4150.0000 - val_accuracy: 0.4897 - val_precision: 0.5434 - val_recall: 0.3505 - val_auc: 0.9551 - val_prc: 0.4648 - val_f1: 0.2308 - val_mcc: 0.2735\n",
      "Epoch 15/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.3799 - tp: 24937.0000 - fp: 14583.0000 - tn: 1161223.0000 - fn: 26185.0000 - accuracy: 0.5769 - precision: 0.6310 - recall: 0.4878 - auc: 0.9654 - prc: 0.5885 - f1: 0.2481 - mcc: 0.2906 - val_loss: 1.3898 - val_tp: 2311.0000 - val_fp: 1969.0000 - val_tn: 145001.0000 - val_fn: 4079.0000 - val_accuracy: 0.4770 - val_precision: 0.5400 - val_recall: 0.3617 - val_auc: 0.9558 - val_prc: 0.4625 - val_f1: 0.2319 - val_mcc: 0.2709\n",
      "Epoch 16/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.3921 - tp: 24857.0000 - fp: 14718.0000 - tn: 1161088.0000 - fn: 26265.0000 - accuracy: 0.5711 - precision: 0.6281 - recall: 0.4862 - auc: 0.9634 - prc: 0.5849 - f1: 0.2332 - mcc: 0.2901 - val_loss: 1.5530 - val_tp: 1983.0000 - val_fp: 2198.0000 - val_tn: 144772.0000 - val_fn: 4407.0000 - val_accuracy: 0.4272 - val_precision: 0.4743 - val_recall: 0.3103 - val_auc: 0.9458 - val_prc: 0.4048 - val_f1: 0.2526 - val_mcc: 0.2493\n",
      "Epoch 17/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.4000 - tp: 25346.0000 - fp: 14862.0000 - tn: 1160944.0000 - fn: 25776.0000 - accuracy: 0.5755 - precision: 0.6304 - recall: 0.4958 - auc: 0.9633 - prc: 0.5887 - f1: 0.2394 - mcc: 0.2903 - val_loss: 1.2077 - val_tp: 2807.0000 - val_fp: 1491.0000 - val_tn: 145479.0000 - val_fn: 3583.0000 - val_accuracy: 0.5604 - val_precision: 0.6531 - val_recall: 0.4393 - val_auc: 0.9651 - val_prc: 0.5703 - val_f1: 0.2469 - val_mcc: 0.3022\n",
      "Epoch 18/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.3988 - tp: 24618.0000 - fp: 14539.0000 - tn: 1161267.0000 - fn: 26504.0000 - accuracy: 0.5664 - precision: 0.6287 - recall: 0.4816 - auc: 0.9632 - prc: 0.5845 - f1: 0.2322 - mcc: 0.2869 - val_loss: 1.1370 - val_tp: 3107.0000 - val_fp: 1536.0000 - val_tn: 145434.0000 - val_fn: 3283.0000 - val_accuracy: 0.5911 - val_precision: 0.6692 - val_recall: 0.4862 - val_auc: 0.9678 - val_prc: 0.6046 - val_f1: 0.2584 - val_mcc: 0.3192\n",
      "Epoch 19/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.3769 - tp: 24776.0000 - fp: 14257.0000 - tn: 1161549.0000 - fn: 26346.0000 - accuracy: 0.5714 - precision: 0.6347 - recall: 0.4846 - auc: 0.9651 - prc: 0.5915 - f1: 0.2372 - mcc: 0.2926 - val_loss: 1.3314 - val_tp: 2654.0000 - val_fp: 1786.0000 - val_tn: 145184.0000 - val_fn: 3736.0000 - val_accuracy: 0.5282 - val_precision: 0.5977 - val_recall: 0.4153 - val_auc: 0.9576 - val_prc: 0.5177 - val_f1: 0.2328 - val_mcc: 0.2882\n",
      "Epoch 20/20\n",
      "3196/3196 [==============================] - 11s 4ms/step - loss: 0.4086 - tp: 23510.0000 - fp: 15209.0000 - tn: 1160597.0000 - fn: 27612.0000 - accuracy: 0.5459 - precision: 0.6072 - recall: 0.4599 - auc: 0.9598 - prc: 0.5553 - f1: 0.2276 - mcc: 0.2785 - val_loss: 1.6672 - val_tp: 1785.0000 - val_fp: 2119.0000 - val_tn: 144851.0000 - val_fn: 4605.0000 - val_accuracy: 0.4033 - val_precision: 0.4572 - val_recall: 0.2793 - val_auc: 0.9379 - val_prc: 0.3730 - val_f1: 0.2324 - val_mcc: 0.2433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_10_80_T/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_10_80_T/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_16_80_T\n",
      "Training features shape: (57528, 16, 5)\n",
      "Training labels shape: (57528, 24)\n",
      "\n",
      "Dev (validation) features shape: (7191, 16, 5)\n",
      "Dev (validation) labels shape: (7191, 24)\n",
      "\n",
      "Input shape: (16, 5)\n",
      "\n",
      "Epoch 1/20\n",
      "3596/3596 [==============================] - 16s 4ms/step - loss: 1.4151 - tp: 3929.0000 - fp: 7863.0000 - tn: 1315281.0000 - fn: 53599.0000 - accuracy: 0.2248 - precision: 0.3332 - recall: 0.0683 - auc: 0.8557 - prc: 0.2018 - f1: 0.0829 - mcc: 0.1137 - val_loss: 1.7091 - val_tp: 560.0000 - val_fp: 531.0000 - val_tn: 164862.0000 - val_fn: 6631.0000 - val_accuracy: 0.4070 - val_precision: 0.5133 - val_recall: 0.0779 - val_auc: 0.9453 - val_prc: 0.3845 - val_f1: 0.2257 - val_mcc: 0.2207\n",
      "Epoch 2/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.6191 - tp: 11783.0000 - fp: 14191.0000 - tn: 1308953.0000 - fn: 45745.0000 - accuracy: 0.3874 - precision: 0.4536 - recall: 0.2048 - auc: 0.9305 - prc: 0.3619 - f1: 0.1631 - mcc: 0.1973 - val_loss: 1.8750 - val_tp: 721.0000 - val_fp: 1024.0000 - val_tn: 164369.0000 - val_fn: 6470.0000 - val_accuracy: 0.3173 - val_precision: 0.4132 - val_recall: 0.1003 - val_auc: 0.9244 - val_prc: 0.3064 - val_f1: 0.2145 - val_mcc: 0.2038\n",
      "Epoch 3/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.4792 - tp: 16484.0000 - fp: 15077.0000 - tn: 1308067.0000 - fn: 41044.0000 - accuracy: 0.4496 - precision: 0.5223 - recall: 0.2865 - auc: 0.9476 - prc: 0.4431 - f1: 0.1890 - mcc: 0.2273 - val_loss: 1.5273 - val_tp: 1322.0000 - val_fp: 1383.0000 - val_tn: 164010.0000 - val_fn: 5869.0000 - val_accuracy: 0.4205 - val_precision: 0.4887 - val_recall: 0.1838 - val_auc: 0.9513 - val_prc: 0.4124 - val_f1: 0.2094 - val_mcc: 0.2367\n",
      "Epoch 4/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.4344 - tp: 20044.0000 - fp: 15750.0000 - tn: 1307394.0000 - fn: 37484.0000 - accuracy: 0.4983 - precision: 0.5600 - recall: 0.3484 - auc: 0.9570 - prc: 0.4958 - f1: 0.2082 - mcc: 0.2468 - val_loss: 1.4623 - val_tp: 1505.0000 - val_fp: 1839.0000 - val_tn: 163554.0000 - val_fn: 5686.0000 - val_accuracy: 0.4102 - val_precision: 0.4501 - val_recall: 0.2093 - val_auc: 0.9553 - val_prc: 0.4205 - val_f1: 0.2704 - val_mcc: 0.2450\n",
      "Epoch 5/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.3981 - tp: 20889.0000 - fp: 16878.0000 - tn: 1306266.0000 - fn: 36639.0000 - accuracy: 0.4997 - precision: 0.5531 - recall: 0.3631 - auc: 0.9564 - prc: 0.4944 - f1: 0.2334 - mcc: 0.2515 - val_loss: 1.0692 - val_tp: 2831.0000 - val_fp: 1190.0000 - val_tn: 164203.0000 - val_fn: 4360.0000 - val_accuracy: 0.6227 - val_precision: 0.7041 - val_recall: 0.3937 - val_auc: 0.9770 - val_prc: 0.6409 - val_f1: 0.2617 - val_mcc: 0.3229\n",
      "Epoch 6/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.3804 - tp: 23440.0000 - fp: 16904.0000 - tn: 1306240.0000 - fn: 34088.0000 - accuracy: 0.5252 - precision: 0.5810 - recall: 0.4075 - auc: 0.9587 - prc: 0.5289 - f1: 0.2147 - mcc: 0.2623 - val_loss: 1.1367 - val_tp: 2769.0000 - val_fp: 1507.0000 - val_tn: 163886.0000 - val_fn: 4422.0000 - val_accuracy: 0.5764 - val_precision: 0.6476 - val_recall: 0.3851 - val_auc: 0.9721 - val_prc: 0.5946 - val_f1: 0.2715 - val_mcc: 0.3010\n",
      "Epoch 7/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.3571 - tp: 24731.0000 - fp: 15845.0000 - tn: 1307299.0000 - fn: 32797.0000 - accuracy: 0.5534 - precision: 0.6095 - recall: 0.4299 - auc: 0.9659 - prc: 0.5670 - f1: 0.2421 - mcc: 0.2759 - val_loss: 1.3784 - val_tp: 2024.0000 - val_fp: 1608.0000 - val_tn: 163785.0000 - val_fn: 5167.0000 - val_accuracy: 0.4933 - val_precision: 0.5573 - val_recall: 0.2815 - val_auc: 0.9587 - val_prc: 0.4816 - val_f1: 0.2150 - val_mcc: 0.2666\n",
      "Epoch 8/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.3476 - tp: 27737.0000 - fp: 15325.0000 - tn: 1307819.0000 - fn: 29791.0000 - accuracy: 0.5840 - precision: 0.6441 - recall: 0.4821 - auc: 0.9679 - prc: 0.6115 - f1: 0.2442 - mcc: 0.2888 - val_loss: 1.3790 - val_tp: 2025.0000 - val_fp: 1615.0000 - val_tn: 163778.0000 - val_fn: 5166.0000 - val_accuracy: 0.4731 - val_precision: 0.5563 - val_recall: 0.2816 - val_auc: 0.9588 - val_prc: 0.4854 - val_f1: 0.2158 - val_mcc: 0.2612\n",
      "Epoch 9/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.3419 - tp: 28830.0000 - fp: 15177.0000 - tn: 1307967.0000 - fn: 28698.0000 - accuracy: 0.6003 - precision: 0.6551 - recall: 0.5011 - auc: 0.9712 - prc: 0.6313 - f1: 0.2517 - mcc: 0.2955 - val_loss: 1.0285 - val_tp: 3254.0000 - val_fp: 1364.0000 - val_tn: 164029.0000 - val_fn: 3937.0000 - val_accuracy: 0.6134 - val_precision: 0.7046 - val_recall: 0.4525 - val_auc: 0.9769 - val_prc: 0.6602 - val_f1: 0.2864 - val_mcc: 0.3162\n",
      "Epoch 10/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.3149 - tp: 27653.0000 - fp: 15300.0000 - tn: 1307844.0000 - fn: 29875.0000 - accuracy: 0.5854 - precision: 0.6438 - recall: 0.4807 - auc: 0.9708 - prc: 0.6199 - f1: 0.2676 - mcc: 0.2909 - val_loss: 1.1781 - val_tp: 2916.0000 - val_fp: 1649.0000 - val_tn: 163744.0000 - val_fn: 4275.0000 - val_accuracy: 0.5646 - val_precision: 0.6388 - val_recall: 0.4055 - val_auc: 0.9684 - val_prc: 0.5794 - val_f1: 0.2391 - val_mcc: 0.2961\n",
      "Epoch 11/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.3228 - tp: 29296.0000 - fp: 15295.0000 - tn: 1307849.0000 - fn: 28232.0000 - accuracy: 0.6045 - precision: 0.6570 - recall: 0.5092 - auc: 0.9717 - prc: 0.6383 - f1: 0.2619 - mcc: 0.3009 - val_loss: 1.0139 - val_tp: 3305.0000 - val_fp: 1475.0000 - val_tn: 163918.0000 - val_fn: 3886.0000 - val_accuracy: 0.6188 - val_precision: 0.6914 - val_recall: 0.4596 - val_auc: 0.9774 - val_prc: 0.6578 - val_f1: 0.2495 - val_mcc: 0.3196\n",
      "Epoch 12/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.3115 - tp: 29365.0000 - fp: 15523.0000 - tn: 1307621.0000 - fn: 28163.0000 - accuracy: 0.6015 - precision: 0.6542 - recall: 0.5104 - auc: 0.9727 - prc: 0.6421 - f1: 0.2571 - mcc: 0.2996 - val_loss: 1.1591 - val_tp: 2903.0000 - val_fp: 1773.0000 - val_tn: 163620.0000 - val_fn: 4288.0000 - val_accuracy: 0.5571 - val_precision: 0.6208 - val_recall: 0.4037 - val_auc: 0.9686 - val_prc: 0.5665 - val_f1: 0.2507 - val_mcc: 0.2962\n",
      "Epoch 13/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.3024 - tp: 32473.0000 - fp: 14450.0000 - tn: 1308694.0000 - fn: 25055.0000 - accuracy: 0.6427 - precision: 0.6920 - recall: 0.5645 - auc: 0.9762 - prc: 0.6890 - f1: 0.2773 - mcc: 0.3193 - val_loss: 1.0939 - val_tp: 3170.0000 - val_fp: 1679.0000 - val_tn: 163714.0000 - val_fn: 4021.0000 - val_accuracy: 0.5821 - val_precision: 0.6537 - val_recall: 0.4408 - val_auc: 0.9724 - val_prc: 0.6160 - val_f1: 0.2792 - val_mcc: 0.3011\n",
      "Epoch 14/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.3153 - tp: 32295.0000 - fp: 14334.0000 - tn: 1308810.0000 - fn: 25233.0000 - accuracy: 0.6407 - precision: 0.6926 - recall: 0.5614 - auc: 0.9758 - prc: 0.6937 - f1: 0.2804 - mcc: 0.3182 - val_loss: 1.2627 - val_tp: 2534.0000 - val_fp: 1643.0000 - val_tn: 163750.0000 - val_fn: 4657.0000 - val_accuracy: 0.5179 - val_precision: 0.6067 - val_recall: 0.3524 - val_auc: 0.9638 - val_prc: 0.5333 - val_f1: 0.2698 - val_mcc: 0.2756\n",
      "Epoch 15/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.3143 - tp: 28967.0000 - fp: 15948.0000 - tn: 1307196.0000 - fn: 28561.0000 - accuracy: 0.5915 - precision: 0.6449 - recall: 0.5035 - auc: 0.9711 - prc: 0.6293 - f1: 0.2818 - mcc: 0.2938 - val_loss: 1.2248 - val_tp: 2558.0000 - val_fp: 1728.0000 - val_tn: 163665.0000 - val_fn: 4633.0000 - val_accuracy: 0.5251 - val_precision: 0.5968 - val_recall: 0.3557 - val_auc: 0.9672 - val_prc: 0.5421 - val_f1: 0.2666 - val_mcc: 0.2856\n",
      "Epoch 16/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.2981 - tp: 32613.0000 - fp: 14212.0000 - tn: 1308932.0000 - fn: 24915.0000 - accuracy: 0.6419 - precision: 0.6965 - recall: 0.5669 - auc: 0.9766 - prc: 0.6957 - f1: 0.2979 - mcc: 0.3214 - val_loss: 1.2275 - val_tp: 2918.0000 - val_fp: 1854.0000 - val_tn: 163539.0000 - val_fn: 4273.0000 - val_accuracy: 0.5355 - val_precision: 0.6115 - val_recall: 0.4058 - val_auc: 0.9657 - val_prc: 0.5578 - val_f1: 0.2664 - val_mcc: 0.2877\n",
      "Epoch 17/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.2892 - tp: 32274.0000 - fp: 14666.0000 - tn: 1308478.0000 - fn: 25254.0000 - accuracy: 0.6348 - precision: 0.6876 - recall: 0.5610 - auc: 0.9740 - prc: 0.6846 - f1: 0.2760 - mcc: 0.3195 - val_loss: 1.2210 - val_tp: 3006.0000 - val_fp: 1810.0000 - val_tn: 163583.0000 - val_fn: 4185.0000 - val_accuracy: 0.5490 - val_precision: 0.6242 - val_recall: 0.4180 - val_auc: 0.9660 - val_prc: 0.5657 - val_f1: 0.2380 - val_mcc: 0.2915\n",
      "Epoch 18/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.2830 - tp: 32676.0000 - fp: 14199.0000 - tn: 1308945.0000 - fn: 24852.0000 - accuracy: 0.6401 - precision: 0.6971 - recall: 0.5680 - auc: 0.9753 - prc: 0.7005 - f1: 0.2755 - mcc: 0.3202 - val_loss: 1.4154 - val_tp: 2332.0000 - val_fp: 2417.0000 - val_tn: 162976.0000 - val_fn: 4859.0000 - val_accuracy: 0.4321 - val_precision: 0.4911 - val_recall: 0.3243 - val_auc: 0.9560 - val_prc: 0.4546 - val_f1: 0.2786 - val_mcc: 0.2568\n",
      "Epoch 19/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.2940 - tp: 32485.0000 - fp: 14976.0000 - tn: 1308168.0000 - fn: 25043.0000 - accuracy: 0.6304 - precision: 0.6845 - recall: 0.5647 - auc: 0.9718 - prc: 0.6844 - f1: 0.2998 - mcc: 0.3163 - val_loss: 1.1649 - val_tp: 2940.0000 - val_fp: 1546.0000 - val_tn: 163847.0000 - val_fn: 4251.0000 - val_accuracy: 0.5581 - val_precision: 0.6554 - val_recall: 0.4088 - val_auc: 0.9696 - val_prc: 0.5976 - val_f1: 0.2622 - val_mcc: 0.2941\n",
      "Epoch 20/20\n",
      "3596/3596 [==============================] - 13s 4ms/step - loss: 0.3067 - tp: 33436.0000 - fp: 14586.0000 - tn: 1308558.0000 - fn: 24092.0000 - accuracy: 0.6454 - precision: 0.6963 - recall: 0.5812 - auc: 0.9742 - prc: 0.7021 - f1: 0.3132 - mcc: 0.3249 - val_loss: 1.4496 - val_tp: 2475.0000 - val_fp: 2258.0000 - val_tn: 163135.0000 - val_fn: 4716.0000 - val_accuracy: 0.4634 - val_precision: 0.5229 - val_recall: 0.3442 - val_auc: 0.9518 - val_prc: 0.4754 - val_f1: 0.2544 - val_mcc: 0.2652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_16_80_T/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_16_80_T/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_12_80_T\n",
      "Training features shape: (54845, 12, 5)\n",
      "Training labels shape: (54845, 24)\n",
      "\n",
      "Dev (validation) features shape: (6856, 12, 5)\n",
      "Dev (validation) labels shape: (6856, 24)\n",
      "\n",
      "Input shape: (12, 5)\n",
      "\n",
      "Epoch 1/20\n",
      "3428/3428 [==============================] - 15s 4ms/step - loss: 1.4849 - tp: 2345.0000 - fp: 6934.0000 - tn: 1254501.0000 - fn: 52500.0000 - accuracy: 0.1739 - precision: 0.2527 - recall: 0.0428 - auc: 0.8332 - prc: 0.1591 - f1: 0.0713 - mcc: 0.0964 - val_loss: 1.8267 - val_tp: 461.0000 - val_fp: 797.0000 - val_tn: 156891.0000 - val_fn: 6395.0000 - val_accuracy: 0.2930 - val_precision: 0.3665 - val_recall: 0.0672 - val_auc: 0.9292 - val_prc: 0.2907 - val_f1: 0.2262 - val_mcc: 0.1824\n",
      "Epoch 2/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.7007 - tp: 7786.0000 - fp: 14616.0000 - tn: 1246819.0000 - fn: 47059.0000 - accuracy: 0.3029 - precision: 0.3476 - recall: 0.1420 - auc: 0.9148 - prc: 0.2809 - f1: 0.1364 - mcc: 0.1666 - val_loss: 1.4077 - val_tp: 1428.0000 - val_fp: 1311.0000 - val_tn: 156377.0000 - val_fn: 5428.0000 - val_accuracy: 0.4783 - val_precision: 0.5214 - val_recall: 0.2083 - val_auc: 0.9610 - val_prc: 0.4603 - val_f1: 0.2074 - val_mcc: 0.2397\n",
      "Epoch 3/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.5722 - tp: 11021.0000 - fp: 15516.0000 - tn: 1245919.0000 - fn: 43824.0000 - accuracy: 0.3662 - precision: 0.4153 - recall: 0.2009 - auc: 0.9364 - prc: 0.3496 - f1: 0.1612 - mcc: 0.1918 - val_loss: 2.3441 - val_tp: 356.0000 - val_fp: 2053.0000 - val_tn: 155635.0000 - val_fn: 6500.0000 - val_accuracy: 0.0955 - val_precision: 0.1478 - val_recall: 0.0519 - val_auc: 0.8901 - val_prc: 0.1848 - val_f1: 0.2007 - val_mcc: 0.1752\n",
      "Epoch 4/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.5005 - tp: 13273.0000 - fp: 16880.0000 - tn: 1244555.0000 - fn: 41572.0000 - accuracy: 0.3960 - precision: 0.4402 - recall: 0.2420 - auc: 0.9420 - prc: 0.3764 - f1: 0.1804 - mcc: 0.2070 - val_loss: 1.9443 - val_tp: 718.0000 - val_fp: 1727.0000 - val_tn: 155961.0000 - val_fn: 6138.0000 - val_accuracy: 0.2698 - val_precision: 0.2937 - val_recall: 0.1047 - val_auc: 0.9178 - val_prc: 0.2660 - val_f1: 0.1530 - val_mcc: 0.1945\n",
      "Epoch 5/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.4702 - tp: 16030.0000 - fp: 16506.0000 - tn: 1244929.0000 - fn: 38815.0000 - accuracy: 0.4418 - precision: 0.4927 - recall: 0.2923 - auc: 0.9503 - prc: 0.4250 - f1: 0.1884 - mcc: 0.2240 - val_loss: 1.8096 - val_tp: 683.0000 - val_fp: 1948.0000 - val_tn: 155740.0000 - val_fn: 6173.0000 - val_accuracy: 0.2739 - val_precision: 0.2596 - val_recall: 0.0996 - val_auc: 0.9300 - val_prc: 0.2803 - val_f1: 0.1935 - val_mcc: 0.1731\n",
      "Epoch 6/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.4325 - tp: 17578.0000 - fp: 17234.0000 - tn: 1244201.0000 - fn: 37267.0000 - accuracy: 0.4610 - precision: 0.5049 - recall: 0.3205 - auc: 0.9520 - prc: 0.4410 - f1: 0.1992 - mcc: 0.2340 - val_loss: 1.5720 - val_tp: 1342.0000 - val_fp: 1746.0000 - val_tn: 155942.0000 - val_fn: 5514.0000 - val_accuracy: 0.3928 - val_precision: 0.4346 - val_recall: 0.1957 - val_auc: 0.9465 - val_prc: 0.3713 - val_f1: 0.1973 - val_mcc: 0.2324\n",
      "Epoch 7/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.4353 - tp: 19683.0000 - fp: 16603.0000 - tn: 1244832.0000 - fn: 35162.0000 - accuracy: 0.4843 - precision: 0.5424 - recall: 0.3589 - auc: 0.9568 - prc: 0.4790 - f1: 0.2136 - mcc: 0.2427 - val_loss: 1.5542 - val_tp: 1415.0000 - val_fp: 2069.0000 - val_tn: 155619.0000 - val_fn: 5441.0000 - val_accuracy: 0.3541 - val_precision: 0.4061 - val_recall: 0.2064 - val_auc: 0.9480 - val_prc: 0.3679 - val_f1: 0.2498 - val_mcc: 0.2216\n",
      "Epoch 8/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.4183 - tp: 22168.0000 - fp: 16098.0000 - tn: 1245337.0000 - fn: 32677.0000 - accuracy: 0.5158 - precision: 0.5793 - recall: 0.4042 - auc: 0.9607 - prc: 0.5279 - f1: 0.2246 - mcc: 0.2557 - val_loss: 1.3440 - val_tp: 2259.0000 - val_fp: 1752.0000 - val_tn: 155936.0000 - val_fn: 4597.0000 - val_accuracy: 0.4943 - val_precision: 0.5632 - val_recall: 0.3295 - val_auc: 0.9585 - val_prc: 0.4749 - val_f1: 0.2350 - val_mcc: 0.2581\n",
      "Epoch 9/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.3878 - tp: 22057.0000 - fp: 16484.0000 - tn: 1244951.0000 - fn: 32788.0000 - accuracy: 0.5104 - precision: 0.5723 - recall: 0.4022 - auc: 0.9600 - prc: 0.5170 - f1: 0.2306 - mcc: 0.2558 - val_loss: 1.3194 - val_tp: 2346.0000 - val_fp: 1742.0000 - val_tn: 155946.0000 - val_fn: 4510.0000 - val_accuracy: 0.5022 - val_precision: 0.5739 - val_recall: 0.3422 - val_auc: 0.9611 - val_prc: 0.4993 - val_f1: 0.2156 - val_mcc: 0.2671\n",
      "Epoch 10/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.3779 - tp: 22707.0000 - fp: 17409.0000 - tn: 1244026.0000 - fn: 32138.0000 - accuracy: 0.5109 - precision: 0.5660 - recall: 0.4140 - auc: 0.9590 - prc: 0.5186 - f1: 0.2310 - mcc: 0.2584 - val_loss: 1.4203 - val_tp: 2176.0000 - val_fp: 1970.0000 - val_tn: 155718.0000 - val_fn: 4680.0000 - val_accuracy: 0.4560 - val_precision: 0.5248 - val_recall: 0.3174 - val_auc: 0.9550 - val_prc: 0.4544 - val_f1: 0.2133 - val_mcc: 0.2529\n",
      "Epoch 11/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.3756 - tp: 22434.0000 - fp: 17417.0000 - tn: 1244018.0000 - fn: 32411.0000 - accuracy: 0.5054 - precision: 0.5629 - recall: 0.4090 - auc: 0.9604 - prc: 0.5215 - f1: 0.2334 - mcc: 0.2554 - val_loss: 1.4324 - val_tp: 2136.0000 - val_fp: 1921.0000 - val_tn: 155767.0000 - val_fn: 4720.0000 - val_accuracy: 0.4603 - val_precision: 0.5265 - val_recall: 0.3116 - val_auc: 0.9530 - val_prc: 0.4434 - val_f1: 0.2155 - val_mcc: 0.2427\n",
      "Epoch 12/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.3743 - tp: 24497.0000 - fp: 16632.0000 - tn: 1244803.0000 - fn: 30348.0000 - accuracy: 0.5347 - precision: 0.5956 - recall: 0.4467 - auc: 0.9631 - prc: 0.5630 - f1: 0.2433 - mcc: 0.2674 - val_loss: 1.1466 - val_tp: 2936.0000 - val_fp: 1653.0000 - val_tn: 156035.0000 - val_fn: 3920.0000 - val_accuracy: 0.5623 - val_precision: 0.6398 - val_recall: 0.4282 - val_auc: 0.9694 - val_prc: 0.5902 - val_f1: 0.2489 - val_mcc: 0.2931\n",
      "Epoch 13/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.3681 - tp: 25867.0000 - fp: 16168.0000 - tn: 1245267.0000 - fn: 28978.0000 - accuracy: 0.5533 - precision: 0.6154 - recall: 0.4716 - auc: 0.9653 - prc: 0.5882 - f1: 0.2499 - mcc: 0.2784 - val_loss: 1.1782 - val_tp: 2824.0000 - val_fp: 1678.0000 - val_tn: 156010.0000 - val_fn: 4032.0000 - val_accuracy: 0.5527 - val_precision: 0.6273 - val_recall: 0.4119 - val_auc: 0.9681 - val_prc: 0.5652 - val_f1: 0.2177 - val_mcc: 0.2824\n",
      "Epoch 14/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.3456 - tp: 25110.0000 - fp: 17281.0000 - tn: 1244154.0000 - fn: 29735.0000 - accuracy: 0.5392 - precision: 0.5923 - recall: 0.4578 - auc: 0.9633 - prc: 0.5617 - f1: 0.2603 - mcc: 0.2750 - val_loss: 1.3472 - val_tp: 2482.0000 - val_fp: 1900.0000 - val_tn: 155788.0000 - val_fn: 4374.0000 - val_accuracy: 0.4899 - val_precision: 0.5664 - val_recall: 0.3620 - val_auc: 0.9581 - val_prc: 0.4951 - val_f1: 0.2325 - val_mcc: 0.2630\n",
      "Epoch 15/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.3477 - tp: 25735.0000 - fp: 17382.0000 - tn: 1244053.0000 - fn: 29110.0000 - accuracy: 0.5481 - precision: 0.5969 - recall: 0.4692 - auc: 0.9638 - prc: 0.5691 - f1: 0.2594 - mcc: 0.2752 - val_loss: 1.3273 - val_tp: 2652.0000 - val_fp: 1893.0000 - val_tn: 155795.0000 - val_fn: 4204.0000 - val_accuracy: 0.5200 - val_precision: 0.5835 - val_recall: 0.3868 - val_auc: 0.9585 - val_prc: 0.5087 - val_f1: 0.2199 - val_mcc: 0.2680\n",
      "Epoch 16/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.3664 - tp: 26097.0000 - fp: 16523.0000 - tn: 1244912.0000 - fn: 28748.0000 - accuracy: 0.5599 - precision: 0.6123 - recall: 0.4758 - auc: 0.9651 - prc: 0.5799 - f1: 0.2478 - mcc: 0.2806 - val_loss: 1.6676 - val_tp: 1709.0000 - val_fp: 2351.0000 - val_tn: 155337.0000 - val_fn: 5147.0000 - val_accuracy: 0.3819 - val_precision: 0.4209 - val_recall: 0.2493 - val_auc: 0.9394 - val_prc: 0.3587 - val_f1: 0.2234 - val_mcc: 0.2104\n",
      "Epoch 17/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.3814 - tp: 25620.0000 - fp: 16638.0000 - tn: 1244797.0000 - fn: 29225.0000 - accuracy: 0.5496 - precision: 0.6063 - recall: 0.4671 - auc: 0.9631 - prc: 0.5693 - f1: 0.2574 - mcc: 0.2786 - val_loss: 1.3396 - val_tp: 2469.0000 - val_fp: 1630.0000 - val_tn: 156058.0000 - val_fn: 4387.0000 - val_accuracy: 0.5104 - val_precision: 0.6023 - val_recall: 0.3601 - val_auc: 0.9589 - val_prc: 0.5029 - val_f1: 0.2284 - val_mcc: 0.2730\n",
      "Epoch 18/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.3655 - tp: 25664.0000 - fp: 16828.0000 - tn: 1244607.0000 - fn: 29181.0000 - accuracy: 0.5467 - precision: 0.6040 - recall: 0.4679 - auc: 0.9630 - prc: 0.5699 - f1: 0.2509 - mcc: 0.2781 - val_loss: 1.5626 - val_tp: 1859.0000 - val_fp: 1967.0000 - val_tn: 155721.0000 - val_fn: 4997.0000 - val_accuracy: 0.4043 - val_precision: 0.4859 - val_recall: 0.2711 - val_auc: 0.9469 - val_prc: 0.4088 - val_f1: 0.1878 - val_mcc: 0.2378\n",
      "Epoch 19/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.3606 - tp: 25583.0000 - fp: 16892.0000 - tn: 1244543.0000 - fn: 29262.0000 - accuracy: 0.5445 - precision: 0.6023 - recall: 0.4665 - auc: 0.9630 - prc: 0.5699 - f1: 0.2505 - mcc: 0.2750 - val_loss: 1.3114 - val_tp: 2723.0000 - val_fp: 1855.0000 - val_tn: 155833.0000 - val_fn: 4133.0000 - val_accuracy: 0.5207 - val_precision: 0.5948 - val_recall: 0.3972 - val_auc: 0.9597 - val_prc: 0.5189 - val_f1: 0.1996 - val_mcc: 0.2775\n",
      "Epoch 20/20\n",
      "3428/3428 [==============================] - 12s 4ms/step - loss: 0.3460 - tp: 25533.0000 - fp: 16623.0000 - tn: 1244812.0000 - fn: 29312.0000 - accuracy: 0.5462 - precision: 0.6057 - recall: 0.4655 - auc: 0.9632 - prc: 0.5761 - f1: 0.2375 - mcc: 0.2770 - val_loss: 1.4348 - val_tp: 2487.0000 - val_fp: 2237.0000 - val_tn: 155451.0000 - val_fn: 4369.0000 - val_accuracy: 0.4651 - val_precision: 0.5265 - val_recall: 0.3627 - val_auc: 0.9542 - val_prc: 0.4728 - val_f1: 0.2371 - val_mcc: 0.2624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_12_80_T/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_12_80_T/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_20_80_T\n",
      "Training features shape: (59096, 20, 5)\n",
      "Training labels shape: (59096, 24)\n",
      "\n",
      "Dev (validation) features shape: (7387, 20, 5)\n",
      "Dev (validation) labels shape: (7387, 24)\n",
      "\n",
      "Input shape: (20, 5)\n",
      "\n",
      "Epoch 1/20\n",
      "3694/3694 [==============================] - 16s 4ms/step - loss: 1.2199 - tp: 7428.0000 - fp: 10769.0000 - tn: 1348439.0000 - fn: 51668.0000 - accuracy: 0.2676 - precision: 0.4082 - recall: 0.1257 - auc: 0.8740 - prc: 0.2538 - f1: 0.0895 - mcc: 0.1262 - val_loss: 1.8625 - val_tp: 718.0000 - val_fp: 911.0000 - val_tn: 168990.0000 - val_fn: 6669.0000 - val_accuracy: 0.3180 - val_precision: 0.4408 - val_recall: 0.0972 - val_auc: 0.9265 - val_prc: 0.3147 - val_f1: 0.1688 - val_mcc: 0.1979\n",
      "Epoch 2/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.5664 - tp: 15508.0000 - fp: 16186.0000 - tn: 1343022.0000 - fn: 43588.0000 - accuracy: 0.4159 - precision: 0.4893 - recall: 0.2624 - auc: 0.9414 - prc: 0.4129 - f1: 0.1696 - mcc: 0.2035 - val_loss: 1.4813 - val_tp: 1754.0000 - val_fp: 1347.0000 - val_tn: 168554.0000 - val_fn: 5633.0000 - val_accuracy: 0.4726 - val_precision: 0.5656 - val_recall: 0.2374 - val_auc: 0.9539 - val_prc: 0.4679 - val_f1: 0.1874 - val_mcc: 0.2436\n",
      "Epoch 3/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.4677 - tp: 21230.0000 - fp: 17631.0000 - tn: 1341577.0000 - fn: 37866.0000 - accuracy: 0.4832 - precision: 0.5463 - recall: 0.3592 - auc: 0.9519 - prc: 0.4889 - f1: 0.2004 - mcc: 0.2358 - val_loss: 1.4194 - val_tp: 1789.0000 - val_fp: 1582.0000 - val_tn: 168319.0000 - val_fn: 5598.0000 - val_accuracy: 0.4761 - val_precision: 0.5307 - val_recall: 0.2422 - val_auc: 0.9580 - val_prc: 0.4660 - val_f1: 0.2270 - val_mcc: 0.2430\n",
      "Epoch 4/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.3910 - tp: 24251.0000 - fp: 15795.0000 - tn: 1343413.0000 - fn: 34845.0000 - accuracy: 0.5428 - precision: 0.6056 - recall: 0.4104 - auc: 0.9646 - prc: 0.5630 - f1: 0.2319 - mcc: 0.2630 - val_loss: 1.1172 - val_tp: 2868.0000 - val_fp: 1480.0000 - val_tn: 168421.0000 - val_fn: 4519.0000 - val_accuracy: 0.5931 - val_precision: 0.6596 - val_recall: 0.3882 - val_auc: 0.9733 - val_prc: 0.6135 - val_f1: 0.2770 - val_mcc: 0.2944\n",
      "Epoch 5/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.3921 - tp: 26226.0000 - fp: 16516.0000 - tn: 1342692.0000 - fn: 32870.0000 - accuracy: 0.5574 - precision: 0.6136 - recall: 0.4438 - auc: 0.9658 - prc: 0.5794 - f1: 0.2448 - mcc: 0.2711 - val_loss: 1.6304 - val_tp: 1572.0000 - val_fp: 1832.0000 - val_tn: 168069.0000 - val_fn: 5815.0000 - val_accuracy: 0.3889 - val_precision: 0.4618 - val_recall: 0.2128 - val_auc: 0.9432 - val_prc: 0.3979 - val_f1: 0.1852 - val_mcc: 0.2187\n",
      "Epoch 6/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.3312 - tp: 28836.0000 - fp: 16333.0000 - tn: 1342875.0000 - fn: 30260.0000 - accuracy: 0.5855 - precision: 0.6384 - recall: 0.4880 - auc: 0.9695 - prc: 0.6180 - f1: 0.2621 - mcc: 0.2838 - val_loss: 1.1891 - val_tp: 2723.0000 - val_fp: 1640.0000 - val_tn: 168261.0000 - val_fn: 4664.0000 - val_accuracy: 0.5385 - val_precision: 0.6241 - val_recall: 0.3686 - val_auc: 0.9694 - val_prc: 0.5802 - val_f1: 0.2890 - val_mcc: 0.2712\n",
      "Epoch 7/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.3613 - tp: 28344.0000 - fp: 16753.0000 - tn: 1342455.0000 - fn: 30752.0000 - accuracy: 0.5732 - precision: 0.6285 - recall: 0.4796 - auc: 0.9686 - prc: 0.6123 - f1: 0.2504 - mcc: 0.2782 - val_loss: 1.3048 - val_tp: 2631.0000 - val_fp: 1915.0000 - val_tn: 167986.0000 - val_fn: 4756.0000 - val_accuracy: 0.5150 - val_precision: 0.5788 - val_recall: 0.3562 - val_auc: 0.9623 - val_prc: 0.5229 - val_f1: 0.2813 - val_mcc: 0.2620\n",
      "Epoch 8/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.3327 - tp: 30748.0000 - fp: 15124.0000 - tn: 1344084.0000 - fn: 28348.0000 - accuracy: 0.6176 - precision: 0.6703 - recall: 0.5203 - auc: 0.9743 - prc: 0.6573 - f1: 0.2746 - mcc: 0.3020 - val_loss: 0.9830 - val_tp: 3718.0000 - val_fp: 1633.0000 - val_tn: 168268.0000 - val_fn: 3669.0000 - val_accuracy: 0.6214 - val_precision: 0.6948 - val_recall: 0.5033 - val_auc: 0.9778 - val_prc: 0.6778 - val_f1: 0.3367 - val_mcc: 0.3126\n",
      "Epoch 9/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.3105 - tp: 31594.0000 - fp: 15098.0000 - tn: 1344110.0000 - fn: 27502.0000 - accuracy: 0.6258 - precision: 0.6766 - recall: 0.5346 - auc: 0.9756 - prc: 0.6683 - f1: 0.2892 - mcc: 0.3101 - val_loss: 1.0375 - val_tp: 3418.0000 - val_fp: 1507.0000 - val_tn: 168394.0000 - val_fn: 3969.0000 - val_accuracy: 0.6164 - val_precision: 0.6940 - val_recall: 0.4627 - val_auc: 0.9757 - val_prc: 0.6477 - val_f1: 0.2945 - val_mcc: 0.3094\n",
      "Epoch 10/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.3089 - tp: 33262.0000 - fp: 15258.0000 - tn: 1343950.0000 - fn: 25834.0000 - accuracy: 0.6408 - precision: 0.6855 - recall: 0.5628 - auc: 0.9757 - prc: 0.6859 - f1: 0.3079 - mcc: 0.3181 - val_loss: 1.0616 - val_tp: 3383.0000 - val_fp: 1379.0000 - val_tn: 168522.0000 - val_fn: 4004.0000 - val_accuracy: 0.6178 - val_precision: 0.7104 - val_recall: 0.4580 - val_auc: 0.9744 - val_prc: 0.6559 - val_f1: 0.2530 - val_mcc: 0.3048\n",
      "Epoch 11/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.2924 - tp: 31712.0000 - fp: 15862.0000 - tn: 1343346.0000 - fn: 27384.0000 - accuracy: 0.6172 - precision: 0.6666 - recall: 0.5366 - auc: 0.9743 - prc: 0.6628 - f1: 0.2985 - mcc: 0.3059 - val_loss: 1.3863 - val_tp: 2428.0000 - val_fp: 2064.0000 - val_tn: 167837.0000 - val_fn: 4959.0000 - val_accuracy: 0.4799 - val_precision: 0.5405 - val_recall: 0.3287 - val_auc: 0.9569 - val_prc: 0.4824 - val_f1: 0.2348 - val_mcc: 0.2533\n",
      "Epoch 12/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.3164 - tp: 31660.0000 - fp: 15645.0000 - tn: 1343563.0000 - fn: 27436.0000 - accuracy: 0.6227 - precision: 0.6693 - recall: 0.5357 - auc: 0.9732 - prc: 0.6547 - f1: 0.2791 - mcc: 0.3078 - val_loss: 1.2116 - val_tp: 3194.0000 - val_fp: 1888.0000 - val_tn: 168013.0000 - val_fn: 4193.0000 - val_accuracy: 0.5671 - val_precision: 0.6285 - val_recall: 0.4324 - val_auc: 0.9645 - val_prc: 0.5633 - val_f1: 0.2327 - val_mcc: 0.2835\n",
      "Epoch 13/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.3242 - tp: 32427.0000 - fp: 15822.0000 - tn: 1343386.0000 - fn: 26669.0000 - accuracy: 0.6230 - precision: 0.6721 - recall: 0.5487 - auc: 0.9721 - prc: 0.6618 - f1: 0.2700 - mcc: 0.3101 - val_loss: 1.2792 - val_tp: 2518.0000 - val_fp: 1476.0000 - val_tn: 168425.0000 - val_fn: 4869.0000 - val_accuracy: 0.5231 - val_precision: 0.6304 - val_recall: 0.3409 - val_auc: 0.9647 - val_prc: 0.5510 - val_f1: 0.1860 - val_mcc: 0.2697\n",
      "Epoch 14/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.2943 - tp: 33336.0000 - fp: 14505.0000 - tn: 1344703.0000 - fn: 25760.0000 - accuracy: 0.6469 - precision: 0.6968 - recall: 0.5641 - auc: 0.9764 - prc: 0.6935 - f1: 0.2796 - mcc: 0.3229 - val_loss: 1.2733 - val_tp: 2936.0000 - val_fp: 2061.0000 - val_tn: 167840.0000 - val_fn: 4451.0000 - val_accuracy: 0.5320 - val_precision: 0.5876 - val_recall: 0.3975 - val_auc: 0.9631 - val_prc: 0.5419 - val_f1: 0.2449 - val_mcc: 0.2729\n",
      "Epoch 15/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.2916 - tp: 33640.0000 - fp: 14664.0000 - tn: 1344544.0000 - fn: 25456.0000 - accuracy: 0.6480 - precision: 0.6964 - recall: 0.5692 - auc: 0.9759 - prc: 0.6951 - f1: 0.2943 - mcc: 0.3226 - val_loss: 1.2773 - val_tp: 2698.0000 - val_fp: 2129.0000 - val_tn: 167772.0000 - val_fn: 4689.0000 - val_accuracy: 0.5047 - val_precision: 0.5589 - val_recall: 0.3652 - val_auc: 0.9631 - val_prc: 0.5187 - val_f1: 0.2436 - val_mcc: 0.2669\n",
      "Epoch 16/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.2875 - tp: 35473.0000 - fp: 14535.0000 - tn: 1344673.0000 - fn: 23623.0000 - accuracy: 0.6637 - precision: 0.7093 - recall: 0.6003 - auc: 0.9770 - prc: 0.7194 - f1: 0.3164 - mcc: 0.3308 - val_loss: 1.3398 - val_tp: 2586.0000 - val_fp: 1998.0000 - val_tn: 167903.0000 - val_fn: 4801.0000 - val_accuracy: 0.4991 - val_precision: 0.5641 - val_recall: 0.3501 - val_auc: 0.9589 - val_prc: 0.5029 - val_f1: 0.2438 - val_mcc: 0.2548\n",
      "Epoch 17/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.2945 - tp: 33397.0000 - fp: 14967.0000 - tn: 1344241.0000 - fn: 25699.0000 - accuracy: 0.6398 - precision: 0.6905 - recall: 0.5651 - auc: 0.9747 - prc: 0.6890 - f1: 0.2853 - mcc: 0.3149 - val_loss: 1.1667 - val_tp: 3292.0000 - val_fp: 1899.0000 - val_tn: 168002.0000 - val_fn: 4095.0000 - val_accuracy: 0.5810 - val_precision: 0.6342 - val_recall: 0.4456 - val_auc: 0.9667 - val_prc: 0.5903 - val_f1: 0.2704 - val_mcc: 0.2916\n",
      "Epoch 18/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.2841 - tp: 35557.0000 - fp: 14254.0000 - tn: 1344954.0000 - fn: 23539.0000 - accuracy: 0.6704 - precision: 0.7138 - recall: 0.6017 - auc: 0.9762 - prc: 0.7157 - f1: 0.3153 - mcc: 0.3339 - val_loss: 0.9554 - val_tp: 4045.0000 - val_fp: 1788.0000 - val_tn: 168113.0000 - val_fn: 3342.0000 - val_accuracy: 0.6451 - val_precision: 0.6935 - val_recall: 0.5476 - val_auc: 0.9774 - val_prc: 0.6839 - val_f1: 0.3155 - val_mcc: 0.3273\n",
      "Epoch 19/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.2881 - tp: 34681.0000 - fp: 14492.0000 - tn: 1344716.0000 - fn: 24415.0000 - accuracy: 0.6564 - precision: 0.7053 - recall: 0.5869 - auc: 0.9757 - prc: 0.7056 - f1: 0.2981 - mcc: 0.3256 - val_loss: 1.2014 - val_tp: 2942.0000 - val_fp: 1872.0000 - val_tn: 168029.0000 - val_fn: 4445.0000 - val_accuracy: 0.5377 - val_precision: 0.6111 - val_recall: 0.3983 - val_auc: 0.9670 - val_prc: 0.5630 - val_f1: 0.2477 - val_mcc: 0.2765\n",
      "Epoch 20/20\n",
      "3694/3694 [==============================] - 13s 4ms/step - loss: 0.2960 - tp: 34281.0000 - fp: 14207.0000 - tn: 1345001.0000 - fn: 24815.0000 - accuracy: 0.6523 - precision: 0.7070 - recall: 0.5801 - auc: 0.9761 - prc: 0.7064 - f1: 0.2906 - mcc: 0.3232 - val_loss: 1.0948 - val_tp: 3385.0000 - val_fp: 1584.0000 - val_tn: 168317.0000 - val_fn: 4002.0000 - val_accuracy: 0.6031 - val_precision: 0.6812 - val_recall: 0.4582 - val_auc: 0.9724 - val_prc: 0.6406 - val_f1: 0.2483 - val_mcc: 0.3033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_20_80_T/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_20_80_T/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_14_80_T\n",
      "Training features shape: (56438, 14, 5)\n",
      "Training labels shape: (56438, 24)\n",
      "\n",
      "Dev (validation) features shape: (7055, 14, 5)\n",
      "Dev (validation) labels shape: (7055, 24)\n",
      "\n",
      "Input shape: (14, 5)\n",
      "\n",
      "Epoch 1/20\n",
      "3528/3528 [==============================] - 15s 4ms/step - loss: 1.4870 - tp: 2784.0000 - fp: 8098.0000 - tn: 1289976.0000 - fn: 53654.0000 - accuracy: 0.1891 - precision: 0.2558 - recall: 0.0493 - auc: 0.8405 - prc: 0.1670 - f1: 0.0745 - mcc: 0.0889 - val_loss: 2.2806 - val_tp: 253.0000 - val_fp: 1023.0000 - val_tn: 161242.0000 - val_fn: 6802.0000 - val_accuracy: 0.1787 - val_precision: 0.1983 - val_recall: 0.0359 - val_auc: 0.8800 - val_prc: 0.1857 - val_f1: 0.1232 - val_mcc: 0.1309\n",
      "Epoch 2/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.6881 - tp: 9189.0000 - fp: 15578.0000 - tn: 1282496.0000 - fn: 47249.0000 - accuracy: 0.3273 - precision: 0.3710 - recall: 0.1628 - auc: 0.9203 - prc: 0.2995 - f1: 0.1406 - mcc: 0.1660 - val_loss: 2.1772 - val_tp: 429.0000 - val_fp: 1694.0000 - val_tn: 160571.0000 - val_fn: 6626.0000 - val_accuracy: 0.2189 - val_precision: 0.2021 - val_recall: 0.0608 - val_auc: 0.8970 - val_prc: 0.2166 - val_f1: 0.1660 - val_mcc: 0.1749\n",
      "Epoch 3/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.5642 - tp: 12190.0000 - fp: 16968.0000 - tn: 1281106.0000 - fn: 44248.0000 - accuracy: 0.3759 - precision: 0.4181 - recall: 0.2160 - auc: 0.9363 - prc: 0.3513 - f1: 0.1712 - mcc: 0.1896 - val_loss: 1.7011 - val_tp: 1178.0000 - val_fp: 1620.0000 - val_tn: 160645.0000 - val_fn: 5877.0000 - val_accuracy: 0.3691 - val_precision: 0.4210 - val_recall: 0.1670 - val_auc: 0.9388 - val_prc: 0.3534 - val_f1: 0.2221 - val_mcc: 0.2165\n",
      "Epoch 4/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.5059 - tp: 15776.0000 - fp: 16459.0000 - tn: 1281615.0000 - fn: 40662.0000 - accuracy: 0.4343 - precision: 0.4894 - recall: 0.2795 - auc: 0.9485 - prc: 0.4194 - f1: 0.1773 - mcc: 0.2162 - val_loss: 1.9282 - val_tp: 929.0000 - val_fp: 2311.0000 - val_tn: 159954.0000 - val_fn: 6126.0000 - val_accuracy: 0.2822 - val_precision: 0.2867 - val_recall: 0.1317 - val_auc: 0.9213 - val_prc: 0.2743 - val_f1: 0.2170 - val_mcc: 0.1874\n",
      "Epoch 5/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.4285 - tp: 18301.0000 - fp: 18042.0000 - tn: 1280032.0000 - fn: 38137.0000 - accuracy: 0.4575 - precision: 0.5036 - recall: 0.3243 - auc: 0.9533 - prc: 0.4453 - f1: 0.1994 - mcc: 0.2318 - val_loss: 1.4324 - val_tp: 1640.0000 - val_fp: 1775.0000 - val_tn: 160490.0000 - val_fn: 5415.0000 - val_accuracy: 0.4318 - val_precision: 0.4802 - val_recall: 0.2325 - val_auc: 0.9566 - val_prc: 0.4283 - val_f1: 0.2577 - val_mcc: 0.2489\n",
      "Epoch 6/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.4052 - tp: 19245.0000 - fp: 18058.0000 - tn: 1280016.0000 - fn: 37193.0000 - accuracy: 0.4698 - precision: 0.5159 - recall: 0.3410 - auc: 0.9567 - prc: 0.4631 - f1: 0.2146 - mcc: 0.2398 - val_loss: 1.5004 - val_tp: 1661.0000 - val_fp: 2001.0000 - val_tn: 160264.0000 - val_fn: 5394.0000 - val_accuracy: 0.3986 - val_precision: 0.4536 - val_recall: 0.2354 - val_auc: 0.9522 - val_prc: 0.4078 - val_f1: 0.2215 - val_mcc: 0.2366\n",
      "Epoch 7/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.4007 - tp: 20903.0000 - fp: 17736.0000 - tn: 1280338.0000 - fn: 35535.0000 - accuracy: 0.4946 - precision: 0.5410 - recall: 0.3704 - auc: 0.9603 - prc: 0.4984 - f1: 0.2255 - mcc: 0.2514 - val_loss: 0.9693 - val_tp: 3274.0000 - val_fp: 1189.0000 - val_tn: 161076.0000 - val_fn: 3781.0000 - val_accuracy: 0.6499 - val_precision: 0.7336 - val_recall: 0.4641 - val_auc: 0.9804 - val_prc: 0.6913 - val_f1: 0.2571 - val_mcc: 0.3336\n",
      "Epoch 8/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.3785 - tp: 24418.0000 - fp: 16064.0000 - tn: 1282010.0000 - fn: 32020.0000 - accuracy: 0.5446 - precision: 0.6032 - recall: 0.4327 - auc: 0.9657 - prc: 0.5616 - f1: 0.2349 - mcc: 0.2687 - val_loss: 0.9496 - val_tp: 3383.0000 - val_fp: 1208.0000 - val_tn: 161057.0000 - val_fn: 3672.0000 - val_accuracy: 0.6609 - val_precision: 0.7369 - val_recall: 0.4795 - val_auc: 0.9810 - val_prc: 0.6956 - val_f1: 0.2590 - val_mcc: 0.3415\n",
      "Epoch 9/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.3644 - tp: 24651.0000 - fp: 17111.0000 - tn: 1280963.0000 - fn: 31787.0000 - accuracy: 0.5382 - precision: 0.5903 - recall: 0.4368 - auc: 0.9631 - prc: 0.5502 - f1: 0.2405 - mcc: 0.2698 - val_loss: 1.2796 - val_tp: 2261.0000 - val_fp: 1624.0000 - val_tn: 160641.0000 - val_fn: 4794.0000 - val_accuracy: 0.5019 - val_precision: 0.5820 - val_recall: 0.3205 - val_auc: 0.9645 - val_prc: 0.5133 - val_f1: 0.2209 - val_mcc: 0.2702\n",
      "Epoch 10/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.3438 - tp: 23206.0000 - fp: 17593.0000 - tn: 1280481.0000 - fn: 33232.0000 - accuracy: 0.5193 - precision: 0.5688 - recall: 0.4112 - auc: 0.9621 - prc: 0.5269 - f1: 0.2206 - mcc: 0.2656 - val_loss: 1.2341 - val_tp: 2694.0000 - val_fp: 1810.0000 - val_tn: 160455.0000 - val_fn: 4361.0000 - val_accuracy: 0.5345 - val_precision: 0.5981 - val_recall: 0.3819 - val_auc: 0.9654 - val_prc: 0.5419 - val_f1: 0.2255 - val_mcc: 0.2826\n",
      "Epoch 11/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.3479 - tp: 25653.0000 - fp: 17355.0000 - tn: 1280719.0000 - fn: 30785.0000 - accuracy: 0.5467 - precision: 0.5965 - recall: 0.4545 - auc: 0.9653 - prc: 0.5663 - f1: 0.2430 - mcc: 0.2741 - val_loss: 1.2488 - val_tp: 2328.0000 - val_fp: 1603.0000 - val_tn: 160662.0000 - val_fn: 4727.0000 - val_accuracy: 0.5229 - val_precision: 0.5922 - val_recall: 0.3300 - val_auc: 0.9669 - val_prc: 0.5275 - val_f1: 0.2080 - val_mcc: 0.2811\n",
      "Epoch 12/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.3483 - tp: 25809.0000 - fp: 17298.0000 - tn: 1280776.0000 - fn: 30629.0000 - accuracy: 0.5470 - precision: 0.5987 - recall: 0.4573 - auc: 0.9647 - prc: 0.5691 - f1: 0.2620 - mcc: 0.2780 - val_loss: 1.6551 - val_tp: 1563.0000 - val_fp: 2340.0000 - val_tn: 159925.0000 - val_fn: 5492.0000 - val_accuracy: 0.3639 - val_precision: 0.4005 - val_recall: 0.2215 - val_auc: 0.9419 - val_prc: 0.3561 - val_f1: 0.2094 - val_mcc: 0.2304\n",
      "Epoch 13/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.3300 - tp: 25681.0000 - fp: 17880.0000 - tn: 1280194.0000 - fn: 30757.0000 - accuracy: 0.5419 - precision: 0.5895 - recall: 0.4550 - auc: 0.9647 - prc: 0.5628 - f1: 0.2486 - mcc: 0.2750 - val_loss: 1.7247 - val_tp: 1731.0000 - val_fp: 2798.0000 - val_tn: 159467.0000 - val_fn: 5324.0000 - val_accuracy: 0.3586 - val_precision: 0.3822 - val_recall: 0.2454 - val_auc: 0.9389 - val_prc: 0.3536 - val_f1: 0.2181 - val_mcc: 0.2317\n",
      "Epoch 14/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.3474 - tp: 26949.0000 - fp: 17816.0000 - tn: 1280258.0000 - fn: 29489.0000 - accuracy: 0.5536 - precision: 0.6020 - recall: 0.4775 - auc: 0.9644 - prc: 0.5763 - f1: 0.2536 - mcc: 0.2799 - val_loss: 1.7933 - val_tp: 1309.0000 - val_fp: 2487.0000 - val_tn: 159778.0000 - val_fn: 5746.0000 - val_accuracy: 0.3147 - val_precision: 0.3448 - val_recall: 0.1855 - val_auc: 0.9325 - val_prc: 0.3145 - val_f1: 0.1864 - val_mcc: 0.2187\n",
      "Epoch 15/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.3524 - tp: 26071.0000 - fp: 17763.0000 - tn: 1280311.0000 - fn: 30367.0000 - accuracy: 0.5426 - precision: 0.5948 - recall: 0.4619 - auc: 0.9640 - prc: 0.5695 - f1: 0.2394 - mcc: 0.2754 - val_loss: 1.6864 - val_tp: 1592.0000 - val_fp: 2273.0000 - val_tn: 159992.0000 - val_fn: 5463.0000 - val_accuracy: 0.3671 - val_precision: 0.4119 - val_recall: 0.2257 - val_auc: 0.9393 - val_prc: 0.3658 - val_f1: 0.1763 - val_mcc: 0.2288\n",
      "Epoch 16/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.3114 - tp: 27484.0000 - fp: 17244.0000 - tn: 1280830.0000 - fn: 28954.0000 - accuracy: 0.5667 - precision: 0.6145 - recall: 0.4870 - auc: 0.9670 - prc: 0.5973 - f1: 0.2578 - mcc: 0.2851 - val_loss: 1.1802 - val_tp: 2872.0000 - val_fp: 1743.0000 - val_tn: 160522.0000 - val_fn: 4183.0000 - val_accuracy: 0.5532 - val_precision: 0.6223 - val_recall: 0.4071 - val_auc: 0.9686 - val_prc: 0.5741 - val_f1: 0.2178 - val_mcc: 0.2934\n",
      "Epoch 17/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.3384 - tp: 27497.0000 - fp: 17511.0000 - tn: 1280563.0000 - fn: 28941.0000 - accuracy: 0.5640 - precision: 0.6109 - recall: 0.4872 - auc: 0.9647 - prc: 0.5928 - f1: 0.2588 - mcc: 0.2824 - val_loss: 1.0699 - val_tp: 3390.0000 - val_fp: 1763.0000 - val_tn: 160502.0000 - val_fn: 3665.0000 - val_accuracy: 0.5989 - val_precision: 0.6579 - val_recall: 0.4805 - val_auc: 0.9725 - val_prc: 0.6282 - val_f1: 0.2809 - val_mcc: 0.3131\n",
      "Epoch 18/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.3253 - tp: 28249.0000 - fp: 17537.0000 - tn: 1280537.0000 - fn: 28189.0000 - accuracy: 0.5703 - precision: 0.6170 - recall: 0.5005 - auc: 0.9665 - prc: 0.6037 - f1: 0.2658 - mcc: 0.2893 - val_loss: 1.3772 - val_tp: 2681.0000 - val_fp: 2095.0000 - val_tn: 160170.0000 - val_fn: 4374.0000 - val_accuracy: 0.4910 - val_precision: 0.5613 - val_recall: 0.3800 - val_auc: 0.9568 - val_prc: 0.5034 - val_f1: 0.2101 - val_mcc: 0.2713\n",
      "Epoch 19/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.3431 - tp: 26767.0000 - fp: 17566.0000 - tn: 1280508.0000 - fn: 29671.0000 - accuracy: 0.5476 - precision: 0.6038 - recall: 0.4743 - auc: 0.9631 - prc: 0.5818 - f1: 0.2334 - mcc: 0.2773 - val_loss: 1.2333 - val_tp: 2987.0000 - val_fp: 1877.0000 - val_tn: 160388.0000 - val_fn: 4068.0000 - val_accuracy: 0.5400 - val_precision: 0.6141 - val_recall: 0.4234 - val_auc: 0.9653 - val_prc: 0.5691 - val_f1: 0.2035 - val_mcc: 0.2829\n",
      "Epoch 20/20\n",
      "3528/3528 [==============================] - 12s 4ms/step - loss: 0.3420 - tp: 28309.0000 - fp: 16471.0000 - tn: 1281603.0000 - fn: 28129.0000 - accuracy: 0.5755 - precision: 0.6322 - recall: 0.5016 - auc: 0.9682 - prc: 0.6204 - f1: 0.2489 - mcc: 0.2927 - val_loss: 1.5386 - val_tp: 2128.0000 - val_fp: 2271.0000 - val_tn: 159994.0000 - val_fn: 4927.0000 - val_accuracy: 0.4211 - val_precision: 0.4837 - val_recall: 0.3016 - val_auc: 0.9489 - val_prc: 0.4295 - val_f1: 0.1884 - val_mcc: 0.2418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_14_80_T/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_14_80_T/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_24_80_T\n",
      "Training features shape: (60230, 24, 5)\n",
      "Training labels shape: (60230, 24)\n",
      "\n",
      "Dev (validation) features shape: (7529, 24, 5)\n",
      "Dev (validation) labels shape: (7529, 24)\n",
      "\n",
      "Input shape: (24, 5)\n",
      "\n",
      "Epoch 1/20\n",
      "3765/3765 [==============================] - 16s 4ms/step - loss: 1.1401 - tp: 7591.0000 - fp: 12247.0000 - tn: 1373043.0000 - fn: 52639.0000 - accuracy: 0.2735 - precision: 0.3826 - recall: 0.1260 - auc: 0.8748 - prc: 0.2506 - f1: 0.0942 - mcc: 0.1290 - val_loss: 2.1708 - val_tp: 407.0000 - val_fp: 1060.0000 - val_tn: 172107.0000 - val_fn: 7122.0000 - val_accuracy: 0.2274 - val_precision: 0.2774 - val_recall: 0.0541 - val_auc: 0.8927 - val_prc: 0.2203 - val_f1: 0.1331 - val_mcc: 0.1295\n",
      "Epoch 2/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.5352 - tp: 16303.0000 - fp: 16702.0000 - tn: 1368588.0000 - fn: 43927.0000 - accuracy: 0.4175 - precision: 0.4940 - recall: 0.2707 - auc: 0.9433 - prc: 0.4138 - f1: 0.1749 - mcc: 0.2002 - val_loss: 2.0293 - val_tp: 639.0000 - val_fp: 1518.0000 - val_tn: 171649.0000 - val_fn: 6890.0000 - val_accuracy: 0.2419 - val_precision: 0.2962 - val_recall: 0.0849 - val_auc: 0.9110 - val_prc: 0.2555 - val_f1: 0.2282 - val_mcc: 0.1810\n",
      "Epoch 3/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.4557 - tp: 21076.0000 - fp: 17500.0000 - tn: 1367790.0000 - fn: 39154.0000 - accuracy: 0.4822 - precision: 0.5464 - recall: 0.3499 - auc: 0.9547 - prc: 0.4824 - f1: 0.2069 - mcc: 0.2292 - val_loss: 2.0090 - val_tp: 530.0000 - val_fp: 1793.0000 - val_tn: 171374.0000 - val_fn: 6999.0000 - val_accuracy: 0.1857 - val_precision: 0.2282 - val_recall: 0.0704 - val_auc: 0.9162 - val_prc: 0.2415 - val_f1: 0.2252 - val_mcc: 0.1772\n",
      "Epoch 4/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.3908 - tp: 23339.0000 - fp: 17027.0000 - tn: 1368263.0000 - fn: 36891.0000 - accuracy: 0.5115 - precision: 0.5782 - recall: 0.3875 - auc: 0.9597 - prc: 0.5214 - f1: 0.2264 - mcc: 0.2429 - val_loss: 1.4949 - val_tp: 1803.0000 - val_fp: 1713.0000 - val_tn: 171454.0000 - val_fn: 5726.0000 - val_accuracy: 0.4325 - val_precision: 0.5128 - val_recall: 0.2395 - val_auc: 0.9519 - val_prc: 0.4332 - val_f1: 0.2325 - val_mcc: 0.2347\n",
      "Epoch 5/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.3533 - tp: 27269.0000 - fp: 17277.0000 - tn: 1368013.0000 - fn: 32961.0000 - accuracy: 0.5578 - precision: 0.6122 - recall: 0.4527 - auc: 0.9669 - prc: 0.5781 - f1: 0.2738 - mcc: 0.2645 - val_loss: 1.2709 - val_tp: 2625.0000 - val_fp: 1772.0000 - val_tn: 171395.0000 - val_fn: 4904.0000 - val_accuracy: 0.5310 - val_precision: 0.5970 - val_recall: 0.3487 - val_auc: 0.9638 - val_prc: 0.5231 - val_f1: 0.2675 - val_mcc: 0.2710\n",
      "Epoch 6/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.3379 - tp: 30459.0000 - fp: 16138.0000 - tn: 1369152.0000 - fn: 29771.0000 - accuracy: 0.6002 - precision: 0.6537 - recall: 0.5057 - auc: 0.9725 - prc: 0.6340 - f1: 0.2796 - mcc: 0.2859 - val_loss: 0.8337 - val_tp: 4172.0000 - val_fp: 1111.0000 - val_tn: 172056.0000 - val_fn: 3357.0000 - val_accuracy: 0.6989 - val_precision: 0.7897 - val_recall: 0.5541 - val_auc: 0.9847 - val_prc: 0.7607 - val_f1: 0.3699 - val_mcc: 0.3549\n",
      "Epoch 7/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.3140 - tp: 32203.0000 - fp: 15275.0000 - tn: 1370015.0000 - fn: 28027.0000 - accuracy: 0.6251 - precision: 0.6783 - recall: 0.5347 - auc: 0.9758 - prc: 0.6677 - f1: 0.3070 - mcc: 0.2991 - val_loss: 1.0108 - val_tp: 3598.0000 - val_fp: 1511.0000 - val_tn: 171656.0000 - val_fn: 3931.0000 - val_accuracy: 0.6240 - val_precision: 0.7042 - val_recall: 0.4779 - val_auc: 0.9768 - val_prc: 0.6614 - val_f1: 0.3142 - val_mcc: 0.3147\n",
      "Epoch 8/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.2887 - tp: 34417.0000 - fp: 15081.0000 - tn: 1370209.0000 - fn: 25813.0000 - accuracy: 0.6443 - precision: 0.6953 - recall: 0.5714 - auc: 0.9760 - prc: 0.6937 - f1: 0.3175 - mcc: 0.3132 - val_loss: 1.1069 - val_tp: 3034.0000 - val_fp: 1556.0000 - val_tn: 171611.0000 - val_fn: 4495.0000 - val_accuracy: 0.5784 - val_precision: 0.6610 - val_recall: 0.4030 - val_auc: 0.9731 - val_prc: 0.6080 - val_f1: 0.3058 - val_mcc: 0.3009\n",
      "Epoch 9/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.2987 - tp: 35247.0000 - fp: 14042.0000 - tn: 1371248.0000 - fn: 24983.0000 - accuracy: 0.6644 - precision: 0.7151 - recall: 0.5852 - auc: 0.9800 - prc: 0.7136 - f1: 0.3432 - mcc: 0.3213 - val_loss: 0.9260 - val_tp: 4134.0000 - val_fp: 1522.0000 - val_tn: 171645.0000 - val_fn: 3395.0000 - val_accuracy: 0.6758 - val_precision: 0.7309 - val_recall: 0.5491 - val_auc: 0.9793 - val_prc: 0.6995 - val_f1: 0.2686 - val_mcc: 0.3498\n",
      "Epoch 10/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.2938 - tp: 34414.0000 - fp: 14140.0000 - tn: 1371150.0000 - fn: 25816.0000 - accuracy: 0.6542 - precision: 0.7088 - recall: 0.5714 - auc: 0.9774 - prc: 0.7003 - f1: 0.3008 - mcc: 0.3211 - val_loss: 1.3434 - val_tp: 2273.0000 - val_fp: 1775.0000 - val_tn: 171392.0000 - val_fn: 5256.0000 - val_accuracy: 0.4730 - val_precision: 0.5615 - val_recall: 0.3019 - val_auc: 0.9608 - val_prc: 0.4943 - val_f1: 0.2530 - val_mcc: 0.2574\n",
      "Epoch 11/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.2913 - tp: 34029.0000 - fp: 14986.0000 - tn: 1370304.0000 - fn: 26201.0000 - accuracy: 0.6457 - precision: 0.6943 - recall: 0.5650 - auc: 0.9770 - prc: 0.6890 - f1: 0.3200 - mcc: 0.3152 - val_loss: 0.7346 - val_tp: 4764.0000 - val_fp: 1214.0000 - val_tn: 171953.0000 - val_fn: 2765.0000 - val_accuracy: 0.7344 - val_precision: 0.7969 - val_recall: 0.6328 - val_auc: 0.9869 - val_prc: 0.7983 - val_f1: 0.3234 - val_mcc: 0.3822\n",
      "Epoch 12/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.3129 - tp: 32844.0000 - fp: 15921.0000 - tn: 1369369.0000 - fn: 27386.0000 - accuracy: 0.6254 - precision: 0.6735 - recall: 0.5453 - auc: 0.9733 - prc: 0.6627 - f1: 0.2880 - mcc: 0.3021 - val_loss: 1.4627 - val_tp: 1901.0000 - val_fp: 1582.0000 - val_tn: 171585.0000 - val_fn: 5628.0000 - val_accuracy: 0.4513 - val_precision: 0.5458 - val_recall: 0.2525 - val_auc: 0.9529 - val_prc: 0.4551 - val_f1: 0.2102 - val_mcc: 0.2494\n",
      "Epoch 13/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.2893 - tp: 32684.0000 - fp: 15464.0000 - tn: 1369826.0000 - fn: 27546.0000 - accuracy: 0.6251 - precision: 0.6788 - recall: 0.5427 - auc: 0.9756 - prc: 0.6729 - f1: 0.3020 - mcc: 0.3048 - val_loss: 1.5250 - val_tp: 1649.0000 - val_fp: 1874.0000 - val_tn: 171293.0000 - val_fn: 5880.0000 - val_accuracy: 0.3985 - val_precision: 0.4681 - val_recall: 0.2190 - val_auc: 0.9490 - val_prc: 0.4040 - val_f1: 0.2182 - val_mcc: 0.2344\n",
      "Epoch 14/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.2889 - tp: 33376.0000 - fp: 15318.0000 - tn: 1369972.0000 - fn: 26854.0000 - accuracy: 0.6347 - precision: 0.6854 - recall: 0.5541 - auc: 0.9748 - prc: 0.6766 - f1: 0.2965 - mcc: 0.3087 - val_loss: 1.2235 - val_tp: 2958.0000 - val_fp: 1748.0000 - val_tn: 171419.0000 - val_fn: 4571.0000 - val_accuracy: 0.5464 - val_precision: 0.6286 - val_recall: 0.3929 - val_auc: 0.9659 - val_prc: 0.5584 - val_f1: 0.2402 - val_mcc: 0.2831\n",
      "Epoch 15/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.3027 - tp: 34467.0000 - fp: 14905.0000 - tn: 1370385.0000 - fn: 25763.0000 - accuracy: 0.6449 - precision: 0.6981 - recall: 0.5723 - auc: 0.9759 - prc: 0.6927 - f1: 0.2797 - mcc: 0.3126 - val_loss: 1.0944 - val_tp: 3433.0000 - val_fp: 1839.0000 - val_tn: 171328.0000 - val_fn: 4096.0000 - val_accuracy: 0.5807 - val_precision: 0.6512 - val_recall: 0.4560 - val_auc: 0.9720 - val_prc: 0.6092 - val_f1: 0.2724 - val_mcc: 0.2957\n",
      "Epoch 16/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.2948 - tp: 32922.0000 - fp: 15231.0000 - tn: 1370059.0000 - fn: 27308.0000 - accuracy: 0.6290 - precision: 0.6837 - recall: 0.5466 - auc: 0.9745 - prc: 0.6685 - f1: 0.2825 - mcc: 0.3048 - val_loss: 1.0516 - val_tp: 3306.0000 - val_fp: 1415.0000 - val_tn: 171752.0000 - val_fn: 4223.0000 - val_accuracy: 0.6088 - val_precision: 0.7003 - val_recall: 0.4391 - val_auc: 0.9749 - val_prc: 0.6344 - val_f1: 0.2847 - val_mcc: 0.3108\n",
      "Epoch 17/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.2837 - tp: 34171.0000 - fp: 14823.0000 - tn: 1370467.0000 - fn: 26059.0000 - accuracy: 0.6450 - precision: 0.6975 - recall: 0.5673 - auc: 0.9765 - prc: 0.6889 - f1: 0.3081 - mcc: 0.3134 - val_loss: 1.5116 - val_tp: 2274.0000 - val_fp: 2123.0000 - val_tn: 171044.0000 - val_fn: 5255.0000 - val_accuracy: 0.4617 - val_precision: 0.5172 - val_recall: 0.3020 - val_auc: 0.9471 - val_prc: 0.4412 - val_f1: 0.2314 - val_mcc: 0.2544\n",
      "Epoch 18/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.2754 - tp: 35173.0000 - fp: 15223.0000 - tn: 1370067.0000 - fn: 25057.0000 - accuracy: 0.6519 - precision: 0.6979 - recall: 0.5840 - auc: 0.9740 - prc: 0.6890 - f1: 0.3192 - mcc: 0.3166 - val_loss: 1.6678 - val_tp: 2218.0000 - val_fp: 2334.0000 - val_tn: 170833.0000 - val_fn: 5311.0000 - val_accuracy: 0.4430 - val_precision: 0.4873 - val_recall: 0.2946 - val_auc: 0.9361 - val_prc: 0.3995 - val_f1: 0.2204 - val_mcc: 0.2460\n",
      "Epoch 19/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.3004 - tp: 31067.0000 - fp: 16352.0000 - tn: 1368938.0000 - fn: 29163.0000 - accuracy: 0.6015 - precision: 0.6552 - recall: 0.5158 - auc: 0.9691 - prc: 0.6302 - f1: 0.2625 - mcc: 0.2902 - val_loss: 1.1910 - val_tp: 3016.0000 - val_fp: 1629.0000 - val_tn: 171538.0000 - val_fn: 4513.0000 - val_accuracy: 0.5620 - val_precision: 0.6493 - val_recall: 0.4006 - val_auc: 0.9677 - val_prc: 0.5851 - val_f1: 0.2689 - val_mcc: 0.2850\n",
      "Epoch 20/20\n",
      "3765/3765 [==============================] - 13s 4ms/step - loss: 0.2979 - tp: 31778.0000 - fp: 15926.0000 - tn: 1369364.0000 - fn: 28452.0000 - accuracy: 0.6155 - precision: 0.6661 - recall: 0.5276 - auc: 0.9716 - prc: 0.6463 - f1: 0.2734 - mcc: 0.2978 - val_loss: 1.2917 - val_tp: 2533.0000 - val_fp: 1739.0000 - val_tn: 171428.0000 - val_fn: 4996.0000 - val_accuracy: 0.5185 - val_precision: 0.5929 - val_recall: 0.3364 - val_auc: 0.9629 - val_prc: 0.5216 - val_f1: 0.2672 - val_mcc: 0.2717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_24_80_T/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_24_80_T/assets\n"
     ]
    }
   ],
   "source": [
    "PATH = Path(\"../data_generation/training_data/non_homology_reduced/\")\n",
    "for dir in os.listdir(PATH):\n",
    "    if dir[-1] != \"U\" and \"gnravall\" not in dir and os.path.isdir(PATH/dir):\n",
    "        if \"clusters\" in dir:\n",
    "            # pass\n",
    "            print(dir)\n",
    "            train(PATH/dir, 24)\n",
    "        else:\n",
    "            pass\n",
    "            # train(PATH/dir, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnabert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
