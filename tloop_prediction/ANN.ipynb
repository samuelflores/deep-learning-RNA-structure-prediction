{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aef19d0-9369-45f7-81aa-d7ca27ca925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 23:52:26.857027: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/mimer/NOBACKUP/groups/naiss2024-5-16/tloop/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/mimer/NOBACKUP/groups/naiss2024-5-16/tloop/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# standard libraries\n",
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# standard scientific libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import asarray, save, load\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv1D, Conv2D, MaxPooling2D, Dropout, Flatten, Input, MaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4ac808",
   "metadata": {},
   "source": [
    "TODO\n",
    "- fragment length (8- 14)\n",
    "- classifier vs. single-sequence (GNRA)\n",
    "- with/without decoys\n",
    "\n",
    "ADD VALIDATION SET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2bc2c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3f533a-9c9c-46ff-bff6-70da4c18f363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 23:52:31.118308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13762 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:86:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Config (hyperparameters, metrics, etc.)\n",
    "\n",
    "DATA_DIR = Path(\"../data_generation/training_data/gnra_8_80_T/\")\n",
    "SET_NAME = str(DATA_DIR).split(\"/\")[-1]\n",
    "RESULTS_FILE = Path(f\"results/{SET_NAME}\")\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES = 2\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name = 'tp'),\n",
    "      keras.metrics.FalsePositives(name = 'fp'),\n",
    "      keras.metrics.TrueNegatives(name = 'tn'),\n",
    "      keras.metrics.FalseNegatives(name = 'fn'),\n",
    "      # keras.metrics.BinaryAccuracy(name = 'accuracy'), # TODO remove this?\n",
    "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name = 'precision'),\n",
    "      keras.metrics.Recall(name = 'recall'),\n",
    "      keras.metrics.AUC(name = 'auc'),\n",
    "      keras.metrics.AUC(name = 'prc', curve = 'PR'), # precision-recall curve\n",
    "      tfa.metrics.F1Score(name = 'f1', num_classes = NUM_CLASSES),\n",
    "      tfa.metrics.MatthewsCorrelationCoefficient(name = 'mcc', num_classes = NUM_CLASSES)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2613041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training features shape: (33084, 8, 5)\n",
      "training labels shape: (33084, 2)\n",
      "\n",
      "testing features shape: (4136, 8, 5)\n",
      "testing labels shape: (4136, 2)\n",
      "\n",
      "dev (validation) features shape: (4135, 8, 5)\n",
      "dev (validation) labels shape: (4135, 2)\n",
      "\n",
      "input shape: (8, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "\n",
    "train_dict = np.load(DATA_DIR/\"train_matrices.npz\", allow_pickle=True)\n",
    "x_train = np.stack(train_dict['arr_0'], axis=0)\n",
    "y_train = np.load(DATA_DIR/\"train_labels.npy\", allow_pickle=True) # TODO as_type(int) needed?\n",
    "y_train = to_categorical(y_train, num_classes=NUM_CLASSES)  # TODO categorical, one-hot encode labels\n",
    "\n",
    "test_dict = np.load(DATA_DIR/\"test_matrices.npz\", allow_pickle=True)\n",
    "x_test = np.stack(test_dict['arr_0'], axis=0)\n",
    "y_test = np.load(DATA_DIR/\"test_labels.npy\", allow_pickle=True)\n",
    "y_test = to_categorical(y_test, num_classes=NUM_CLASSES)\n",
    "\n",
    "dev_dict = np.load(DATA_DIR/\"dev_matrices.npz\", allow_pickle=True)\n",
    "x_dev = np.stack(dev_dict['arr_0'], axis=0)\n",
    "y_dev = np.load(DATA_DIR/\"dev_labels.npy\", allow_pickle=True)\n",
    "y_dev = to_categorical(y_dev, num_classes=NUM_CLASSES)\n",
    "\n",
    "#! Merge dev and test sets (if validation set not used)\n",
    "# x_test = np.concatenate((x_test, x_dev), axis=0)\n",
    "# y_test = np.concatenate((y_test, y_dev), axis=0)\n",
    "\n",
    "print(\"training features shape:\", x_train.shape)\n",
    "print(\"training labels shape:\", y_train.shape)\n",
    "\n",
    "print(\"\\ntesting features shape:\", x_test.shape)\n",
    "print(\"testing labels shape:\", y_test.shape)\n",
    "\n",
    "print(\"\\ndev (validation) features shape:\", x_dev.shape)\n",
    "print(\"dev (validation) labels shape:\", y_dev.shape)\n",
    "\n",
    "print(\"\\ninput shape:\", x_train.shape[1:])\n",
    "\n",
    "INPUT_SHAPE = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bafc96ad-62ad-47da-834b-df3dc94e2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(metrics=METRICS, output_bias=None, input_shape=INPUT_SHAPE, pool_size = 2):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    \n",
    "    model = Sequential([        \n",
    "        # First convolution\n",
    "        Conv1D(16, 3, strides=1, activation='relu', padding='same', # TODO set as 64?\n",
    "               input_shape = input_shape,\n",
    "               kernel_initializer = 'he_normal',\n",
    "               bias_initializer = 'zeros'),\n",
    "        MaxPooling1D(pool_size = pool_size, strides = 2), # TODO set strides?\n",
    "        Dropout(0.2),\n",
    "        Conv1D(32, 3, strides = 1, activation = 'relu', padding = 'same',\n",
    "               kernel_initializer = 'he_normal',\n",
    "               bias_initializer = 'zeros'),\n",
    "        MaxPooling1D(pool_size = pool_size, strides = 2),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        \n",
    "        # Neuron hidden layer\n",
    "        Dense(int(INPUT_SHAPE[0]/pool_size) * 32, activation = 'relu', kernel_initializer='he_normal', bias_initializer = output_bias),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Output neuron\n",
    "        # Dense(1, activation='sigmoid')  # Sigmoid for binary question. It will contain a value from 0-1 where 0 for class ('not GNRA') and 1 for the other ('GNRA')\n",
    "        Dense(NUM_CLASSES, activation='softmax', bias_initializer=output_bias, kernel_initializer='glorot_uniform') # TODO categorical: Softmax for multiclass classification\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate = 1e-3),  # optimizer=RMSprop(lr=0.001),\n",
    "        loss=keras.losses.CategoricalCrossentropy(), \n",
    "        # loss=keras.losses.BinaryCrossentropy(), # TODO remove?\n",
    "        metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0212af-03ea-4253-b725-d11b35d7ed07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.54, 1: 7.23}\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weight\n",
    "\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "y_integers = np.argmax(y_train, axis=1)\n",
    "class_weights = np.round(class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_integers), y=y_integers), 2)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "print(d_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66f3b235-e4e4-47ba-b861-e8f97efd7741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /apps/Arch/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 23:52:36.030706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2068/2068 [==============================] - 17s 6ms/step - loss: 0.3225 - tp: 28625.0000 - fp: 4459.0000 - tn: 28625.0000 - fn: 4459.0000 - accuracy: 0.8652 - precision: 0.8652 - recall: 0.8652 - auc: 0.9413 - prc: 0.9413 - f1: 0.6950 - mcc: 0.4720 - val_loss: 0.2361 - val_tp: 3775.0000 - val_fp: 360.0000 - val_tn: 3775.0000 - val_fn: 360.0000 - val_accuracy: 0.9129 - val_precision: 0.9129 - val_recall: 0.9129 - val_auc: 0.9666 - val_prc: 0.9633 - val_f1: 0.7734 - val_mcc: 0.6104\n",
      "Epoch 2/20\n",
      "2068/2068 [==============================] - 12s 6ms/step - loss: 0.2065 - tp: 30545.0000 - fp: 2539.0000 - tn: 30545.0000 - fn: 2539.0000 - accuracy: 0.9233 - precision: 0.9233 - recall: 0.9233 - auc: 0.9726 - prc: 0.9706 - f1: 0.7907 - mcc: 0.6272 - val_loss: 0.1124 - val_tp: 3985.0000 - val_fp: 150.0000 - val_tn: 3985.0000 - val_fn: 150.0000 - val_accuracy: 0.9637 - val_precision: 0.9637 - val_recall: 0.9637 - val_auc: 0.9906 - val_prc: 0.9896 - val_f1: 0.8789 - val_mcc: 0.7735\n",
      "Epoch 3/20\n",
      "2068/2068 [==============================] - 12s 6ms/step - loss: 0.1753 - tp: 30970.0000 - fp: 2114.0000 - tn: 30970.0000 - fn: 2114.0000 - accuracy: 0.9361 - precision: 0.9361 - recall: 0.9361 - auc: 0.9801 - prc: 0.9786 - f1: 0.8174 - mcc: 0.6718 - val_loss: 0.2043 - val_tp: 3864.0000 - val_fp: 271.0000 - val_tn: 3864.0000 - val_fn: 271.0000 - val_accuracy: 0.9345 - val_precision: 0.9345 - val_recall: 0.9345 - val_auc: 0.9721 - val_prc: 0.9674 - val_f1: 0.8143 - val_mcc: 0.6750\n",
      "Epoch 4/20\n",
      "2068/2068 [==============================] - 12s 6ms/step - loss: 0.1562 - tp: 31168.0000 - fp: 1916.0000 - tn: 31168.0000 - fn: 1916.0000 - accuracy: 0.9421 - precision: 0.9421 - recall: 0.9421 - auc: 0.9831 - prc: 0.9819 - f1: 0.8304 - mcc: 0.6936 - val_loss: 0.1317 - val_tp: 3958.0000 - val_fp: 177.0000 - val_tn: 3958.0000 - val_fn: 177.0000 - val_accuracy: 0.9572 - val_precision: 0.9572 - val_recall: 0.9572 - val_auc: 0.9872 - val_prc: 0.9858 - val_f1: 0.8631 - val_mcc: 0.7491\n",
      "Epoch 5/20\n",
      "2068/2068 [==============================] - 11s 5ms/step - loss: 0.1446 - tp: 31234.0000 - fp: 1850.0000 - tn: 31234.0000 - fn: 1850.0000 - accuracy: 0.9441 - precision: 0.9441 - recall: 0.9441 - auc: 0.9850 - prc: 0.9841 - f1: 0.8358 - mcc: 0.7039 - val_loss: 0.1150 - val_tp: 3970.0000 - val_fp: 165.0000 - val_tn: 3970.0000 - val_fn: 165.0000 - val_accuracy: 0.9601 - val_precision: 0.9601 - val_recall: 0.9601 - val_auc: 0.9907 - val_prc: 0.9900 - val_f1: 0.8704 - val_mcc: 0.7611\n",
      "Epoch 6/20\n",
      "2068/2068 [==============================] - 10s 5ms/step - loss: 0.1337 - tp: 31420.0000 - fp: 1664.0000 - tn: 31420.0000 - fn: 1664.0000 - accuracy: 0.9497 - precision: 0.9497 - recall: 0.9497 - auc: 0.9869 - prc: 0.9859 - f1: 0.8485 - mcc: 0.7250 - val_loss: 0.1210 - val_tp: 3958.0000 - val_fp: 177.0000 - val_tn: 3958.0000 - val_fn: 177.0000 - val_accuracy: 0.9572 - val_precision: 0.9572 - val_recall: 0.9572 - val_auc: 0.9901 - val_prc: 0.9896 - val_f1: 0.8638 - val_mcc: 0.7515\n",
      "Epoch 7/20\n",
      "2068/2068 [==============================] - 10s 5ms/step - loss: 0.1273 - tp: 31527.0000 - fp: 1557.0000 - tn: 31527.0000 - fn: 1557.0000 - accuracy: 0.9529 - precision: 0.9529 - recall: 0.9529 - auc: 0.9883 - prc: 0.9875 - f1: 0.8561 - mcc: 0.7375 - val_loss: 0.1199 - val_tp: 3971.0000 - val_fp: 164.0000 - val_tn: 3971.0000 - val_fn: 164.0000 - val_accuracy: 0.9603 - val_precision: 0.9603 - val_recall: 0.9603 - val_auc: 0.9895 - val_prc: 0.9887 - val_f1: 0.8714 - val_mcc: 0.7633\n",
      "Epoch 8/20\n",
      "2068/2068 [==============================] - 10s 5ms/step - loss: 0.1237 - tp: 31464.0000 - fp: 1620.0000 - tn: 31464.0000 - fn: 1620.0000 - accuracy: 0.9510 - precision: 0.9510 - recall: 0.9510 - auc: 0.9890 - prc: 0.9884 - f1: 0.8518 - mcc: 0.7308 - val_loss: 0.1248 - val_tp: 3941.0000 - val_fp: 194.0000 - val_tn: 3941.0000 - val_fn: 194.0000 - val_accuracy: 0.9531 - val_precision: 0.9531 - val_recall: 0.9531 - val_auc: 0.9897 - val_prc: 0.9893 - val_f1: 0.8546 - val_mcc: 0.7380\n",
      "Epoch 9/20\n",
      "2068/2068 [==============================] - 10s 5ms/step - loss: 0.1202 - tp: 31589.0000 - fp: 1495.0000 - tn: 31589.0000 - fn: 1495.0000 - accuracy: 0.9548 - precision: 0.9548 - recall: 0.9548 - auc: 0.9892 - prc: 0.9884 - f1: 0.8608 - mcc: 0.7454 - val_loss: 0.1030 - val_tp: 3984.0000 - val_fp: 151.0000 - val_tn: 3984.0000 - val_fn: 151.0000 - val_accuracy: 0.9635 - val_precision: 0.9635 - val_recall: 0.9635 - val_auc: 0.9921 - val_prc: 0.9914 - val_f1: 0.8798 - val_mcc: 0.7780\n",
      "Epoch 10/20\n",
      "2068/2068 [==============================] - 10s 5ms/step - loss: 0.1131 - tp: 31683.0000 - fp: 1401.0000 - tn: 31683.0000 - fn: 1401.0000 - accuracy: 0.9577 - precision: 0.9577 - recall: 0.9577 - auc: 0.9901 - prc: 0.9892 - f1: 0.8681 - mcc: 0.7582 - val_loss: 0.1169 - val_tp: 3979.0000 - val_fp: 156.0000 - val_tn: 3979.0000 - val_fn: 156.0000 - val_accuracy: 0.9623 - val_precision: 0.9623 - val_recall: 0.9623 - val_auc: 0.9907 - val_prc: 0.9901 - val_f1: 0.8770 - val_mcc: 0.7738\n",
      "Epoch 11/20\n",
      "2068/2068 [==============================] - 10s 5ms/step - loss: 0.1120 - tp: 31675.0000 - fp: 1409.0000 - tn: 31675.0000 - fn: 1409.0000 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - auc: 0.9902 - prc: 0.9894 - f1: 0.8675 - mcc: 0.7574 - val_loss: 0.1135 - val_tp: 3978.0000 - val_fp: 157.0000 - val_tn: 3978.0000 - val_fn: 157.0000 - val_accuracy: 0.9620 - val_precision: 0.9620 - val_recall: 0.9620 - val_auc: 0.9909 - val_prc: 0.9901 - val_f1: 0.8757 - val_mcc: 0.7705\n",
      "Epoch 12/20\n",
      "2068/2068 [==============================] - 10s 5ms/step - loss: 0.1066 - tp: 31721.0000 - fp: 1363.0000 - tn: 31721.0000 - fn: 1363.0000 - accuracy: 0.9588 - precision: 0.9588 - recall: 0.9588 - auc: 0.9913 - prc: 0.9906 - f1: 0.8705 - mcc: 0.7614 - val_loss: 0.1079 - val_tp: 3980.0000 - val_fp: 155.0000 - val_tn: 3980.0000 - val_fn: 155.0000 - val_accuracy: 0.9625 - val_precision: 0.9625 - val_recall: 0.9625 - val_auc: 0.9920 - val_prc: 0.9913 - val_f1: 0.8776 - val_mcc: 0.7749\n",
      "Epoch 13/20\n",
      "2068/2068 [==============================] - 10s 5ms/step - loss: 0.1022 - tp: 31771.0000 - fp: 1313.0000 - tn: 31771.0000 - fn: 1313.0000 - accuracy: 0.9603 - precision: 0.9603 - recall: 0.9603 - auc: 0.9915 - prc: 0.9907 - f1: 0.8748 - mcc: 0.7696 - val_loss: 0.1132 - val_tp: 3966.0000 - val_fp: 169.0000 - val_tn: 3966.0000 - val_fn: 169.0000 - val_accuracy: 0.9591 - val_precision: 0.9591 - val_recall: 0.9591 - val_auc: 0.9913 - val_prc: 0.9909 - val_f1: 0.8693 - val_mcc: 0.7618\n",
      "Epoch 14/20\n",
      "2068/2068 [==============================] - 10s 5ms/step - loss: 0.1104 - tp: 31675.0000 - fp: 1409.0000 - tn: 31675.0000 - fn: 1409.0000 - accuracy: 0.9574 - precision: 0.9574 - recall: 0.9574 - auc: 0.9909 - prc: 0.9902 - f1: 0.8679 - mcc: 0.7588 - val_loss: 0.1257 - val_tp: 3964.0000 - val_fp: 171.0000 - val_tn: 3964.0000 - val_fn: 171.0000 - val_accuracy: 0.9586 - val_precision: 0.9586 - val_recall: 0.9586 - val_auc: 0.9888 - val_prc: 0.9881 - val_f1: 0.8681 - val_mcc: 0.7598\n",
      "Epoch 15/20\n",
      "2068/2068 [==============================] - 9s 4ms/step - loss: 0.1013 - tp: 31831.0000 - fp: 1253.0000 - tn: 31831.0000 - fn: 1253.0000 - accuracy: 0.9621 - precision: 0.9621 - recall: 0.9621 - auc: 0.9917 - prc: 0.9910 - f1: 0.8796 - mcc: 0.7781 - val_loss: 0.1236 - val_tp: 3957.0000 - val_fp: 178.0000 - val_tn: 3957.0000 - val_fn: 178.0000 - val_accuracy: 0.9570 - val_precision: 0.9570 - val_recall: 0.9570 - val_auc: 0.9893 - val_prc: 0.9883 - val_f1: 0.8639 - val_mcc: 0.7530\n",
      "Epoch 16/20\n",
      "2068/2068 [==============================] - 9s 4ms/step - loss: 0.1040 - tp: 31762.0000 - fp: 1322.0000 - tn: 31762.0000 - fn: 1322.0000 - accuracy: 0.9600 - precision: 0.9600 - recall: 0.9600 - auc: 0.9915 - prc: 0.9908 - f1: 0.8741 - mcc: 0.7685 - val_loss: 0.1025 - val_tp: 3992.0000 - val_fp: 143.0000 - val_tn: 3992.0000 - val_fn: 143.0000 - val_accuracy: 0.9654 - val_precision: 0.9654 - val_recall: 0.9654 - val_auc: 0.9922 - val_prc: 0.9912 - val_f1: 0.8856 - val_mcc: 0.7888\n",
      "Epoch 17/20\n",
      "2068/2068 [==============================] - 9s 4ms/step - loss: 0.1040 - tp: 31792.0000 - fp: 1292.0000 - tn: 31792.0000 - fn: 1292.0000 - accuracy: 0.9609 - precision: 0.9609 - recall: 0.9609 - auc: 0.9917 - prc: 0.9912 - f1: 0.8761 - mcc: 0.7714 - val_loss: 0.1055 - val_tp: 3993.0000 - val_fp: 142.0000 - val_tn: 3993.0000 - val_fn: 142.0000 - val_accuracy: 0.9657 - val_precision: 0.9657 - val_recall: 0.9657 - val_auc: 0.9920 - val_prc: 0.9911 - val_f1: 0.8862 - val_mcc: 0.7899\n",
      "Epoch 18/20\n",
      "2068/2068 [==============================] - 9s 4ms/step - loss: 0.0949 - tp: 31904.0000 - fp: 1180.0000 - tn: 31904.0000 - fn: 1180.0000 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - auc: 0.9928 - prc: 0.9922 - f1: 0.8853 - mcc: 0.7878 - val_loss: 0.1132 - val_tp: 3983.0000 - val_fp: 152.0000 - val_tn: 3983.0000 - val_fn: 152.0000 - val_accuracy: 0.9632 - val_precision: 0.9632 - val_recall: 0.9632 - val_auc: 0.9916 - val_prc: 0.9910 - val_f1: 0.8795 - val_mcc: 0.7780\n",
      "Epoch 19/20\n",
      "2068/2068 [==============================] - 9s 4ms/step - loss: 0.0983 - tp: 31855.0000 - fp: 1229.0000 - tn: 31855.0000 - fn: 1229.0000 - accuracy: 0.9629 - precision: 0.9629 - recall: 0.9629 - auc: 0.9922 - prc: 0.9915 - f1: 0.8815 - mcc: 0.7813 - val_loss: 0.1247 - val_tp: 3967.0000 - val_fp: 168.0000 - val_tn: 3967.0000 - val_fn: 168.0000 - val_accuracy: 0.9594 - val_precision: 0.9594 - val_recall: 0.9594 - val_auc: 0.9888 - val_prc: 0.9876 - val_f1: 0.8699 - val_mcc: 0.7628\n",
      "Epoch 20/20\n",
      "2068/2068 [==============================] - 9s 4ms/step - loss: 0.0935 - tp: 31920.0000 - fp: 1164.0000 - tn: 31920.0000 - fn: 1164.0000 - accuracy: 0.9648 - precision: 0.9648 - recall: 0.9648 - auc: 0.9926 - prc: 0.9919 - f1: 0.8867 - mcc: 0.7902 - val_loss: 0.1236 - val_tp: 3968.0000 - val_fp: 167.0000 - val_tn: 3968.0000 - val_fn: 167.0000 - val_accuracy: 0.9596 - val_precision: 0.9596 - val_recall: 0.9596 - val_auc: 0.9895 - val_prc: 0.9883 - val_f1: 0.8705 - val_mcc: 0.7638\n"
     ]
    }
   ],
   "source": [
    "# Train with class weights\n",
    "\n",
    "model = make_model()\n",
    "#weighted_model.load_weights(initial_weights)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data = (x_dev, y_dev),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    \n",
    "    # The class weights go here\n",
    "    class_weight=d_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9b63e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/gnra_8_80_T/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/gnra_8_80_T/assets\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save(RESULTS_FILE, overwrite=True)\n",
    "\n",
    "# Save history\n",
    "with open(RESULTS_FILE/\"history\", 'wb') as file:\n",
    "    pickle.dump(history.history, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnabert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
