{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aef19d0-9369-45f7-81aa-d7ca27ca925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 12:17:01.951472: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/mimer/NOBACKUP/groups/naiss2024-5-16/tloop/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/mimer/NOBACKUP/groups/naiss2024-5-16/tloop/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# standard libraries\n",
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# standard scientific libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import asarray, save, load\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv1D, Conv2D, MaxPooling2D, Dropout, Flatten, Input, MaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2bc2c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3f533a-9c9c-46ff-bff6-70da4c18f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Config (hyperparameters, metrics, etc.)\n",
    "\n",
    "# DATA_DIR = Path(\"../data_generation/training_data/\")\n",
    "# SET_NAME = str(DATA_DIR).split(\"/\")[-1]\n",
    "# RESULTS_FILE = Path(f\"results/ANN/{SET_NAME}\")\n",
    "# EPOCHS = 20\n",
    "# BATCH_SIZE = 16\n",
    "# NUM_CLASSES = 2\n",
    "# METRICS = [\n",
    "#       keras.metrics.TruePositives(name = 'tp'),\n",
    "#       keras.metrics.FalsePositives(name = 'fp'),\n",
    "#       keras.metrics.TrueNegatives(name = 'tn'),\n",
    "#       keras.metrics.FalseNegatives(name = 'fn'),\n",
    "#       # keras.metrics.BinaryAccuracy(name = 'accuracy'), # TODO remove this?\n",
    "#       keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "#       keras.metrics.Precision(name = 'precision'),\n",
    "#       keras.metrics.Recall(name = 'recall'),\n",
    "#       keras.metrics.AUC(name = 'auc', curve='roc'),\n",
    "#       keras.metrics.AUC(name = 'prc', curve = 'PR'), # precision-recall curve\n",
    "#       tfa.metrics.F1Score(name = 'f1', num_classes = NUM_CLASSES),\n",
    "#       tfa.metrics.MatthewsCorrelationCoefficient(name = 'mcc', num_classes = NUM_CLASSES)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2613041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load dataset\n",
    "\n",
    "# train_dict = np.load(DATA_DIR/\"train_matrices.npz\", allow_pickle=True)\n",
    "# x_train = np.stack(train_dict['arr_0'], axis=0)\n",
    "# y_train = np.load(DATA_DIR/\"train_labels.npy\", allow_pickle=True) # TODO as_type(int) needed?\n",
    "# y_train = to_categorical(y_train, num_classes=NUM_CLASSES)  # TODO categorical, one-hot encode labels\n",
    "\n",
    "# test_dict = np.load(DATA_DIR/\"test_matrices.npz\", allow_pickle=True)\n",
    "# x_test = np.stack(test_dict['arr_0'], axis=0)\n",
    "# y_test = np.load(DATA_DIR/\"test_labels.npy\", allow_pickle=True)\n",
    "# y_test = to_categorical(y_test, num_classes=NUM_CLASSES)\n",
    "\n",
    "# dev_dict = np.load(DATA_DIR/\"dev_matrices.npz\", allow_pickle=True)\n",
    "# x_dev = np.stack(dev_dict['arr_0'], axis=0)\n",
    "# y_dev = np.load(DATA_DIR/\"dev_labels.npy\", allow_pickle=True)\n",
    "# y_dev = to_categorical(y_dev, num_classes=NUM_CLASSES)\n",
    "\n",
    "# #! Merge dev and test sets (if validation set not used)\n",
    "# # x_test = np.concatenate((x_test, x_dev), axis=0)\n",
    "# # y_test = np.concatenate((y_test, y_dev), axis=0)\n",
    "\n",
    "# print(\"training features shape:\", x_train.shape)\n",
    "# print(\"training labels shape:\", y_train.shape)\n",
    "\n",
    "# print(\"\\ntesting features shape:\", x_test.shape)\n",
    "# print(\"testing labels shape:\", y_test.shape)\n",
    "\n",
    "# print(\"\\ndev (validation) features shape:\", x_dev.shape)\n",
    "# print(\"dev (validation) labels shape:\", y_dev.shape)\n",
    "\n",
    "# print(\"\\ninput shape:\", x_train.shape[1:])\n",
    "\n",
    "# INPUT_SHAPE = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bafc96ad-62ad-47da-834b-df3dc94e2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(metrics, num_classes, input_shape, output_bias=None, pool_size = 2):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    \n",
    "    model = Sequential([        \n",
    "        # First convolution\n",
    "        Conv1D(16, 3, strides=1, activation='relu', padding='same', # TODO set as 64?\n",
    "               input_shape = input_shape,\n",
    "               kernel_initializer = 'he_normal',\n",
    "               bias_initializer = 'zeros'),\n",
    "        MaxPooling1D(pool_size = pool_size, strides = 2), # TODO set strides?\n",
    "        Dropout(0.2),\n",
    "        Conv1D(32, 3, strides = 1, activation = 'relu', padding = 'same',\n",
    "               kernel_initializer = 'he_normal',\n",
    "               bias_initializer = 'zeros'),\n",
    "        MaxPooling1D(pool_size = pool_size, strides = 2),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        \n",
    "        # Neuron hidden layer\n",
    "        Dense(int(input_shape[0]/pool_size) * 32, activation = 'relu', kernel_initializer='he_normal', bias_initializer = output_bias),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Output neuron\n",
    "        # Dense(1, activation='sigmoid')  # Sigmoid for binary question. It will contain a value from 0-1 where 0 for class ('not GNRA') and 1 for the other ('GNRA')\n",
    "        Dense(num_classes, activation='softmax', bias_initializer=output_bias, kernel_initializer='glorot_uniform') # TODO categorical: Softmax for multiclass classification\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate = 1e-3),  # optimizer=RMSprop(lr=0.001),\n",
    "        loss=keras.losses.CategoricalCrossentropy(), \n",
    "        # loss=keras.losses.BinaryCrossentropy(), # TODO remove?\n",
    "        metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f0212af-03ea-4253-b725-d11b35d7ed07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.16, 1: 0.88}\n"
     ]
    }
   ],
   "source": [
    "# # Calculate class weight\n",
    "\n",
    "# # Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# # The sum of the weights of all examples stays the same.\n",
    "# y_integers = np.argmax(y_train, axis=1)\n",
    "# class_weights = np.round(class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_integers), y=y_integers), 2)\n",
    "# d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# print(d_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f3b235-e4e4-47ba-b861-e8f97efd7741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train with class weights\n",
    "\n",
    "# model = make_model(METRICS, NUM_CLASSES, INPUT_SHAPE)\n",
    "# #weighted_model.load_weights(initial_weights)\n",
    "\n",
    "# history = model.fit(\n",
    "#     x_train,\n",
    "#     y_train,\n",
    "#     validation_data = (x_dev, y_dev),\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     epochs=EPOCHS,\n",
    "    \n",
    "#     # The class weights go here\n",
    "#     class_weight=d_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b63e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model\n",
    "# model.save(RESULTS_FILE, overwrite=True)\n",
    "\n",
    "# # Save history\n",
    "# with open(RESULTS_FILE/\"history\", 'wb') as file:\n",
    "#     pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf891565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(DATA_DIR, NUM_CLASSES, EPOCHS = 20, BATCH_SIZE = 16):\n",
    "    DATA_DIR = Path(DATA_DIR)\n",
    "    SET_NAME = str(DATA_DIR).split(\"/\")[-1]\n",
    "    RESULTS_FILE = Path(f\"results/ANN/{SET_NAME}\")\n",
    "    METRICS = [\n",
    "        keras.metrics.TruePositives(name = 'tp'),\n",
    "        keras.metrics.FalsePositives(name = 'fp'),\n",
    "        keras.metrics.TrueNegatives(name = 'tn'),\n",
    "        keras.metrics.FalseNegatives(name = 'fn'),\n",
    "        # keras.metrics.BinaryAccuracy(name = 'accuracy'), # TODO remove this?\n",
    "        keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name = 'precision'),\n",
    "        keras.metrics.Recall(name = 'recall'),\n",
    "        keras.metrics.AUC(name = 'auc', curve='roc'),\n",
    "        keras.metrics.AUC(name = 'prc', curve = 'PR'), # precision-recall curve\n",
    "        tfa.metrics.F1Score(name = 'f1', num_classes = NUM_CLASSES),\n",
    "        tfa.metrics.MatthewsCorrelationCoefficient(name = 'mcc', num_classes = NUM_CLASSES)\n",
    "    ]\n",
    "\n",
    "    # Load dataset\n",
    "    \n",
    "    train_dict = np.load(DATA_DIR/\"train_matrices.npz\", allow_pickle=True)\n",
    "    x_train = np.stack(train_dict['arr_0'], axis=0)\n",
    "    y_train = np.load(DATA_DIR/\"train_labels.npy\", allow_pickle=True)\n",
    "    y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "\n",
    "    dev_dict = np.load(DATA_DIR/\"dev_matrices.npz\", allow_pickle=True)\n",
    "    x_dev = np.stack(dev_dict['arr_0'], axis=0)\n",
    "    y_dev = np.load(DATA_DIR/\"dev_labels.npy\", allow_pickle=True)\n",
    "    y_dev = to_categorical(y_dev, num_classes=NUM_CLASSES)\n",
    "\n",
    "    print(\"Training features shape:\", x_train.shape)\n",
    "    print(\"Training labels shape:\", y_train.shape)\n",
    "\n",
    "    print(\"\\nDev (validation) features shape:\", x_dev.shape)\n",
    "    print(\"Dev (validation) labels shape:\", y_dev.shape)\n",
    "\n",
    "    print(\"\\nInput shape:\", x_train.shape[1:])\n",
    "    print()\n",
    "\n",
    "    INPUT_SHAPE = x_train.shape[1:]\n",
    "\n",
    "    # Calculate class weight\n",
    "\n",
    "    # Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "    # The sum of the weights of all examples stays the same.\n",
    "    y_integers = np.argmax(y_train, axis=1)\n",
    "    class_weights = np.round(class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_integers), y=y_integers), 2)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    # Train with class weights\n",
    "\n",
    "    model = make_model(METRICS, NUM_CLASSES, INPUT_SHAPE)\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_data = (x_dev, y_dev),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        \n",
    "        # The class weights go here\n",
    "        class_weight=d_class_weights)\n",
    "    \n",
    "    # Save model\n",
    "    model.save(RESULTS_FILE, overwrite=True)\n",
    "\n",
    "    # Save history\n",
    "    with open(RESULTS_FILE/\"history\", 'wb') as file:\n",
    "        pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5a9f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_18_80_T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 12:18:33.844520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38551 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:4b:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (58392, 18, 5)\n",
      "Training labels shape: (58392, 24)\n",
      "\n",
      "Dev (validation) features shape: (7299, 18, 5)\n",
      "Dev (validation) labels shape: (7299, 24)\n",
      "\n",
      "Input shape: (18, 5)\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /apps/Arch/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 12:18:37.613219: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n",
      "2024-05-05 12:18:38.593073: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3650/3650 [==============================] - 18s 4ms/step - loss: 1.4139 - tp: 4798.0000 - fp: 9530.0000 - tn: 1333486.0000 - fn: 53594.0000 - accuracy: 0.2169 - precision: 0.3349 - recall: 0.0822 - auc: 0.8553 - prc: 0.2003 - f1: 0.0762 - mcc: 0.1075 - val_loss: 2.2500 - val_tp: 439.0000 - val_fp: 2012.0000 - val_tn: 165865.0000 - val_fn: 6860.0000 - val_accuracy: 0.1663 - val_precision: 0.1791 - val_recall: 0.0601 - val_auc: 0.8948 - val_prc: 0.1997 - val_f1: 0.2472 - val_mcc: 0.1463\n",
      "Epoch 2/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.6484 - tp: 10734.0000 - fp: 16606.0000 - tn: 1326410.0000 - fn: 47658.0000 - accuracy: 0.3242 - precision: 0.3926 - recall: 0.1838 - auc: 0.9164 - prc: 0.3095 - f1: 0.1462 - mcc: 0.1744 - val_loss: 1.6240 - val_tp: 1470.0000 - val_fp: 1440.0000 - val_tn: 166437.0000 - val_fn: 5829.0000 - val_accuracy: 0.4068 - val_precision: 0.5052 - val_recall: 0.2014 - val_auc: 0.9429 - val_prc: 0.3957 - val_f1: 0.1908 - val_mcc: 0.2299\n",
      "Epoch 3/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.5390 - tp: 15286.0000 - fp: 17205.0000 - tn: 1325811.0000 - fn: 43106.0000 - accuracy: 0.4098 - precision: 0.4705 - recall: 0.2618 - auc: 0.9438 - prc: 0.4000 - f1: 0.1890 - mcc: 0.2034 - val_loss: 1.9302 - val_tp: 612.0000 - val_fp: 1447.0000 - val_tn: 166430.0000 - val_fn: 6687.0000 - val_accuracy: 0.2359 - val_precision: 0.2972 - val_recall: 0.0838 - val_auc: 0.9198 - val_prc: 0.2667 - val_f1: 0.2019 - val_mcc: 0.1972\n",
      "Epoch 4/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.4475 - tp: 17051.0000 - fp: 17271.0000 - tn: 1325745.0000 - fn: 41341.0000 - accuracy: 0.4357 - precision: 0.4968 - recall: 0.2920 - auc: 0.9496 - prc: 0.4293 - f1: 0.2090 - mcc: 0.2228 - val_loss: 1.4146 - val_tp: 1532.0000 - val_fp: 1220.0000 - val_tn: 166657.0000 - val_fn: 5767.0000 - val_accuracy: 0.4513 - val_precision: 0.5567 - val_recall: 0.2099 - val_auc: 0.9581 - val_prc: 0.4577 - val_f1: 0.2226 - val_mcc: 0.2518\n",
      "Epoch 5/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.4166 - tp: 23278.0000 - fp: 16548.0000 - tn: 1326468.0000 - fn: 35114.0000 - accuracy: 0.5141 - precision: 0.5845 - recall: 0.3987 - auc: 0.9600 - prc: 0.5338 - f1: 0.2325 - mcc: 0.2474 - val_loss: 1.8339 - val_tp: 1206.0000 - val_fp: 2344.0000 - val_tn: 165533.0000 - val_fn: 6093.0000 - val_accuracy: 0.2857 - val_precision: 0.3397 - val_recall: 0.1652 - val_auc: 0.9306 - val_prc: 0.3091 - val_f1: 0.2340 - val_mcc: 0.1956\n",
      "Epoch 6/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3834 - tp: 25616.0000 - fp: 16009.0000 - tn: 1327007.0000 - fn: 32776.0000 - accuracy: 0.5511 - precision: 0.6154 - recall: 0.4387 - auc: 0.9669 - prc: 0.5791 - f1: 0.2572 - mcc: 0.2661 - val_loss: 1.4109 - val_tp: 1605.0000 - val_fp: 1335.0000 - val_tn: 166542.0000 - val_fn: 5694.0000 - val_accuracy: 0.4369 - val_precision: 0.5459 - val_recall: 0.2199 - val_auc: 0.9581 - val_prc: 0.4554 - val_f1: 0.2437 - val_mcc: 0.2503\n",
      "Epoch 7/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3675 - tp: 25245.0000 - fp: 15290.0000 - tn: 1327726.0000 - fn: 33147.0000 - accuracy: 0.5559 - precision: 0.6228 - recall: 0.4323 - auc: 0.9681 - prc: 0.5795 - f1: 0.2699 - mcc: 0.2698 - val_loss: 1.7422 - val_tp: 1073.0000 - val_fp: 2484.0000 - val_tn: 165393.0000 - val_fn: 6226.0000 - val_accuracy: 0.2776 - val_precision: 0.3017 - val_recall: 0.1470 - val_auc: 0.9381 - val_prc: 0.3083 - val_f1: 0.2900 - val_mcc: 0.2209\n",
      "Epoch 8/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3559 - tp: 29171.0000 - fp: 14702.0000 - tn: 1328314.0000 - fn: 29221.0000 - accuracy: 0.5993 - precision: 0.6649 - recall: 0.4996 - auc: 0.9730 - prc: 0.6401 - f1: 0.2794 - mcc: 0.2899 - val_loss: 1.4420 - val_tp: 1851.0000 - val_fp: 1830.0000 - val_tn: 166047.0000 - val_fn: 5448.0000 - val_accuracy: 0.4196 - val_precision: 0.5029 - val_recall: 0.2536 - val_auc: 0.9556 - val_prc: 0.4414 - val_f1: 0.2876 - val_mcc: 0.2494\n",
      "Epoch 9/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3579 - tp: 27639.0000 - fp: 16190.0000 - tn: 1326826.0000 - fn: 30753.0000 - accuracy: 0.5693 - precision: 0.6306 - recall: 0.4733 - auc: 0.9660 - prc: 0.5957 - f1: 0.2719 - mcc: 0.2787 - val_loss: 1.4934 - val_tp: 2184.0000 - val_fp: 2058.0000 - val_tn: 165819.0000 - val_fn: 5115.0000 - val_accuracy: 0.4513 - val_precision: 0.5149 - val_recall: 0.2992 - val_auc: 0.9490 - val_prc: 0.4390 - val_f1: 0.2612 - val_mcc: 0.2569\n",
      "Epoch 10/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3219 - tp: 30307.0000 - fp: 15197.0000 - tn: 1327819.0000 - fn: 28085.0000 - accuracy: 0.6054 - precision: 0.6660 - recall: 0.5190 - auc: 0.9713 - prc: 0.6477 - f1: 0.2794 - mcc: 0.2944 - val_loss: 1.5419 - val_tp: 2111.0000 - val_fp: 2236.0000 - val_tn: 165641.0000 - val_fn: 5188.0000 - val_accuracy: 0.4201 - val_precision: 0.4856 - val_recall: 0.2892 - val_auc: 0.9467 - val_prc: 0.4222 - val_f1: 0.2396 - val_mcc: 0.2558\n",
      "Epoch 11/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3110 - tp: 31198.0000 - fp: 14542.0000 - tn: 1328474.0000 - fn: 27194.0000 - accuracy: 0.6229 - precision: 0.6821 - recall: 0.5343 - auc: 0.9732 - prc: 0.6680 - f1: 0.2827 - mcc: 0.3013 - val_loss: 1.2808 - val_tp: 2779.0000 - val_fp: 2103.0000 - val_tn: 165774.0000 - val_fn: 4520.0000 - val_accuracy: 0.5135 - val_precision: 0.5692 - val_recall: 0.3807 - val_auc: 0.9631 - val_prc: 0.5321 - val_f1: 0.2616 - val_mcc: 0.2820\n",
      "Epoch 12/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3388 - tp: 29312.0000 - fp: 15966.0000 - tn: 1327050.0000 - fn: 29080.0000 - accuracy: 0.5837 - precision: 0.6474 - recall: 0.5020 - auc: 0.9697 - prc: 0.6305 - f1: 0.2706 - mcc: 0.2839 - val_loss: 1.3817 - val_tp: 2388.0000 - val_fp: 1728.0000 - val_tn: 166149.0000 - val_fn: 4911.0000 - val_accuracy: 0.4672 - val_precision: 0.5802 - val_recall: 0.3272 - val_auc: 0.9574 - val_prc: 0.4936 - val_f1: 0.2463 - val_mcc: 0.2625\n",
      "Epoch 13/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3249 - tp: 29391.0000 - fp: 14884.0000 - tn: 1328132.0000 - fn: 29001.0000 - accuracy: 0.5950 - precision: 0.6638 - recall: 0.5033 - auc: 0.9712 - prc: 0.6403 - f1: 0.2657 - mcc: 0.2914 - val_loss: 1.6520 - val_tp: 1747.0000 - val_fp: 1948.0000 - val_tn: 165929.0000 - val_fn: 5552.0000 - val_accuracy: 0.3768 - val_precision: 0.4728 - val_recall: 0.2393 - val_auc: 0.9407 - val_prc: 0.3833 - val_f1: 0.2225 - val_mcc: 0.2370\n",
      "Epoch 14/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3101 - tp: 31113.0000 - fp: 14890.0000 - tn: 1328126.0000 - fn: 27279.0000 - accuracy: 0.6176 - precision: 0.6763 - recall: 0.5328 - auc: 0.9728 - prc: 0.6574 - f1: 0.2897 - mcc: 0.3021 - val_loss: 1.2144 - val_tp: 2886.0000 - val_fp: 1816.0000 - val_tn: 166061.0000 - val_fn: 4413.0000 - val_accuracy: 0.5471 - val_precision: 0.6138 - val_recall: 0.3954 - val_auc: 0.9649 - val_prc: 0.5527 - val_f1: 0.2897 - val_mcc: 0.2905\n",
      "Epoch 15/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3083 - tp: 30894.0000 - fp: 14799.0000 - tn: 1328217.0000 - fn: 27498.0000 - accuracy: 0.6153 - precision: 0.6761 - recall: 0.5291 - auc: 0.9730 - prc: 0.6589 - f1: 0.2953 - mcc: 0.3003 - val_loss: 0.9826 - val_tp: 3565.0000 - val_fp: 1495.0000 - val_tn: 166382.0000 - val_fn: 3734.0000 - val_accuracy: 0.6276 - val_precision: 0.7045 - val_recall: 0.4884 - val_auc: 0.9777 - val_prc: 0.6704 - val_f1: 0.3278 - val_mcc: 0.3272\n",
      "Epoch 16/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.2994 - tp: 34303.0000 - fp: 13563.0000 - tn: 1329453.0000 - fn: 24089.0000 - accuracy: 0.6632 - precision: 0.7166 - recall: 0.5875 - auc: 0.9782 - prc: 0.7215 - f1: 0.2979 - mcc: 0.3255 - val_loss: 1.2806 - val_tp: 2708.0000 - val_fp: 1796.0000 - val_tn: 166081.0000 - val_fn: 4591.0000 - val_accuracy: 0.5313 - val_precision: 0.6012 - val_recall: 0.3710 - val_auc: 0.9620 - val_prc: 0.5299 - val_f1: 0.2759 - val_mcc: 0.2851\n",
      "Epoch 17/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3057 - tp: 31403.0000 - fp: 14667.0000 - tn: 1328349.0000 - fn: 26989.0000 - accuracy: 0.6246 - precision: 0.6816 - recall: 0.5378 - auc: 0.9723 - prc: 0.6631 - f1: 0.2836 - mcc: 0.3073 - val_loss: 1.0012 - val_tp: 3638.0000 - val_fp: 1470.0000 - val_tn: 166407.0000 - val_fn: 3661.0000 - val_accuracy: 0.6330 - val_precision: 0.7122 - val_recall: 0.4984 - val_auc: 0.9764 - val_prc: 0.6658 - val_f1: 0.2815 - val_mcc: 0.3345\n",
      "Epoch 18/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.2932 - tp: 33400.0000 - fp: 14112.0000 - tn: 1328904.0000 - fn: 24992.0000 - accuracy: 0.6474 - precision: 0.7030 - recall: 0.5720 - auc: 0.9761 - prc: 0.7010 - f1: 0.2957 - mcc: 0.3184 - val_loss: 1.1488 - val_tp: 3357.0000 - val_fp: 1778.0000 - val_tn: 166099.0000 - val_fn: 3942.0000 - val_accuracy: 0.5708 - val_precision: 0.6537 - val_recall: 0.4599 - val_auc: 0.9683 - val_prc: 0.6095 - val_f1: 0.2731 - val_mcc: 0.3049\n",
      "Epoch 19/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3351 - tp: 30748.0000 - fp: 14735.0000 - tn: 1328281.0000 - fn: 27644.0000 - accuracy: 0.6059 - precision: 0.6760 - recall: 0.5266 - auc: 0.9718 - prc: 0.6641 - f1: 0.2771 - mcc: 0.2971 - val_loss: 1.4251 - val_tp: 2297.0000 - val_fp: 1794.0000 - val_tn: 166083.0000 - val_fn: 5002.0000 - val_accuracy: 0.4666 - val_precision: 0.5615 - val_recall: 0.3147 - val_auc: 0.9551 - val_prc: 0.4720 - val_f1: 0.2397 - val_mcc: 0.2638\n",
      "Epoch 20/20\n",
      "3650/3650 [==============================] - 13s 4ms/step - loss: 0.3235 - tp: 30646.0000 - fp: 14780.0000 - tn: 1328236.0000 - fn: 27746.0000 - accuracy: 0.6093 - precision: 0.6746 - recall: 0.5248 - auc: 0.9718 - prc: 0.6592 - f1: 0.2650 - mcc: 0.2984 - val_loss: 1.1161 - val_tp: 3297.0000 - val_fp: 1760.0000 - val_tn: 166117.0000 - val_fn: 4002.0000 - val_accuracy: 0.5875 - val_precision: 0.6520 - val_recall: 0.4517 - val_auc: 0.9701 - val_prc: 0.6096 - val_f1: 0.2857 - val_mcc: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_18_80_T/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/clusters_18_80_T/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_22_80_T\n",
      "Training features shape: (59692, 22, 5)\n",
      "Training labels shape: (59692, 24)\n",
      "\n",
      "Dev (validation) features shape: (7461, 22, 5)\n",
      "Dev (validation) labels shape: (7461, 24)\n",
      "\n",
      "Input shape: (22, 5)\n",
      "\n",
      "Epoch 1/20\n",
      "3731/3731 [==============================] - 16s 4ms/step - loss: 1.1992 - tp: 7224.0000 - fp: 9421.0000 - tn: 1363495.0000 - fn: 52468.0000 - accuracy: 0.2982 - precision: 0.4340 - recall: 0.1210 - auc: 0.8904 - prc: 0.2782 - f1: 0.0990 - mcc: 0.1358 - val_loss: 1.6948 - val_tp: 1040.0000 - val_fp: 1194.0000 - val_tn: 170409.0000 - val_fn: 6421.0000 - val_accuracy: 0.3756 - val_precision: 0.4655 - val_recall: 0.1394 - val_auc: 0.9407 - val_prc: 0.3688 - val_f1: 0.2096 - val_mcc: 0.2037\n",
      "Epoch 2/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.5781 - tp: 15793.0000 - fp: 15579.0000 - tn: 1357337.0000 - fn: 43899.0000 - accuracy: 0.4172 - precision: 0.5034 - recall: 0.2646 - auc: 0.9367 - prc: 0.4097 - f1: 0.1725 - mcc: 0.2006 - val_loss: 2.2714 - val_tp: 624.0000 - val_fp: 1881.0000 - val_tn: 169722.0000 - val_fn: 6837.0000 - val_accuracy: 0.2126 - val_precision: 0.2491 - val_recall: 0.0836 - val_auc: 0.8856 - val_prc: 0.2139 - val_f1: 0.2026 - val_mcc: 0.1304\n",
      "Epoch 3/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.4793 - tp: 19925.0000 - fp: 16105.0000 - tn: 1356811.0000 - fn: 39767.0000 - accuracy: 0.4765 - precision: 0.5530 - recall: 0.3338 - auc: 0.9521 - prc: 0.4775 - f1: 0.2101 - mcc: 0.2303 - val_loss: 1.3955 - val_tp: 1665.0000 - val_fp: 1613.0000 - val_tn: 169990.0000 - val_fn: 5796.0000 - val_accuracy: 0.4352 - val_precision: 0.5079 - val_recall: 0.2232 - val_auc: 0.9593 - val_prc: 0.4442 - val_f1: 0.3063 - val_mcc: 0.2152\n",
      "Epoch 4/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.4160 - tp: 25104.0000 - fp: 15280.0000 - tn: 1357636.0000 - fn: 34588.0000 - accuracy: 0.5504 - precision: 0.6216 - recall: 0.4206 - auc: 0.9648 - prc: 0.5672 - f1: 0.2674 - mcc: 0.2606 - val_loss: 1.5750 - val_tp: 1404.0000 - val_fp: 1641.0000 - val_tn: 169962.0000 - val_fn: 6057.0000 - val_accuracy: 0.4116 - val_precision: 0.4611 - val_recall: 0.1882 - val_auc: 0.9477 - val_prc: 0.3930 - val_f1: 0.2460 - val_mcc: 0.2249\n",
      "Epoch 5/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3537 - tp: 27492.0000 - fp: 14581.0000 - tn: 1358335.0000 - fn: 32200.0000 - accuracy: 0.5852 - precision: 0.6534 - recall: 0.4606 - auc: 0.9709 - prc: 0.6113 - f1: 0.2669 - mcc: 0.2808 - val_loss: 1.0677 - val_tp: 3006.0000 - val_fp: 1381.0000 - val_tn: 170222.0000 - val_fn: 4455.0000 - val_accuracy: 0.6054 - val_precision: 0.6852 - val_recall: 0.4029 - val_auc: 0.9759 - val_prc: 0.6291 - val_f1: 0.2871 - val_mcc: 0.2996\n",
      "Epoch 6/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3533 - tp: 29059.0000 - fp: 14426.0000 - tn: 1358490.0000 - fn: 30633.0000 - accuracy: 0.5983 - precision: 0.6683 - recall: 0.4868 - auc: 0.9730 - prc: 0.6405 - f1: 0.2763 - mcc: 0.2880 - val_loss: 1.2200 - val_tp: 2329.0000 - val_fp: 1266.0000 - val_tn: 170337.0000 - val_fn: 5132.0000 - val_accuracy: 0.5395 - val_precision: 0.6478 - val_recall: 0.3122 - val_auc: 0.9691 - val_prc: 0.5630 - val_f1: 0.2642 - val_mcc: 0.2734\n",
      "Epoch 7/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3425 - tp: 29595.0000 - fp: 14984.0000 - tn: 1357932.0000 - fn: 30097.0000 - accuracy: 0.6019 - precision: 0.6639 - recall: 0.4958 - auc: 0.9728 - prc: 0.6368 - f1: 0.2811 - mcc: 0.2934 - val_loss: 1.1910 - val_tp: 2719.0000 - val_fp: 1704.0000 - val_tn: 169899.0000 - val_fn: 4742.0000 - val_accuracy: 0.5376 - val_precision: 0.6147 - val_recall: 0.3644 - val_auc: 0.9686 - val_prc: 0.5618 - val_f1: 0.2996 - val_mcc: 0.2744\n",
      "Epoch 8/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3333 - tp: 30132.0000 - fp: 14936.0000 - tn: 1357980.0000 - fn: 29560.0000 - accuracy: 0.6085 - precision: 0.6686 - recall: 0.5048 - auc: 0.9740 - prc: 0.6454 - f1: 0.2957 - mcc: 0.2958 - val_loss: 1.0504 - val_tp: 3335.0000 - val_fp: 1441.0000 - val_tn: 170162.0000 - val_fn: 4126.0000 - val_accuracy: 0.6204 - val_precision: 0.6983 - val_recall: 0.4470 - val_auc: 0.9750 - val_prc: 0.6458 - val_f1: 0.3193 - val_mcc: 0.3111\n",
      "Epoch 9/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3160 - tp: 33591.0000 - fp: 13927.0000 - tn: 1358989.0000 - fn: 26101.0000 - accuracy: 0.6517 - precision: 0.7069 - recall: 0.5627 - auc: 0.9781 - prc: 0.6987 - f1: 0.3043 - mcc: 0.3180 - val_loss: 0.9884 - val_tp: 3559.0000 - val_fp: 1136.0000 - val_tn: 170467.0000 - val_fn: 3902.0000 - val_accuracy: 0.6440 - val_precision: 0.7580 - val_recall: 0.4770 - val_auc: 0.9789 - val_prc: 0.7002 - val_f1: 0.2545 - val_mcc: 0.3049\n",
      "Epoch 10/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3092 - tp: 34322.0000 - fp: 13504.0000 - tn: 1359412.0000 - fn: 25370.0000 - accuracy: 0.6600 - precision: 0.7176 - recall: 0.5750 - auc: 0.9792 - prc: 0.7196 - f1: 0.3037 - mcc: 0.3249 - val_loss: 1.0466 - val_tp: 3321.0000 - val_fp: 1226.0000 - val_tn: 170377.0000 - val_fn: 4140.0000 - val_accuracy: 0.6301 - val_precision: 0.7304 - val_recall: 0.4451 - val_auc: 0.9762 - val_prc: 0.6677 - val_f1: 0.2749 - val_mcc: 0.3010\n",
      "Epoch 11/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.3089 - tp: 35385.0000 - fp: 13431.0000 - tn: 1359485.0000 - fn: 24307.0000 - accuracy: 0.6722 - precision: 0.7249 - recall: 0.5928 - auc: 0.9792 - prc: 0.7270 - f1: 0.3051 - mcc: 0.3291 - val_loss: 0.6872 - val_tp: 4975.0000 - val_fp: 1196.0000 - val_tn: 170407.0000 - val_fn: 2486.0000 - val_accuracy: 0.7583 - val_precision: 0.8062 - val_recall: 0.6668 - val_auc: 0.9880 - val_prc: 0.8158 - val_f1: 0.3592 - val_mcc: 0.3979\n",
      "Epoch 12/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.2922 - tp: 34427.0000 - fp: 13708.0000 - tn: 1359208.0000 - fn: 25265.0000 - accuracy: 0.6580 - precision: 0.7152 - recall: 0.5767 - auc: 0.9776 - prc: 0.7124 - f1: 0.2935 - mcc: 0.3230 - val_loss: 1.0042 - val_tp: 3620.0000 - val_fp: 1476.0000 - val_tn: 170127.0000 - val_fn: 3841.0000 - val_accuracy: 0.6305 - val_precision: 0.7104 - val_recall: 0.4852 - val_auc: 0.9768 - val_prc: 0.6807 - val_f1: 0.3047 - val_mcc: 0.3136\n",
      "Epoch 13/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.2906 - tp: 34487.0000 - fp: 13501.0000 - tn: 1359415.0000 - fn: 25205.0000 - accuracy: 0.6619 - precision: 0.7187 - recall: 0.5777 - auc: 0.9785 - prc: 0.7190 - f1: 0.3066 - mcc: 0.3315 - val_loss: 0.6700 - val_tp: 5099.0000 - val_fp: 1201.0000 - val_tn: 170402.0000 - val_fn: 2362.0000 - val_accuracy: 0.7645 - val_precision: 0.8094 - val_recall: 0.6834 - val_auc: 0.9880 - val_prc: 0.8227 - val_f1: 0.3758 - val_mcc: 0.4006\n",
      "Epoch 14/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.2999 - tp: 36601.0000 - fp: 12910.0000 - tn: 1360006.0000 - fn: 23091.0000 - accuracy: 0.6866 - precision: 0.7392 - recall: 0.6132 - auc: 0.9807 - prc: 0.7487 - f1: 0.3063 - mcc: 0.3410 - val_loss: 1.4094 - val_tp: 2285.0000 - val_fp: 1719.0000 - val_tn: 169884.0000 - val_fn: 5176.0000 - val_accuracy: 0.4708 - val_precision: 0.5707 - val_recall: 0.3063 - val_auc: 0.9553 - val_prc: 0.4849 - val_f1: 0.2147 - val_mcc: 0.2463\n",
      "Epoch 15/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.2987 - tp: 35115.0000 - fp: 13250.0000 - tn: 1359666.0000 - fn: 24577.0000 - accuracy: 0.6656 - precision: 0.7260 - recall: 0.5883 - auc: 0.9781 - prc: 0.7254 - f1: 0.2887 - mcc: 0.3283 - val_loss: 1.4711 - val_tp: 1841.0000 - val_fp: 1596.0000 - val_tn: 170007.0000 - val_fn: 5620.0000 - val_accuracy: 0.4439 - val_precision: 0.5356 - val_recall: 0.2467 - val_auc: 0.9536 - val_prc: 0.4491 - val_f1: 0.2122 - val_mcc: 0.2248\n",
      "Epoch 16/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.2843 - tp: 35802.0000 - fp: 13276.0000 - tn: 1359640.0000 - fn: 23890.0000 - accuracy: 0.6745 - precision: 0.7295 - recall: 0.5998 - auc: 0.9784 - prc: 0.7310 - f1: 0.2919 - mcc: 0.3360 - val_loss: 1.0478 - val_tp: 3735.0000 - val_fp: 1473.0000 - val_tn: 170130.0000 - val_fn: 3726.0000 - val_accuracy: 0.6317 - val_precision: 0.7172 - val_recall: 0.5006 - val_auc: 0.9732 - val_prc: 0.6693 - val_f1: 0.2671 - val_mcc: 0.3183\n",
      "Epoch 17/20\n",
      "3731/3731 [==============================] - 13s 4ms/step - loss: 0.2937 - tp: 35389.0000 - fp: 14417.0000 - tn: 1358499.0000 - fn: 24303.0000 - accuracy: 0.6617 - precision: 0.7105 - recall: 0.5929 - auc: 0.9760 - prc: 0.7142 - f1: 0.3040 - mcc: 0.3285 - val_loss: 1.4088 - val_tp: 2334.0000 - val_fp: 2864.0000 - val_tn: 168739.0000 - val_fn: 5127.0000 - val_accuracy: 0.4213 - val_precision: 0.4490 - val_recall: 0.3128 - val_auc: 0.9582 - val_prc: 0.4355 - val_f1: 0.3054 - val_mcc: 0.2389\n",
      "Epoch 18/20\n",
      "  63/3731 [..............................] - ETA: 12s - loss: 0.3429 - tp: 580.0000 - fp: 284.0000 - tn: 22900.0000 - fn: 428.0000 - accuracy: 0.6339 - precision: 0.6713 - recall: 0.5754 - auc: 0.9779 - prc: 0.6970 - f1: 0.4111 - mcc: 0.3303"
     ]
    }
   ],
   "source": [
    "PATH = Path(\"../data_generation/training_data/\")\n",
    "for dir in os.listdir(PATH):\n",
    "    if dir[-1] != \"U\" and \"gnravall\" not in dir and os.path.isdir(PATH/dir):\n",
    "        if \"clusters\" in dir:\n",
    "            # pass\n",
    "            print(dir)\n",
    "            train(PATH/dir, 24)\n",
    "        else:\n",
    "            pass\n",
    "            # train(PATH/dir, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnabert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
