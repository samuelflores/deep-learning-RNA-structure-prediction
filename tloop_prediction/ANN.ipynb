{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aef19d0-9369-45f7-81aa-d7ca27ca925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:32:46.689835: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/mimer/NOBACKUP/groups/naiss2024-5-16/tloop/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/mimer/NOBACKUP/groups/naiss2024-5-16/tloop/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# standard libraries\n",
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# standard scientific libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import asarray, save, load\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv1D, Conv2D, MaxPooling2D, Dropout, Flatten, Input, MaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2bc2c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bafc96ad-62ad-47da-834b-df3dc94e2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(metrics, num_classes, input_shape, output_bias=None, pool_size = 2):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    \n",
    "    model = Sequential([        \n",
    "        # First convolution\n",
    "        Conv1D(16, 3, strides=1, activation='relu', padding='same', # TODO set as 64?\n",
    "               input_shape = input_shape,\n",
    "               kernel_initializer = 'he_normal',\n",
    "               bias_initializer = 'zeros'),\n",
    "        MaxPooling1D(pool_size = pool_size, strides = 2), # TODO set strides?\n",
    "        Dropout(0.2),\n",
    "        Conv1D(32, 3, strides = 1, activation = 'relu', padding = 'same',\n",
    "               kernel_initializer = 'he_normal',\n",
    "               bias_initializer = 'zeros'),\n",
    "        MaxPooling1D(pool_size = pool_size, strides = 2),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        \n",
    "        # Neuron hidden layer\n",
    "        Dense(int(input_shape[0]/pool_size) * 32, activation = 'relu', kernel_initializer='he_normal', bias_initializer = output_bias),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Output neuron\n",
    "        # Dense(1, activation='sigmoid')  # Sigmoid for binary question. It will contain a value from 0-1 where 0 for class ('not GNRA') and 1 for the other ('GNRA')\n",
    "        Dense(num_classes, activation='softmax', bias_initializer=output_bias, kernel_initializer='glorot_uniform') # TODO categorical: Softmax for multiclass classification\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate = 1e-3),  # optimizer=RMSprop(lr=0.001),\n",
    "        loss=keras.losses.CategoricalCrossentropy(), \n",
    "        # loss=keras.losses.BinaryCrossentropy(), # TODO remove?\n",
    "        metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf891565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(DATA_DIR, NUM_CLASSES, EPOCHS = 20, BATCH_SIZE = 16):\n",
    "    DATA_DIR = Path(DATA_DIR)\n",
    "    SET_NAME = str(DATA_DIR).split(\"/\")[-1]\n",
    "    RESULTS_FILE = RESULTS_DIR / SET_NAME\n",
    "    # RESULTS_FILE = Path(f\"results/ANN/homology_reduced/{SET_NAME}\")\n",
    "    METRICS = [ \n",
    "        keras.metrics.TruePositives(name = 'tp'), # TODO is this correct? something is wrong\n",
    "        keras.metrics.FalsePositives(name = 'fp'),\n",
    "        keras.metrics.TrueNegatives(name = 'tn'),\n",
    "        keras.metrics.FalseNegatives(name = 'fn'),\n",
    "        # keras.metrics.BinaryAccuracy(name = 'accuracy'), # TODO remove this?\n",
    "        keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name = 'precision'),\n",
    "        keras.metrics.Recall(name = 'recall'),\n",
    "        keras.metrics.AUC(name = 'auc', curve='roc'),\n",
    "        keras.metrics.AUC(name = 'prc', curve = 'PR'), # precision-recall curve\n",
    "        tfa.metrics.F1Score(name = 'f1', num_classes = NUM_CLASSES),\n",
    "        tfa.metrics.MatthewsCorrelationCoefficient(name = 'mcc', num_classes = NUM_CLASSES)\n",
    "    ]\n",
    "\n",
    "    # Load dataset\n",
    "    \n",
    "    train_dict = np.load(DATA_DIR/\"train_matrices.npz\", allow_pickle=True)\n",
    "    x_train = np.stack(train_dict['arr_0'], axis=0)\n",
    "    y_train = np.load(DATA_DIR/\"train_labels.npy\", allow_pickle=True)\n",
    "    y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "\n",
    "    dev_dict = np.load(DATA_DIR/\"dev_matrices.npz\", allow_pickle=True)\n",
    "    x_dev = np.stack(dev_dict['arr_0'], axis=0)\n",
    "    y_dev = np.load(DATA_DIR/\"dev_labels.npy\", allow_pickle=True)\n",
    "    y_dev = to_categorical(y_dev, num_classes=NUM_CLASSES)\n",
    "\n",
    "    print(\"Training features shape:\", x_train.shape)\n",
    "    print(\"Training labels shape:\", y_train.shape)\n",
    "\n",
    "    print(\"\\nDev (validation) features shape:\", x_dev.shape)\n",
    "    print(\"Dev (validation) labels shape:\", y_dev.shape)\n",
    "\n",
    "    print(\"\\nInput shape:\", x_train.shape[1:])\n",
    "    print()\n",
    "\n",
    "    INPUT_SHAPE = x_train.shape[1:]\n",
    "\n",
    "    # Calculate class weight\n",
    "\n",
    "    # Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "    # The sum of the weights of all examples stays the same.\n",
    "    y_integers = np.argmax(y_train, axis=1)\n",
    "    class_weights = np.round(class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_integers), y=y_integers), 2)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    # Train with class weights\n",
    "\n",
    "    model = make_model(METRICS, NUM_CLASSES, INPUT_SHAPE)\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_data = (x_dev, y_dev),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        \n",
    "        # The class weights go here\n",
    "        class_weight=d_class_weights)\n",
    "    \n",
    "    # Save model\n",
    "    model.save(RESULTS_FILE, overwrite=True)\n",
    "\n",
    "    # Save history\n",
    "    with open(RESULTS_FILE/\"history\", 'wb') as file:\n",
    "        pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce5a9f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:34:19.428716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13762 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:87:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (246, 8, 5)\n",
      "Training labels shape: (246, 2)\n",
      "\n",
      "Dev (validation) features shape: (31, 8, 5)\n",
      "Dev (validation) labels shape: (31, 2)\n",
      "\n",
      "Input shape: (8, 5)\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /apps/Arch/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:34:23.020413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 5s 68ms/step - loss: 0.7974 - tp: 128.0000 - fp: 118.0000 - tn: 128.0000 - fn: 118.0000 - accuracy: 0.5203 - precision: 0.5203 - recall: 0.5203 - auc: 0.5543 - prc: 0.5445 - f1: 0.5177 - mcc: 0.0372 - val_loss: 0.6187 - val_tp: 21.0000 - val_fp: 10.0000 - val_tn: 21.0000 - val_fn: 10.0000 - val_accuracy: 0.6774 - val_precision: 0.6774 - val_recall: 0.6774 - val_auc: 0.7201 - val_prc: 0.6995 - val_f1: 0.6477 - val_mcc: 0.3206\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.7488 - tp: 145.0000 - fp: 101.0000 - tn: 145.0000 - fn: 101.0000 - accuracy: 0.5894 - precision: 0.5894 - recall: 0.5894 - auc: 0.5900 - prc: 0.5660 - f1: 0.5894 - mcc: 0.1798 - val_loss: 0.6148 - val_tp: 24.0000 - val_fp: 7.0000 - val_tn: 24.0000 - val_fn: 7.0000 - val_accuracy: 0.7742 - val_precision: 0.7742 - val_recall: 0.7742 - val_auc: 0.7435 - val_prc: 0.7146 - val_f1: 0.7704 - val_mcc: 0.5424\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7116 - tp: 137.0000 - fp: 109.0000 - tn: 137.0000 - fn: 109.0000 - accuracy: 0.5569 - precision: 0.5569 - recall: 0.5569 - auc: 0.6077 - prc: 0.5915 - f1: 0.5557 - mcc: 0.1118 - val_loss: 0.6024 - val_tp: 23.0000 - val_fp: 8.0000 - val_tn: 23.0000 - val_fn: 8.0000 - val_accuracy: 0.7419 - val_precision: 0.7419 - val_recall: 0.7419 - val_auc: 0.7638 - val_prc: 0.7370 - val_f1: 0.7350 - val_mcc: 0.4701\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7130 - tp: 139.0000 - fp: 107.0000 - tn: 139.0000 - fn: 107.0000 - accuracy: 0.5650 - precision: 0.5650 - recall: 0.5650 - auc: 0.6063 - prc: 0.6014 - f1: 0.5589 - mcc: 0.1262 - val_loss: 0.6101 - val_tp: 22.0000 - val_fp: 9.0000 - val_tn: 22.0000 - val_fn: 9.0000 - val_accuracy: 0.7097 - val_precision: 0.7097 - val_recall: 0.7097 - val_auc: 0.7357 - val_prc: 0.7111 - val_f1: 0.7085 - val_mcc: 0.4304\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6864 - tp: 152.0000 - fp: 94.0000 - tn: 152.0000 - fn: 94.0000 - accuracy: 0.6179 - precision: 0.6179 - recall: 0.6179 - auc: 0.6387 - prc: 0.6193 - f1: 0.6177 - mcc: 0.2393 - val_loss: 0.5933 - val_tp: 21.0000 - val_fp: 10.0000 - val_tn: 21.0000 - val_fn: 10.0000 - val_accuracy: 0.6774 - val_precision: 0.6774 - val_recall: 0.6774 - val_auc: 0.7591 - val_prc: 0.7332 - val_f1: 0.6688 - val_mcc: 0.3376\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6502 - tp: 159.0000 - fp: 87.0000 - tn: 159.0000 - fn: 87.0000 - accuracy: 0.6463 - precision: 0.6463 - recall: 0.6463 - auc: 0.6940 - prc: 0.6774 - f1: 0.6462 - mcc: 0.2926 - val_loss: 0.6081 - val_tp: 22.0000 - val_fp: 9.0000 - val_tn: 22.0000 - val_fn: 9.0000 - val_accuracy: 0.7097 - val_precision: 0.7097 - val_recall: 0.7097 - val_auc: 0.7315 - val_prc: 0.6842 - val_f1: 0.7085 - val_mcc: 0.4304\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6471 - tp: 159.0000 - fp: 87.0000 - tn: 159.0000 - fn: 87.0000 - accuracy: 0.6463 - precision: 0.6463 - recall: 0.6463 - auc: 0.7010 - prc: 0.6826 - f1: 0.6450 - mcc: 0.2911 - val_loss: 0.5893 - val_tp: 21.0000 - val_fp: 10.0000 - val_tn: 21.0000 - val_fn: 10.0000 - val_accuracy: 0.6774 - val_precision: 0.6774 - val_recall: 0.6774 - val_auc: 0.7523 - val_prc: 0.7399 - val_f1: 0.6744 - val_mcc: 0.3545\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6335 - tp: 160.0000 - fp: 86.0000 - tn: 160.0000 - fn: 86.0000 - accuracy: 0.6504 - precision: 0.6504 - recall: 0.6504 - auc: 0.6989 - prc: 0.6901 - f1: 0.6503 - mcc: 0.3010 - val_loss: 0.5952 - val_tp: 22.0000 - val_fp: 9.0000 - val_tn: 22.0000 - val_fn: 9.0000 - val_accuracy: 0.7097 - val_precision: 0.7097 - val_recall: 0.7097 - val_auc: 0.7544 - val_prc: 0.7504 - val_f1: 0.7085 - val_mcc: 0.4304\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6589 - tp: 167.0000 - fp: 79.0000 - tn: 167.0000 - fn: 79.0000 - accuracy: 0.6789 - precision: 0.6789 - recall: 0.6789 - auc: 0.6958 - prc: 0.6641 - f1: 0.6749 - mcc: 0.3581 - val_loss: 0.5886 - val_tp: 22.0000 - val_fp: 9.0000 - val_tn: 22.0000 - val_fn: 9.0000 - val_accuracy: 0.7097 - val_precision: 0.7097 - val_recall: 0.7097 - val_auc: 0.7627 - val_prc: 0.7610 - val_f1: 0.7085 - val_mcc: 0.4304\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6140 - tp: 162.0000 - fp: 84.0000 - tn: 162.0000 - fn: 84.0000 - accuracy: 0.6585 - precision: 0.6585 - recall: 0.6585 - auc: 0.7289 - prc: 0.7078 - f1: 0.6583 - mcc: 0.3209 - val_loss: 0.5759 - val_tp: 22.0000 - val_fp: 9.0000 - val_tn: 22.0000 - val_fn: 9.0000 - val_accuracy: 0.7097 - val_precision: 0.7097 - val_recall: 0.7097 - val_auc: 0.7763 - val_prc: 0.7504 - val_f1: 0.7048 - val_mcc: 0.4110\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6412 - tp: 164.0000 - fp: 82.0000 - tn: 164.0000 - fn: 82.0000 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - auc: 0.6962 - prc: 0.6801 - f1: 0.6653 - mcc: 0.3319 - val_loss: 0.5854 - val_tp: 22.0000 - val_fp: 9.0000 - val_tn: 22.0000 - val_fn: 9.0000 - val_accuracy: 0.7097 - val_precision: 0.7097 - val_recall: 0.7097 - val_auc: 0.7659 - val_prc: 0.7498 - val_f1: 0.7085 - val_mcc: 0.4304\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6227 - tp: 157.0000 - fp: 89.0000 - tn: 157.0000 - fn: 89.0000 - accuracy: 0.6382 - precision: 0.6382 - recall: 0.6382 - auc: 0.7162 - prc: 0.7084 - f1: 0.6375 - mcc: 0.2752 - val_loss: 0.5744 - val_tp: 22.0000 - val_fp: 9.0000 - val_tn: 22.0000 - val_fn: 9.0000 - val_accuracy: 0.7097 - val_precision: 0.7097 - val_recall: 0.7097 - val_auc: 0.7804 - val_prc: 0.7291 - val_f1: 0.7085 - val_mcc: 0.4304\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5955 - tp: 168.0000 - fp: 78.0000 - tn: 168.0000 - fn: 78.0000 - accuracy: 0.6829 - precision: 0.6829 - recall: 0.6829 - auc: 0.7470 - prc: 0.7370 - f1: 0.6824 - mcc: 0.3649 - val_loss: 0.5692 - val_tp: 22.0000 - val_fp: 9.0000 - val_tn: 22.0000 - val_fn: 9.0000 - val_accuracy: 0.7097 - val_precision: 0.7097 - val_recall: 0.7097 - val_auc: 0.7804 - val_prc: 0.7344 - val_f1: 0.7085 - val_mcc: 0.4304\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6389 - tp: 158.0000 - fp: 88.0000 - tn: 158.0000 - fn: 88.0000 - accuracy: 0.6423 - precision: 0.6423 - recall: 0.6423 - auc: 0.6911 - prc: 0.6830 - f1: 0.6419 - mcc: 0.2893 - val_loss: 0.5531 - val_tp: 22.0000 - val_fp: 9.0000 - val_tn: 22.0000 - val_fn: 9.0000 - val_accuracy: 0.7097 - val_precision: 0.7097 - val_recall: 0.7097 - val_auc: 0.7981 - val_prc: 0.7492 - val_f1: 0.7048 - val_mcc: 0.4110\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5947 - tp: 163.0000 - fp: 83.0000 - tn: 163.0000 - fn: 83.0000 - accuracy: 0.6626 - precision: 0.6626 - recall: 0.6626 - auc: 0.7386 - prc: 0.7390 - f1: 0.6623 - mcc: 0.3247 - val_loss: 0.5628 - val_tp: 22.0000 - val_fp: 9.0000 - val_tn: 22.0000 - val_fn: 9.0000 - val_accuracy: 0.7097 - val_precision: 0.7097 - val_recall: 0.7097 - val_auc: 0.7877 - val_prc: 0.7708 - val_f1: 0.7085 - val_mcc: 0.4304\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6058 - tp: 170.0000 - fp: 76.0000 - tn: 170.0000 - fn: 76.0000 - accuracy: 0.6911 - precision: 0.6911 - recall: 0.6911 - auc: 0.7374 - prc: 0.7308 - f1: 0.6907 - mcc: 0.3815 - val_loss: 0.5442 - val_tp: 22.0000 - val_fp: 9.0000 - val_tn: 22.0000 - val_fn: 9.0000 - val_accuracy: 0.7097 - val_precision: 0.7097 - val_recall: 0.7097 - val_auc: 0.8127 - val_prc: 0.7884 - val_f1: 0.7085 - val_mcc: 0.4304\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5678 - tp: 176.0000 - fp: 70.0000 - tn: 176.0000 - fn: 70.0000 - accuracy: 0.7154 - precision: 0.7154 - recall: 0.7154 - auc: 0.7819 - prc: 0.7644 - f1: 0.7139 - mcc: 0.4302 - val_loss: 0.5419 - val_tp: 22.0000 - val_fp: 9.0000 - val_tn: 22.0000 - val_fn: 9.0000 - val_accuracy: 0.7097 - val_precision: 0.7097 - val_recall: 0.7097 - val_auc: 0.8148 - val_prc: 0.7996 - val_f1: 0.7085 - val_mcc: 0.4304\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5724 - tp: 165.0000 - fp: 81.0000 - tn: 165.0000 - fn: 81.0000 - accuracy: 0.6707 - precision: 0.6707 - recall: 0.6707 - auc: 0.7610 - prc: 0.7705 - f1: 0.6707 - mcc: 0.3425 - val_loss: 0.5380 - val_tp: 22.0000 - val_fp: 9.0000 - val_tn: 22.0000 - val_fn: 9.0000 - val_accuracy: 0.7097 - val_precision: 0.7097 - val_recall: 0.7097 - val_auc: 0.8210 - val_prc: 0.8090 - val_f1: 0.7085 - val_mcc: 0.4304\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5723 - tp: 178.0000 - fp: 68.0000 - tn: 178.0000 - fn: 68.0000 - accuracy: 0.7236 - precision: 0.7236 - recall: 0.7236 - auc: 0.7737 - prc: 0.7701 - f1: 0.7227 - mcc: 0.4462 - val_loss: 0.5341 - val_tp: 22.0000 - val_fp: 9.0000 - val_tn: 22.0000 - val_fn: 9.0000 - val_accuracy: 0.7097 - val_precision: 0.7097 - val_recall: 0.7097 - val_auc: 0.8283 - val_prc: 0.8199 - val_f1: 0.7085 - val_mcc: 0.4304\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5568 - tp: 175.0000 - fp: 71.0000 - tn: 175.0000 - fn: 71.0000 - accuracy: 0.7114 - precision: 0.7114 - recall: 0.7114 - auc: 0.7864 - prc: 0.7786 - f1: 0.7111 - mcc: 0.4223 - val_loss: 0.5309 - val_tp: 23.0000 - val_fp: 8.0000 - val_tn: 23.0000 - val_fn: 8.0000 - val_accuracy: 0.7419 - val_precision: 0.7419 - val_recall: 0.7419 - val_auc: 0.8273 - val_prc: 0.8252 - val_f1: 0.7395 - val_mcc: 0.4853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/homology_reduced/gnra_8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/homology_reduced/gnra_8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (452, 24, 5)\n",
      "Training labels shape: (452, 2)\n",
      "\n",
      "Dev (validation) features shape: (57, 24, 5)\n",
      "Dev (validation) labels shape: (57, 2)\n",
      "\n",
      "Input shape: (24, 5)\n",
      "\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 3s 47ms/step - loss: 0.8415 - tp: 246.0000 - fp: 206.0000 - tn: 246.0000 - fn: 206.0000 - accuracy: 0.5442 - precision: 0.5442 - recall: 0.5442 - auc: 0.5603 - prc: 0.5420 - f1: 0.5410 - mcc: 0.0906 - val_loss: 0.5099 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.8720 - val_prc: 0.8773 - val_f1: 0.7708 - val_mcc: 0.5654\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5635 - tp: 326.0000 - fp: 126.0000 - tn: 326.0000 - fn: 126.0000 - accuracy: 0.7212 - precision: 0.7212 - recall: 0.7212 - auc: 0.7820 - prc: 0.7704 - f1: 0.7166 - mcc: 0.4360 - val_loss: 0.4031 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.9172 - val_prc: 0.9058 - val_f1: 0.8389 - val_mcc: 0.6827\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5288 - tp: 333.0000 - fp: 119.0000 - tn: 333.0000 - fn: 119.0000 - accuracy: 0.7367 - precision: 0.7367 - recall: 0.7367 - auc: 0.8203 - prc: 0.8160 - f1: 0.7318 - mcc: 0.4658 - val_loss: 0.3416 - val_tp: 53.0000 - val_fp: 4.0000 - val_tn: 53.0000 - val_fn: 4.0000 - val_accuracy: 0.9298 - val_precision: 0.9298 - val_recall: 0.9298 - val_auc: 0.9375 - val_prc: 0.9112 - val_f1: 0.9260 - val_mcc: 0.8545\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4680 - tp: 361.0000 - fp: 91.0000 - tn: 361.0000 - fn: 91.0000 - accuracy: 0.7987 - precision: 0.7987 - recall: 0.7987 - auc: 0.8681 - prc: 0.8488 - f1: 0.7930 - mcc: 0.5860 - val_loss: 0.3226 - val_tp: 53.0000 - val_fp: 4.0000 - val_tn: 53.0000 - val_fn: 4.0000 - val_accuracy: 0.9298 - val_precision: 0.9298 - val_recall: 0.9298 - val_auc: 0.9446 - val_prc: 0.9280 - val_f1: 0.9271 - val_mcc: 0.8542\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4285 - tp: 366.0000 - fp: 86.0000 - tn: 366.0000 - fn: 86.0000 - accuracy: 0.8097 - precision: 0.8097 - recall: 0.8097 - auc: 0.8855 - prc: 0.8754 - f1: 0.8058 - mcc: 0.6133 - val_loss: 0.3191 - val_tp: 53.0000 - val_fp: 4.0000 - val_tn: 53.0000 - val_fn: 4.0000 - val_accuracy: 0.9298 - val_precision: 0.9298 - val_recall: 0.9298 - val_auc: 0.9375 - val_prc: 0.9209 - val_f1: 0.9260 - val_mcc: 0.8545\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4845 - tp: 353.0000 - fp: 99.0000 - tn: 353.0000 - fn: 99.0000 - accuracy: 0.7810 - precision: 0.7810 - recall: 0.7810 - auc: 0.8596 - prc: 0.8498 - f1: 0.7751 - mcc: 0.5504 - val_loss: 0.3325 - val_tp: 52.0000 - val_fp: 5.0000 - val_tn: 52.0000 - val_fn: 5.0000 - val_accuracy: 0.9123 - val_precision: 0.9123 - val_recall: 0.9123 - val_auc: 0.9335 - val_prc: 0.9173 - val_f1: 0.9066 - val_mcc: 0.8190\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4347 - tp: 366.0000 - fp: 86.0000 - tn: 366.0000 - fn: 86.0000 - accuracy: 0.8097 - precision: 0.8097 - recall: 0.8097 - auc: 0.8908 - prc: 0.8778 - f1: 0.8039 - mcc: 0.6078 - val_loss: 0.3331 - val_tp: 51.0000 - val_fp: 6.0000 - val_tn: 51.0000 - val_fn: 6.0000 - val_accuracy: 0.8947 - val_precision: 0.8947 - val_recall: 0.8947 - val_auc: 0.9351 - val_prc: 0.9169 - val_f1: 0.8890 - val_mcc: 0.7803\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4182 - tp: 368.0000 - fp: 84.0000 - tn: 368.0000 - fn: 84.0000 - accuracy: 0.8142 - precision: 0.8142 - recall: 0.8142 - auc: 0.8939 - prc: 0.8868 - f1: 0.8096 - mcc: 0.6197 - val_loss: 0.3204 - val_tp: 51.0000 - val_fp: 6.0000 - val_tn: 51.0000 - val_fn: 6.0000 - val_accuracy: 0.8947 - val_precision: 0.8947 - val_recall: 0.8947 - val_auc: 0.9394 - val_prc: 0.9272 - val_f1: 0.8920 - val_mcc: 0.7864\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3710 - tp: 379.0000 - fp: 73.0000 - tn: 379.0000 - fn: 73.0000 - accuracy: 0.8385 - precision: 0.8385 - recall: 0.8385 - auc: 0.9180 - prc: 0.9176 - f1: 0.8329 - mcc: 0.6659 - val_loss: 0.3444 - val_tp: 49.0000 - val_fp: 8.0000 - val_tn: 49.0000 - val_fn: 8.0000 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_auc: 0.9267 - val_prc: 0.9213 - val_f1: 0.8575 - val_mcc: 0.7237\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3725 - tp: 382.0000 - fp: 70.0000 - tn: 382.0000 - fn: 70.0000 - accuracy: 0.8451 - precision: 0.8451 - recall: 0.8451 - auc: 0.9180 - prc: 0.9111 - f1: 0.8404 - mcc: 0.6808 - val_loss: 0.3098 - val_tp: 51.0000 - val_fp: 6.0000 - val_tn: 51.0000 - val_fn: 6.0000 - val_accuracy: 0.8947 - val_precision: 0.8947 - val_recall: 0.8947 - val_auc: 0.9472 - val_prc: 0.9382 - val_f1: 0.8920 - val_mcc: 0.7864\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3391 - tp: 382.0000 - fp: 70.0000 - tn: 382.0000 - fn: 70.0000 - accuracy: 0.8451 - precision: 0.8451 - recall: 0.8451 - auc: 0.9295 - prc: 0.9293 - f1: 0.8413 - mcc: 0.6832 - val_loss: 0.2815 - val_tp: 53.0000 - val_fp: 4.0000 - val_tn: 53.0000 - val_fn: 4.0000 - val_accuracy: 0.9298 - val_precision: 0.9298 - val_recall: 0.9298 - val_auc: 0.9541 - val_prc: 0.9435 - val_f1: 0.9271 - val_mcc: 0.8542\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3399 - tp: 387.0000 - fp: 65.0000 - tn: 387.0000 - fn: 65.0000 - accuracy: 0.8562 - precision: 0.8562 - recall: 0.8562 - auc: 0.9298 - prc: 0.9288 - f1: 0.8523 - mcc: 0.7049 - val_loss: 0.2802 - val_tp: 53.0000 - val_fp: 4.0000 - val_tn: 53.0000 - val_fn: 4.0000 - val_accuracy: 0.9298 - val_precision: 0.9298 - val_recall: 0.9298 - val_auc: 0.9544 - val_prc: 0.9337 - val_f1: 0.9271 - val_mcc: 0.8542\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3155 - tp: 395.0000 - fp: 57.0000 - tn: 395.0000 - fn: 57.0000 - accuracy: 0.8739 - precision: 0.8739 - recall: 0.8739 - auc: 0.9400 - prc: 0.9371 - f1: 0.8703 - mcc: 0.7407 - val_loss: 0.2733 - val_tp: 53.0000 - val_fp: 4.0000 - val_tn: 53.0000 - val_fn: 4.0000 - val_accuracy: 0.9298 - val_precision: 0.9298 - val_recall: 0.9298 - val_auc: 0.9514 - val_prc: 0.9328 - val_f1: 0.9271 - val_mcc: 0.8542\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2725 - tp: 402.0000 - fp: 50.0000 - tn: 402.0000 - fn: 50.0000 - accuracy: 0.8894 - precision: 0.8894 - recall: 0.8894 - auc: 0.9548 - prc: 0.9559 - f1: 0.8870 - mcc: 0.7752 - val_loss: 0.2742 - val_tp: 53.0000 - val_fp: 4.0000 - val_tn: 53.0000 - val_fn: 4.0000 - val_accuracy: 0.9298 - val_precision: 0.9298 - val_recall: 0.9298 - val_auc: 0.9532 - val_prc: 0.9292 - val_f1: 0.9271 - val_mcc: 0.8542\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3107 - tp: 395.0000 - fp: 57.0000 - tn: 395.0000 - fn: 57.0000 - accuracy: 0.8739 - precision: 0.8739 - recall: 0.8739 - auc: 0.9465 - prc: 0.9467 - f1: 0.8686 - mcc: 0.7387 - val_loss: 0.2954 - val_tp: 53.0000 - val_fp: 4.0000 - val_tn: 53.0000 - val_fn: 4.0000 - val_accuracy: 0.9298 - val_precision: 0.9298 - val_recall: 0.9298 - val_auc: 0.9437 - val_prc: 0.9367 - val_f1: 0.9271 - val_mcc: 0.8542\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2923 - tp: 400.0000 - fp: 52.0000 - tn: 400.0000 - fn: 52.0000 - accuracy: 0.8850 - precision: 0.8850 - recall: 0.8850 - auc: 0.9484 - prc: 0.9460 - f1: 0.8818 - mcc: 0.7637 - val_loss: 0.2961 - val_tp: 52.0000 - val_fp: 5.0000 - val_tn: 52.0000 - val_fn: 5.0000 - val_accuracy: 0.9123 - val_precision: 0.9123 - val_recall: 0.9123 - val_auc: 0.9486 - val_prc: 0.9439 - val_f1: 0.9095 - val_mcc: 0.8196\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3247 - tp: 384.0000 - fp: 68.0000 - tn: 384.0000 - fn: 68.0000 - accuracy: 0.8496 - precision: 0.8496 - recall: 0.8496 - auc: 0.9357 - prc: 0.9333 - f1: 0.8463 - mcc: 0.6938 - val_loss: 0.2774 - val_tp: 53.0000 - val_fp: 4.0000 - val_tn: 53.0000 - val_fn: 4.0000 - val_accuracy: 0.9298 - val_precision: 0.9298 - val_recall: 0.9298 - val_auc: 0.9504 - val_prc: 0.9368 - val_f1: 0.9271 - val_mcc: 0.8542\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3101 - tp: 394.0000 - fp: 58.0000 - tn: 394.0000 - fn: 58.0000 - accuracy: 0.8717 - precision: 0.8717 - recall: 0.8717 - auc: 0.9397 - prc: 0.9362 - f1: 0.8683 - mcc: 0.7370 - val_loss: 0.2720 - val_tp: 54.0000 - val_fp: 3.0000 - val_tn: 54.0000 - val_fn: 3.0000 - val_accuracy: 0.9474 - val_precision: 0.9474 - val_recall: 0.9474 - val_auc: 0.9492 - val_prc: 0.9325 - val_f1: 0.9449 - val_mcc: 0.8905\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2745 - tp: 402.0000 - fp: 50.0000 - tn: 402.0000 - fn: 50.0000 - accuracy: 0.8894 - precision: 0.8894 - recall: 0.8894 - auc: 0.9560 - prc: 0.9565 - f1: 0.8860 - mcc: 0.7720 - val_loss: 0.2660 - val_tp: 53.0000 - val_fp: 4.0000 - val_tn: 53.0000 - val_fn: 4.0000 - val_accuracy: 0.9298 - val_precision: 0.9298 - val_recall: 0.9298 - val_auc: 0.9511 - val_prc: 0.9385 - val_f1: 0.9271 - val_mcc: 0.8542\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2834 - tp: 402.0000 - fp: 50.0000 - tn: 402.0000 - fn: 50.0000 - accuracy: 0.8894 - precision: 0.8894 - recall: 0.8894 - auc: 0.9520 - prc: 0.9479 - f1: 0.8865 - mcc: 0.7733 - val_loss: 0.2621 - val_tp: 55.0000 - val_fp: 2.0000 - val_tn: 55.0000 - val_fn: 2.0000 - val_accuracy: 0.9649 - val_precision: 0.9649 - val_recall: 0.9649 - val_auc: 0.9535 - val_prc: 0.9327 - val_f1: 0.9630 - val_mcc: 0.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/homology_reduced/gnra_24/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/ANN/homology_reduced/gnra_24/assets\n"
     ]
    }
   ],
   "source": [
    "PATH = Path(\"../data_generation/training_data/homology_reduced/\")\n",
    "RESULTS_DIR = Path(f\"results/ANN/homology_reduced/\")\n",
    "for dir in os.listdir(PATH):\n",
    "    if dir[-1] != \"U\" and \"gnravall\" not in dir and os.path.isdir(PATH/dir):\n",
    "        if \"clusters\" in dir:\n",
    "            pass\n",
    "            # print(dir)\n",
    "            # train(PATH/dir, 24)\n",
    "        else:\n",
    "            # pass\n",
    "            train(PATH/dir, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnabert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
