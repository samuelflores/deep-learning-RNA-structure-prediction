{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO make tensorflow dataset\n",
    "# does this require the arrays to be pre-processed?\n",
    "\n",
    "def make_tf_dataset(all_frags):\n",
    "    all_arrays = [arr for pdb_arrs in all_frags.values() for arr in pdb_arrs]\n",
    "    features = [''.join(arr.tolist()[2]) for arr in all_arrays] # Residue sequences\n",
    "    labels = [arr[1,0] for arr in all_arrays] # Cluster IDs\n",
    "    \n",
    "    features = tf.keras.preprocessing.text.one_hot()\n",
    "\n",
    "    print(labels)\n",
    "    print(features)\n",
    "\n",
    "    # dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "    # dataset = dataset.shuffle(buffer_size=len(features))\n",
    "    # dataset = dataset.batch(32)\n",
    "    # dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
